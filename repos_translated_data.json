[
  {
    "readme": "# community-project\nplayground for the community project in medieninformatik bachelor\n",
    "readme_before": "# community-project\nplayground für das community projekt im medieninformatik bachelor\n"
  },
  {
    "readme": "# b.s.c. in computer science\n\ncourses carried out to obtain the degree of * * bachiller in computer science * *, offered by the [professional school of computer science (epcc)] (https: / / fc.uni.edu.pe / fc / index.php / schools / ciencia-de-la-computation) of the [faculty of science (fc)] (https: / / fc.uni.edu.pe / fc /) at the [national engineering university (uni)) (https: / / www.uni.edu.pe /) from 2012. lima - Peru.\n\n\nperiod 2012-i:\n\ncc101 - introduction to computer science\n\nperiod 2012-ii:\n\ncc102 - introduction to programming\n\nperiod 2013-i:\n\ncc201 - introduction to object-oriented programming\n\nperiod 2013-ii:\n\ncc212 - Computer architecture\ncc262 - algorithms\n\nperiod 2014-i:\n\ncm094 - data structure\ncm274 - introduction to statistics and probabilities\n\nperiod 2014-ii:\n\ncc331 - database\ncc361 - operating systems\n\n# # period 2015-i:\n\ncc060 - genetic algorithms\ncc301 - parallel algorithms\ncm334 - numerical analysis i\n\nperiod 2015-ii:\n\ncc003 - special computer science topics\ncc302 - object-oriented distributed parallel language\ncc322 - graphic computing\ncc342 - computer theory\ncc362 - network-centred computing\ncm431 - numerical analysis ii\n\n# # period 2016-i:\n\ncc021 - special software topics\ncc066 - programming of mobile devices\ncc401 - network application programming\ncc441 - artificial intelligence\ncc461 - compilers\ncc471 - computer biology\ncc481 - network management\n\nperiod 2016-ii:\n\ncc055 - introduction to robotics\ncc063 - computer physics\ncc462 - concurrent and distributed systems\ncc472 - software engineering\ncc482 - nuclear and parallel computing networks\ncc541 - seminar of thesis\ncc562 - modeling and simulation\n\nperiod 2017-i\n\ncc067 - computer security\ncc542 - seminar of thesis ii\ncc571 - advanced operating systems\ncc581 - introduction to grid and cloud computing\n\n",
    "readme_before": "# b.sc. in computer science\n\ncursos realizados para obtener el grado de **bachiller en ciencia de la computación**, ofrecidos por la [escuela profesional de ciencia de la computación (epcc)](https://fc.uni.edu.pe/fc/index.php/escuelas/ciencia-de-la-computacion) de la [facultad de ciencias (fc)](https://fc.uni.edu.pe/fc/) en la [universidad nacional de ingeniería (uni)](https://www.uni.edu.pe/) desde el 2012 hasta el 2017. lima - perú.\n\n\n## periodo 2012-i:\n\n    cc101 - introducción a la ciencia de la computación\n\n## periodo 2012-ii:\n\n    cc102 - introducción a la programación\n\n## periodo 2013-i:\n\n    cc201 - introducción a la programación orientada a objetos\n\n## periodo 2013-ii:\n\n    cc212 - arquitectura de computadores\n    cc262 - algoritmos\n\n## periodo 2014-i:\n\n    cm094 - estructura de datos\n    cm274 - introducción a la estadistica y probabilidades\n\n## periodo 2014-ii:\n\n    cc331 - base de datos\n    cc361 - sistemas operativos\n\n## periodo 2015-i:\n\n    cc060 - algoritmos genéticos\n    cc301 - algoritmos paralelos\n    cm334 - analisis numerico i\n\n## periodo 2015-ii:\n\n    cc003 - topicos especiales de ciencia de la computación\n    cc302 - lenguaje paralelo distribuido orientado a objetos\n    cc322 - computación grafica\n    cc342 - teoria de la computación\n    cc362 - computación centrada en redes\n    cm431 - analisis numerico ii\n\n## periodo 2016-i:\n\n    cc021 - topicos especiales de software\n    cc066 - programación de dispositivos moviles\n    cc401 - programación de aplicaciones en redes\n    cc441 - inteligencia artificial\n    cc461 - compiladores\n    cc471 - biologia computacional\n    cc481 - administración de redes\n\n## periodo 2016-ii:\n\n    cc055 - introducción a la robotica\n    cc063 - fisica computacional\n    cc462 - sistemas concurrentes y distribuidos\n    cc472 - ingenieria de software\n    cc482 - nucleo y redes para computación paralela\n    cc541 - seminario de tesis i\n    cc562 - modelamiento y simulación\n\n## periodo 2017-i\n\n    cc067 - seguridad en computación\n    cc542 - seminario de tesis ii\n    cc571 - sistemas operativos avanzados\n    cc581 - introducción a la computación grid y cloud\n\n"
  },
  {
    "readme": "<img src=\" HTTPs://raw. githubusercontent. com/tarikul-islam-anik/animated-fluent-emojis/master/emojis/people/man 20% student. · alt=\"man student\" width=\"45\"/>My Lotus's path\n\nA repository of complete information on computer engineering courses and parallels with project links\n\n<div dir=\"rtl\"\n\n* A reboot of full information of courses and computer engineering course projects along with the links of projects*\n\n## List\n(General Information)\n(The List of Things)\n(#)\n(#m-1️⃣)\n(#-1️⃣)\n(computer-computer)\n[projects outside of University 1️⃣]\n(#2️⃣)\n(computer support and programming)\n[projects outside the University of 2️⃣] (# external-projects-of-university)\n(#3)\n[Advanced Plan 1] (# Lessons-programming-improvement-provestment-1)\n[projects outside the University of 3️⃣] (# external-projects-of-university)\n(#4️⃣)\n[Advanced Programming 2] (# Lessons-programming-progressive-2)\n(data buildings)\n[projects outside the University of 4️⃣]\n(#-5️⃣)\n(computer-computer)\n(The testing of logical circuits and computer architecture)\n[The Computer Association]\n[projects outside the University of 5️⃣]\n(#6️⃣)\n(Design of algorithms)\n(computer networks)\n(The Qur’an and the tongue)\n(#)\n[projects outside the University of 6️⃣] (# Foreign-out-of-university projects)\n(#7)\n(The test)\n(Afghan)\n(computer network testing)\n(Internet Engineering)\n(Certainly)\n[projects outside of the University of 7️⃣]\n(#-8️⃣)\n(#les and systems)\n(Provision of information)\n[The Master Project]\n[projects outside of University 8️⃣]\n\nOverall information\n\nNumber of projects:*\n[ ]! github (https://img). shields. io/badge/projects – +200-blue)\n\nNumber of hours:*\n[ ]! github (https://img). shields. io/badge/hours-+10000-blue)\n\nNumber of code lines:*\n[ ]! github (https://img). shields. io/badge/lines 20%of 20%code- +400000-blue)\n\n## List of Things\n[x]! HTTPS://geps. dev/progress/100* University course*\n[x]! HTTPS://geps. dev/progress/100* Review and collect projects\n[x]! HTTPS://geps. dev/progress/100*\n[x]! HTTPS://geps. dev/progress/100* projects on GitHub\n[ (HTTP://geps.) dev/progress/50\n[ (HTTP://geps). dev/progress/20* Review and improve projects*\n\n## Tips\n* Some projects may be archived or deleted. ***\n* Some projects may be private. ***\n* Some projects are not on GitHub. ***\n* The only insinuate of the undergraduate degree that had the project are located in this Ryopy. ***\n* Projects outside of the bachelor's course and are freely called \"projects outside the university\" per semester. ***\n\n-\n\n#1 semester 1️⃣\n\n## Computer Workshop\n\n## 📚 Teaching\nHTML and CSS*\n← icdl*\n\n##60 projects\n* Designed Types of Ducks\n* Designing a simple HTML and design page with CSS*\n\n\nProjects outside of University 1️⃣\n* Comparison of followers and followers of Instagram accounts and find repeats\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/duplicated_followers_followings\"><img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n* The total time of watching videos of a course*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/video length>img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* Photos and category using their resolution\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/picture_ Transparency >img src=\"s://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* Make a password list*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/passwordcreator <img src=\" HTTP://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n\n#2 semester #2\n\n• Lessons from Computer Fundamentals and Planning\n\n## 📚 Teaching\n* The Fallchart and simple algorithm questions\n* Python language*\n\n##60 projects\n* The Contact Management System (cms) [11 projects]\n* Links:*\n<a href= HTTPs://github. <img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\nProjects outside of University 2️⃣\nQuestions and projects fortran\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_fortranproject <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n← Goldyran enigma »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/jeyraneigma <img src=\"s://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* The Telegram Lake Project\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/telegramleakdatabase_iranianusers\"<img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n* Telegram Robot Project: Finding Links for Free Website Courses\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb__udemycoursecrawler <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* Mobile app project with kiwi*\n\n\n\n#3 semester 3️⃣\n\nAdvanced Program 1\n\n## 📚 Teaching\n* Advanced Algorithmic Questions »\n* The language of Java and object\n*Desk and comment*\n\n##60 projects\n* Club video management project\n* Links:*\n<a href= HTTPs://github. <img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\nProjects outside of University 3️⃣\nCora website project: Order allocation\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_takhsissefaresh Project <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* Web crawler*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_webcrawler project <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* 1 Library Management Graphic Project in Python*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_library Managementpythongui <img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n*2 Library Management Graphic Projects in Java*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_library Managementjavagui\"<img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Robot from the University Computer Association\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_cesku<img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Managing Channel Posts\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_manager\"<img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Personal Robot\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_myjeyran <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n\n4th semester\n\nAdvanced Programming 2\n\n## 📚 Teaching\n* Advanced Algorithmic Questions »\n* language of C++*\n* Computer graphics support*\n\n##60 projects\n* Telephone Book Project with C++*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_phoneappcpp <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* The Adamic Design Project is the path with Directx 9 (Manage Design and Walking)\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_directxhumanwalkerdetailed environmental project <img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## Lessons from Data Buildings\n\n## 📚 Teaching\n* Types of Data Buildings and Applications\n\n##60 projects\n* The Telephone Book Project with Pabton\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_phoneapppython <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\nProjects outside of University 4️⃣\n* Library Management Graphic Project with Python and pyqt5*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_library Managementpythongui <img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n* Food booking system and real estate consultant system with Java*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_pythonfoodreservationys-realstatesys <img src=\" HTTP://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* Chess game project with Java*\n* Links:*\n<a href= HTTPs://github. <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n\nThe 5th semester\n\n## Computer graphics lesson\n\n## 📚 Teaching\n* Graduate and Advanced Computer Graphics »\n\n##60 projects\n* The Human Design Project is the Way by Directx 9*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_directxhumanwalkerdetailed environmental project <img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n• Lessons from the Logical Circuit Laboratory and Computer Architecture\n\n## 📚 Teaching\n* The practical effect of logical circuits\n* The practical impact of computer architecture*\n*Proteus software training*\n\n##60 projects\nAll projects and assignments\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_communications Computerarchitecturelab\"><img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## The Computer Association\n\n##60 projects\n* Open the Design of the Association »\n* The gathering of articles and writing several seasons of the journal*\n\n\nProjects outside the University of 5️⃣\n* Project with Princeton Graphic Libraries\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_princetonpythonlibariesrgui Problems <img src=\" HTTP://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* An almost functional project with genetic programming*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_geneticprogramming form preimimation <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* The decision tree implementation project to diagnose diabetes*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_decisiontreesinpythonpredictingdiabetes\"<img src=\" HTTP://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* The binary category project of support machines\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_pythonsupportvector machinesbinaryclassification <img src=\" HTTP://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* Advanced calculator project using a limited state machine and a stack machine\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_calculatorfsm-pda\"><img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n* Antlr4 »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_compilerdesignantlicon<img src=\" HTTPskills. dev/icons?i=github & Integrat=dark”=25”\n\n\n\n#6 semester\n\n## The design lesson of algorithms\n\n## 📚 Teaching\n* The addition of algorithms*\n\n##60 projects\n* Projects taught in this course in Java and graphically [5 projects]\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_javaalgorithmdesign problem solvingrs\"<img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## Lessons from Computer Networks\n\n## 📚 Teaching\n* Network and Internet »\n\n##60 projects\n* The same messaging app project as <\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_peertopeermessagingapp>img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## The lesson and the language of the name\n\n## 📚 Teaching\n· · “The microprocessor.”\n* Stm32 and hal*\n* Training projects with stm32f103c8t6*\nStm32cubemx*\n* Kil* Software Training »\n\n##60 projects\nMicroprojects stm32f103c8t6*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_stm32microprocessor Projects*<img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## Apprenticeship lesson\n\n##60 projects\nIntroduction to 3d Games Programming with Directx 12 with latex »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/introductionto3dgameprogrammingwithdirectx12\"><img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\nProjects outside the University of 6️⃣\n* Library Data Project with Col*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_librarydatabasesql<img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* The antivirus system project is based on the longest implementation of common subtypes*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_antivirussystem longestcommonsubbusing\"><img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* A repository project to solve the questions of Kora*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/querasolutions <img src=\"s://skillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Finding projects created in Telegram groups and channels\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_job <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Deming in Bluebank*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_bb2h <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Finding new proxies on Telegram channels\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_proxy <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: Recall dates\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_temers <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n\n7th semester\n\n## The lesson of the microprocessor lab\n\n## 📚 Teaching\n* The practical support of the microprocessor\n* Stm32 and hal’s practical training with the educational board*\n* Training projects with stm32f407vg*\nStm32cubeide*\n* Hercules*\n\n##60 projects\n* A resume design project with latex »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/latex-resume-template <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* My design project with stm32*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_stm32menuprogramlcd2x16\"><img src=\" HTTP://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* RGB display project with color selection in lcd 2x16*\n* The project receives the password and display of solar history in lcd 2x16*\n* The LED Light Control Project with plummetometers and displays its value on lcd 2x16*\n* The Project for the Displaying of RGB Color and Sending History and Color Name*\n* The project receives the family name and separate them and blink the LED »\n* Projecting the amount of temperature and humidity and its display on lcd 2x16*\n* The project receives its name and display on rgb*\n\n\n## AI Lessons\n\n## 📚 Teaching\n* AI and algorithms »\n\n##60 projects\n* The standard game project with the Min Max algorithm*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_tictactopmaxalgorithm\"<img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## Lessons from Computer Networks Laboratory\n\n## 📚 Teaching\ncisco packet trace tracer*\n\n##60 projects\ncisco packet trace tracking tracer*\n****\n\n## Internet Engineering Lessons\n\n## 📚 Teaching\n* The total internet content\n* language training of PHP*\n* WordPress and Elementor »\n* xampp* software training\n\n##60 projects\n* Educational websites and stores[3]\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_internetengineeringwebsitephp\"><img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## Lessons from Data mining\n\n## 📚 Teaching\n* Primary Data mining »\n\n##60 projects\n* Data mining project stackoverflow »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_dataminning stackoverflow project <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\nProjects outside of University 7️⃣\n* Internet Engineering Project Socket »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_socketprogramminginternetengineing\"><img src=\" HTTPs://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* A hidden project*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_steganography Image Project <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* Telegram Robot Project: Post\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_channelposting <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n* undergraduate and doctoral projects of materials and metallurgy engineering, computer engineering, civil engineering and psychology*\n\n\n\n#8 semester\n\nLessons from Singles and Systems\n\n## 📚 Teaching\n* Signals and Systems »\n\n##60 projects\n* Down Project Hacking System Signal\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_downsamplingsignalsystem project <img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## Lessons on Information Recovery\n\n## 📚 Teaching\n* The information retrieval\n\n##60 projects\n* Search engine project retrieval information*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_search engine informationretrieval project <img src=\" HTTPs://killicons. dev/icons?i=github & Integrat=dark”=25”\n\n\n## The Master of Project\n\n##60 projects\n* Online shopping website with 3d goods »\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/ws__shonline_shop\"><img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n\n\nProjects outside the University of 8️⃣\n* The real estate management system project with qt*\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/uni_ethionalsystemqt <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\nTelegram Robot Project: The Robotic Nuclear\n* Links:*\n<a href= HTTPs://github. com/bestmahdi2/tb_core\"><img src=\"s://skillicons. dev/icons?i=github & Integrat=dark”=25”\n* The revenue sharing project of Telegram channels\n* Links:*\n<a href= HTTPs://github. <img src=\" HTTPskillicons. dev/icons?i=github & Integrat=dark”=25”\n</div>\n",
    "readme_before": "# <img src=\"https://raw.githubusercontent.com/tarikul-islam-anik/animated-fluent-emojis/master/emojis/people/man%20student.png\" alt=\"man student\" width=\"45\"/> my bachelor's path | مسیر کارشناسی من\r\n\r\n**a repository of complete information on computer engineering courses and projects along with project links**\r\n\r\n<div dir=\"rtl\">\r\n  \r\n**یک ریپوزیتوری از اطلاعات کامل دروس و پروژه‌های دوره کارشناسی مهندسی کامپیوتر به همراه لینک پروژه‌ها**\r\n\r\n## فهرست\r\n- [اطلاعات کلی](#اطلاعات-کلی)\r\n- [لیست کارها](#لیست-کارها)\r\n- [نکات](#نکات)\r\n- [ترم‌ها](#ترم-1️⃣)\r\n  - [ترم 1️⃣](#ترم-1️⃣)\r\n    - [کارگاه کامپیوتر](#درس-کارگاه-کامپیوتر)\r\n    - [پروژه‌های خارج از دانشگاه 1️⃣](#پروژههای-خارج-از-دانشگاه-1️⃣)\r\n  - [ترم 2️⃣](#ترم-2️⃣)\r\n    - [مبانی کامپیوتر و برنامه‌سازی](#درس-مبانی-کامپیوتر-و-برنامهسازی)\r\n    - [پروژه‌های خارج از دانشگاه 2️⃣](#پروژههای-خارج-از-دانشگاه-2️⃣)\r\n  - [ترم 3️⃣](#ترم-3️⃣)\r\n    - [برنامه‌سازی پیشرفته ۱](#درس-برنامهسازی-پیشرفته-۱)\r\n    - [پروژه‌های خارج از دانشگاه 3️⃣](#پروژههای-خارج-از-دانشگاه-3️⃣)\r\n  - [ترم 4️⃣](#ترم-4️⃣)\r\n    - [برنامه‌نویسی پیشرفته ۲](#درس-برنامهنویسی-پیشرفته-۲)\r\n    - [ساختمان‌های داده](#درس-ساختمانهای-داده)\r\n    - [پروژه‌های خارج از دانشگاه 4️⃣](#پروژههای-خارج-از-دانشگاه-4️⃣)\r\n  - [ترم 5️⃣](#ترم-5️⃣)\r\n    - [گرافیک کامپیوتری](#درس-گرافیک-کامپیوتری)\r\n    - [آزمایشگاه مدارهای منطقی و معماری کامپیوتر](#درس-آزمایشگاه-مدارهای-منطقی-و-معماری-کامپیوتر)\r\n    - [انجمن کامپیوتر](#انجمن-کامپیوتر)\r\n    - [پروژه‌های خارج از دانشگاه 5️⃣](#پروژههای-خارج-از-دانشگاه-5️⃣)\r\n  - [ترم 6️⃣](#ترم-6️⃣)\r\n    - [طراحی الگوریتم‌ها](#درس-طراحی-الگوریتمها)\r\n    - [شبکه‌های کامپیوتری](#درس-شبکههای-کامپیوتری)\r\n    - [ریزپردازنده و زبان اسمبلی](#درس-ریزپردازنده-و-زبان-اسمبلی)\r\n    - [کارآموزی](#درس-کارآموزی)\r\n    - [پروژه‌های خارج از دانشگاه 6️⃣](#پروژههای-خارج-از-دانشگاه-6️⃣)\r\n  - [ترم 7️⃣](#ترم-7️⃣)\r\n    - [آزمایشگاه ریزپردازنده](#درس-آزمایشگاه-ریزپردازنده)\r\n    - [هوش مصنوعی](#درس-هوش-مصنوعی)\r\n    - [آزمایشگاه شبکه‌های کامپیوتری](#درس-آزمایشگاه-شبکههای-کامپیوتری)\r\n    - [مهندسی اینترنت](#درس-مهندسی-اینترنت)\r\n    - [مبانی داده‌کاوی](#درس-مبانی-دادهکاوی)\r\n    - [پروژه‌های خارج از دانشگاه 7️⃣](#پروژههای-خارج-از-دانشگاه-7️⃣)\r\n  - [ترم 8️⃣](#ترم-8️⃣)\r\n    - [سینگال‌ها و سیستم‌ها](#درس-سینگالها-و-سیستمها)\r\n    - [مبانی بازیابی اطلاعات](#درس-مبانی-بازیابی-اطلاعات)\r\n    - [پروژه کارشناسی](#درس-پروژه-کارشناسی)\r\n    - [پروژه‌های خارج از دانشگاه 8️⃣](#پروژههای-خارج-از-دانشگاه-8️⃣)\r\n    \r\n## اطلاعات کلی\r\n\r\n**تعداد پروژه‌ها:**\r\n[![github](https://img.shields.io/badge/projects-+200-blue)]()\r\n\r\n**تعداد ساعت:**\r\n[![github](https://img.shields.io/badge/hours-+10000-blue)]()\r\n\r\n**تعداد خط کد:**\r\n[![github](https://img.shields.io/badge/lines%20of%20code-+400000-blue)]()\r\n\r\n## لیست کارها\r\n- [x] ![](https://geps.dev/progress/100) **دوره کارشناسی دانشگاه**\r\n- [x] ![](https://geps.dev/progress/100) **بررسی و جمع‌آوری پروژه‌ها**\r\n- [x] ![](https://geps.dev/progress/100) **دسته‌بندی و کنترل ورژن پروژه‌ها**\r\n- [x] ![](https://geps.dev/progress/100) **آپلود پروژه‌ها روی گیت‌هاب**\r\n- [ ] ![](https://geps.dev/progress/50) **داکیومنت‌نویسی پروژه‌ها**\r\n- [ ] ![](https://geps.dev/progress/20) **بررسی و بهبود پروژه‌ها**\r\n\r\n## نکات\r\n* **ریپوزیتوری بعضی از پروژه‌ها ممکن است آرشیو یا حذف شده باشند.**\r\n* **ریپوزیتوری بعضی از پروژه‌ها ممکن است از حالت عمومی به حالت خصوصی درآمده باشند.**\r\n* **فایل‌های بعضی از پروژه‌ها روی گیت‌هاب قرار ندارند.**\r\n* **تنها دروسی از دوره کارشناسی که دارای پروژه بودند در این ریپوزیتوری قرار دارند.**\r\n* **پروژه‌های خارج از دوره کارشناسی و به صورت فریلنسری با نام \"پروژه‌های خارج از دانشگاه\" در هر ترم قرار دارند.**\r\n\r\n---\r\n\r\n#  ترم 1️⃣\r\n\r\n## درس کارگاه کامپیوتر\r\n\r\n### 📚 تدریس\r\n* **مباحث html و css**\r\n* **مباحث icdl**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **طراحی انواع داکیومنت**\r\n* **طراحی یک صفحه‌ی ساده html و دیزاین با css**\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 1️⃣\r\n* **مقایسه فالوور و فالوینگ‌های اکانت اینستاگرام و پیدا کردن تکراری‌های آن**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/duplicated_followers_followings\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **محاسبه کل زمان تماشای فیلم‌های یک دوره‌ آموزشی**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/videolength\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **محاسبه و دسته‌بندی عکس‌ها با استفاده از resolution آن‌ها**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/picture_resolution\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **ساخت پسورد لیست**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/passwordlistcreator\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n\r\n# ترم 2️⃣\r\n\r\n## درس مبانی کامپیوتر و برنامه‌سازی\r\n\r\n### 📚 تدریس\r\n* **مباحث فلوچارت و سوالات الگوریتمی ساده**\r\n* **زبان پایتون**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه سیستم مدیریت مخاطبین (cms) [۱۱ پروژه]**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__contactmanagementsystem\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 2️⃣\r\n* **سوالات و پروژه‌های fortran**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__fortranproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه jeyran enigma**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/jeyranenigma\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه دیبتایس لیک‌شده‌ی تلگرام**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/telegramleakdatabase_iranianusers\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: پیدا کردن لینک‌های دوره‌های رایگان وب‌سایت ‌udemy**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__udemycoursecrawler\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه اپلیکیشن موبایل با kiwi**\r\n\r\n\r\n\r\n# ترم 3️⃣\r\n\r\n## درس برنامه‌سازی پیشرفته ۱\r\n\r\n### 📚 تدریس\r\n* **مسوالات الگوریتمی پیشرفته‌تر**\r\n* **زبان جاوا و شئ‌گرایی**\r\n* **داکیومنت‌نویسی و کامنت‌گذاری**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه سیستم مدیریت ویدیو کلوپ**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__videoclubmanagementjava\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 3️⃣\r\n* **پروژه وبسایت کوئرا: تخصیص سفارش**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__takhsissefareshproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه instagram web crawler**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__webcrawlerproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **۱ پروژه گرافیکی مدیریت کتابخانه به زبان پایتون**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__librarymanagementpythongui\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **۲ پروژه گرافیکی مدیریت کتابخانه به زبان جاوا**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__librarymanagementjavagui\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: ربات انجمن کامپیوتر دانشگاه شهرکرد**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__cesku\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: مدیریت پست‌گذاری کانال**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__masterchannelmanager\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: ربات شخصی**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__myjeyran\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n\r\n# ترم 4️⃣\r\n\r\n## درس برنامه‌نویسی پیشرفته ۲\r\n\r\n### 📚 تدریس\r\n* **مسوالات الگوریتمی پیشرفته‌تر**\r\n* **زبان ++c**\r\n* **مبانی گرافیک کامپیوتری**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه دفترچه تلفن با ++c**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__phonebookappcpp\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه طراحی آدمک راه‌رونده با directx 9 (بخش طراحی آدمک و راه‌رفتن)**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__directxhumanwalkerdetailedenvironmentproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس ساختمان‌های داده\r\n\r\n### 📚 تدریس\r\n* **انواع ساختمان‌های داده و کاربردهای آن‌ها**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه دفترچه تلفن با پابتون**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__phonebookapppython\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 4️⃣\r\n* **پروژه گرافیکی مدیریت کتابخانه با پایتون و ‌pyqt5**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__librarymanagementpythongui\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه سیستم رزرو غذا و سیستم مشاور املاک با جاوا**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__pythonfoodreservationsys-realstatesys\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه بازی شطرنج با جاوا**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__javachessboardgame\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n\r\n# ترم 5️⃣\r\n\r\n## درس گرافیک کامپیوتری\r\n\r\n### 📚 تدریس\r\n* **مباحث تکمیلی و پیشرفته گرافیک کامپیوتری**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه طراحی آدمک راه‌رونده با directx 9**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__directxhumanwalkerdetailedenvironmentproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس آزمایشگاه مدارهای منطقی و معماری کامپیوتر\r\n\r\n### 📚 تدریس\r\n* **مباحث عملی مدارهای منطقی**\r\n* **مباحث عملی معماری کامپیوتر**\r\n* **آموزش نرم‌افزار proteus**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **تمامی پروژه‌ها و تکالیف**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__logiccircuitscomputerarchitecturelab\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## انجمن کامپیوتر\r\n\r\n### ⌨️ پروژه‌ها\r\n* **بازطراحی بخش‌های نشریه انجمن**\r\n* **جمع‌آوری مطالب و نوشتن چندین فصل از نشریه**\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 5️⃣\r\n* **پروژه با کتابخانه‌های گرافیکی پرینستون**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__princetonpythonlibrariesguiproblems\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه تقریب تابع با برنامه‌نویسی ژنتیک**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__geneticprogrammingfunctionapproximation\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه پیاده‌سازی درخت تصمیم برای تشخیص دیابت**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__decisiontreesinpythonpredictingdiabetes\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه دسته‌بندی باینری ماشین‌های برداری پشتیبانی**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__pythonsupportvectormachinesbinaryclassification\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ماشین حساب پیشرفته با استفاده از ماشین حالت محدود و ماشین پشته‌ای**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__advancedcalculatorfsm-pda\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه طراحی کامپایلر antlr4**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__compilerdesignantlr4\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n\r\n# ترم 6️⃣\r\n\r\n## درس طراحی الگوریتم‌ها\r\n\r\n### 📚 تدریس\r\n* **مباحث تکمیلی الگوریتم‌ها**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه‌های تدریس‌شده در این درس با زبان جاوا و به صورت گرافیکی [۵ پروژه]**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__javaalgorithmdesignproblemsolvers\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس شبکه‌های کامپیوتری\r\n\r\n### 📚 تدریس\r\n* **مباحث شبکه و اینترنت**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه برنامه پیام‌رسان همتا به همتا**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__peertopeermessagingapp\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس ریزپردازنده و زبان اسمبلی\r\n\r\n### 📚 تدریس\r\n* **مبانی ریزپردازنده**\r\n* **آموزش کلی stm32 و hal**\r\n* **آموزش پروژه‌ها با stm32f103c8t6**\r\n* **آموزش نرم‌افزار stm32cubemx**\r\n* **آموزش نرم‌افزار keil**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه‌های میکروپروسسور stm32f103c8t6**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__stm32microprocessorprojects\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس کارآموزی\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه ترجمه و نوشتن کتاب introduction to 3d game programming with directx 12 با latex**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/introductionto3dgameprogrammingwithdirectx12\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 6️⃣\r\n* **پروژه دیتابیس کتابخانه با sql**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__librarydatabasesql\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه سیستم آنتی‌ویروس بر اساس طولانی‌ترین تطبیق زیر رشته‌های رایج**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__antivirussystemlongestcommonsubstringmatching\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه یک مخزن برای حل سوال های سایت کوئرا**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/querasolutions\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: پیدا کردن پروژه‌های ایجاد شده در گروه و کانال‌های تلگرام**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__jobfinder\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: شبیه‌سازی دُنگ در اپلیکیشن بلوبانک**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__bb2h\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: پیدا کردن پروکسی‌های تازه در کانال‌های تلگرام**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__proxyfinder\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: یادآوری تاریخ‌ها**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__temers\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n\r\n# ترم 7️⃣\r\n\r\n## درس آزمایشگاه ریزپردازنده\r\n\r\n### 📚 تدریس\r\n* **مبانی عملی ریزپردازنده**\r\n* **آموزش عملی stm32 و hal با برد آموزشی**\r\n* **آموزش پروژه‌ها با stm32f407vg**\r\n* **آموزش نرم‌افزار stm32cubeide**\r\n* **آموزش نرم‌افزار hercules**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه طراحی رزومه با latex**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/latex-resume-template\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه طراحی برنامه‌ی منو با stm32**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__stm32menudesignprogramlcd2x16\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه نمایش rgb با انتخاب رنگ در lcd 2x16**\r\n* **پروژه دریافت رمز ورود و نمایش تاریخ شمسی در lcd 2x16**\r\n* **پروژه کنترل نور led با پبتانسیومتر و نمایش مقدار آن روی lcd 2x16**\r\n* **پروژه نمایش رنگ‌های متخلف rgb و فرستادن تاریخ و نام رنگ**\r\n* **پروژه دریافت نام-نام‌خانوادگی و جدا کردن آن‌ها و چشمک زدن led**\r\n* **پروژه فرستادن مقدار دما و رطوبت و نمایش آن روی lcd 2x16**\r\n* **پروژه دریافت نام رنگ و نمایش آن روی rgb**\r\n\r\n\r\n## درس هوش مصنوعی\r\n\r\n### 📚 تدریس\r\n* **مباحث هوش مصنوعی و الگوریتم‌ها**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه بازی دوز با الگوریتم مین ماکس**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__tictactoeminimaxalgorithm\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس آزمایشگاه شبکه‌های کامپیوتری\r\n\r\n### 📚 تدریس\r\n* **آموزش نرم‌افزار cisco packet tracer**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه طراحی خانه‌ی هوشمند با نرم‌افزار cisco packet tracer**\r\n* \r\n\r\n## درس مهندسی اینترنت\r\n\r\n### 📚 تدریس\r\n* **مباحث کلی اینترنت**\r\n* **آموزش زبان php**\r\n* **آموزش wordpress و elementor**\r\n* **آموزش نرم‌افزار xampp**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه‌های وب‌سایت‌های آموزشی و فروشگاهی [۳ پروژه]**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__internetengineeringwebsitephp\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس مبانی داده‌کاوی\r\n\r\n### 📚 تدریس\r\n* **مباحث اولیه داده‌کاوی**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه داده‌کاوی وب‌سایت stackoverflow**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__dataminningstackoverflowproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## پروژه‌های خارج از دانشگاه 7️⃣\r\n* **پروژه مهندسی اینترنت برنامه‌نویسی سوکت**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__socketprogramminginternetengineering\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه نهان‌نگاری**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__steganographyimageproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: پست‌گذار**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__channelposting\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه‌های کارشناسی و داکیومنت رشته‌های مهندسی مواد و متالورژی، مهندسی کامپیوتر، مهندسی عمران و روانشناسی**\r\n\r\n\r\n\r\n# ترم 8️⃣\r\n\r\n## درس سینگال‌ها و سیستم‌ها\r\n\r\n### 📚 تدریس\r\n* **مباحث سیگنال‌ها و سیستم‌ها**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه داون سمپلینگ سیگنال سیستم**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__downsamplingsignalsystemproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس مبانی بازیابی اطلاعات\r\n\r\n### 📚 تدریس\r\n* **مباحث بازیابی اطلاعات**\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه موتور جستجو بازیابی اطلاعات**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__searchengineinformationretrievalproject\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n## درس پروژه کارشناسی\r\n\r\n### ⌨️ پروژه‌ها\r\n* **پروژه وب‌سایت فروشگاهی آنلاین با قابلیت نمایش 3d کالا‌‌ها**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/ws__shonline_online_shop\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n\r\n\r\n##  پروژه‌های خارج از دانشگاه 8️⃣\r\n* **پروژه سیستم مدیریت املاک با qt**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/uni__realestatemanagementsystemqt\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه ربات تلگرام: هسته ربات**\r\n   * **لینک‌ها:** \r\n     <a href=\"https://github.com/bestmahdi2/tb__core\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n* **پروژه تقسیم درآمدهای کانال‌های تلگرام**\r\n   * **لینک‌ها:**\r\n     <a href=\"https://github.com/bestmahdi2/yotta_moghasem\"><img src=\"https://skillicons.dev/icons?i=github&theme=dark\" width=\"25\" alt=\"github repository link\" title=\"click for more information\"></a>\r\n</div>\r\n"
  },
  {
    "readme": "# tcc-ufsm-2020\n**(en-us)**this is the repository for my bachelor's degree final project at [ufsm](https://www.ufsm.br/): a game\nprototype made to explore the entity-component-system (ecs) architecture and procedural dungeon generation.\nwhile the game is not full playable at the moment, it\nFulfills my expectations. a more professional development will occur independently in another\nRepository, after my graduation.\n\n**(en)**this is the repository of my course completion work (tcc) at [ufsm](https://www.ufsm.br/): a\nprototype game designed to explore the *entity-component-system* (ecs) and\nprocedural generation of *dungeons*.\nAlthough the game is not fully playable (or even fun) at the moment,\nHe meets my expectations. further development will occur independently\nin another repository, after my graduation.\n\n![in-game screen.](screenshot.png)\n\n# Wait! i read your article from sbgames 2020! Where do i go?\n[/src/map_gen/](https://github.com/pprobst/tcc-ufsm2020/tree/master/src/map_gen) contents all the algorithms presented in the article. they're\ngenerally easy to follow, but for fully understanding wavefunctioncollapse it\nwould be wise to read gridbugs' [article](https://gridbugs.org/wave-function-collapse/) (my implementation directly derives from it) or karth & smith [research paper](https://adamsmith.as/papers/wfc_is_constraint_solving_in_the_wild.pdf).\nkeep in mind that the procgen pipelines are still far from perfect, and i'll\nstill keep working on them. i'm also working on the general game mechanics and\nin the future i'll play with procedural narrative -- a new interest for me.\n\nhowever, this is a game prototype (not a procedural dungeon generation tool!) and still not ready for playing. but if\nYou know your way around rust and want to fiddle with the procgen algorithms,\nFeel free to do it!\n\nif you want to contact me for whatever reason, send me an email. you can use the email on my github\nprofile or the one in the paper.\n\n# Execution\nfirst, [install and configure rush in your machine](https://doc.rust-lang.org/book/ch01-01-installation.html).\n\nthen, clone this repository, navigate to it and run ```load run```` from your terminal emulator.\n\nTell me if you have any problems.\n\nwhile in-game:\n- use the vi-keys to move or select targets.\n- space for contextual action (e.g. open doors).\n- 'i' to access inventory.\n- 'e' to access equipment.\n- 'z' to switch between melee/ranged weapons.\n- 'f' to target and fire.\n- 'r' to reload.\n\n---\n\n# Main goals (tcc)\nor, _\"it would be good if I did all that!_\". Priority order, sort of.\n- [x] structure the basics of [bracket-lib](https://github.com/thebracket/bracket-lib)\n(rltk) + [specs](https://github.com/amethyst/specs/), using the tutorial developed by wolferson as a basis;\n- [x] player movement @;\n- [x] basic structure of a map;\n- [x] separate file for rendering the map and entities;\n- [x] fov system (_field-of-view_);\n- [x] camera/viewport (divergences begin here);\n- [x] implement a basic ui and take advantage to improve the game states;\n- [x] mobs and basic structure of the combat system;\n- [x] some constructive methods of map generation:\n- [x] random walkers;\n- [x] cellular automata (ca);\n- [x] ensure connectivity.\n- [x] bsp (binary space partitioning) dungeons;\n- [x] diggers/tunnelers.\n- [x] Final touches.\n- [x] hybrid map generation system (pipeline) using\n[wfc](https://github.com/mxgmn/wavefunctioncollapse) together with other algorithms;\n- [x] load external map manually drawn;\n- [x] apply wfc on the current map;\n- [x] ensure connectivity by the flood-fill method (ca);\n- [x] insertion of prefabricated structures into the map;\n- [x] different themes of maps:\n- [x] tdcl (top-down basement-like);\n- [x] tdml (top-down mansion-like);\n- [x] forests;\n- [x] ruins;\n- [x] wfc as external/internal architecture.\n- [x] inventory and consumption of items;\n- [x] equipment;\n- [x] treasure chests;\n- [x] selection of regions on the map to apply generation algorithms;\n- [x] use [ron](https://github.com/ron-rs/ron) (not json) to structure the raws;\n- [x] basic serialization/deserialization system using ron +\nserde for mobs, items and colors.\n\nOf course, as I develop, I may have to\nchange/enhance already marked checklist items. this is a natural process;\nconsider that marked items already have the _basic structure_ completed.\n\n# Known problems, etc.\n- the spawning system is far from adequate.\n- distortion of the tiles depending on the resolution.\n- some crashes occur from time to time in the stage of map generation.\n- probable cause: access to map index 0 (not used).\n- for now, wfc does not restart when there is contradiction (rare of occurrence).\n\n# Contributions #\nif you have any good idea or suggestion, feel free to open a\n[_issue_](https://github.com/pprobst/tcc-ufsm2020/issues/new).\n\n# References and inspirations\nLook at my monograph file for the reference list. other github projects they had\nportions of code used (or that served as the basis for something) are referenced in the form of comments in the relevant source files.\n",
    "readme_before": "# tcc-ufsm-2020\n**(en-us)** this is the repository for my bachelor's degree final project at [ufsm](https://www.ufsm.br/): a game\nprototype made to explore the entity-component-system (ecs) architecture and procedural dungeon generation.\nwhile the game is not fully playable (or even enjoyable) at the moment, it\nfulfills my expectations. a more profound development will occur independently in another\nrepository, after my graduation.\n\n**(pt-br)** este é o repositório do meu trabalho de conclusão de curso (tcc) na [ufsm](https://www.ufsm.br/): um\nprotótipo de jogo elaborado para explorar a arquitetura *entity-component-system* (ecs) e\ngeração procedural de *dungeons*.\nembora o jogo não seja totalmente jogável (ou mesmo divertido) no momento,\nele cumpre minhas expectativas. um desenvolvimento mais aprofundado ocorrerá de forma independente\nem outro repositório, após a minha graduação.\n\n![in-game screen.](screenshot.png)\n\n## wait! i read your article from sbgames 2020! where do i go?\n[/src/map_gen/](https://github.com/pprobst/tcc-ufsm-2020/tree/master/src/map_gen) contains all the algorithms presented in the article. they're\ngenerally easy to follow, but for fully understanding wavefunctioncollapse it\nwould be wise to read gridbugs' [article](https://gridbugs.org/wave-function-collapse/) (my implementation directly derives from it) or karth & smith [research paper](https://adamsmith.as/papers/wfc_is_constraint_solving_in_the_wild.pdf).\nkeep in mind that the procgen pipelines are still far from perfect, and i'll\nstill keep working on them. i'm also working on the general game mechanics and\nin the future i'll play with procedural narrative -- a new interest for me.\n\nhowever, this is a game prototype (not a procedural dungeon generation tool!) and still not ready for playing. but if\nyou know your way around rust and want to fiddle with the procgen algorithms,\nfeel free to do it!\n\nif you want to contact me for whatever reason, send me an email. you can use the email on my github\nprofile or the one in the paper.\n\n## execution\nfirst, [install and configure rust in your machine](https://doc.rust-lang.org/book/ch01-01-installation.html).\n\nthen, clone this repository, navigate to it and run ```cargo run``` from your terminal emulator.\n\ntell me if you have any problems.\n\nwhile in-game:\n- use the vi-keys to move or select targets.\n- space for contextual action (e.g. open doors).\n- 'i' to access inventory.\n- 'e' to access equipment.\n- 'z' to switch between melee/ranged weapons.\n- 'f' to target and fire.\n- 'r' to reload.\n\n---\n\n## objetivos principais (tcc)\nou, _\"seria bom se eu fizesse tudo isso!_\". ordem de prioridade, mais ou menos.\n- [x] estruturar o básico do básico do [bracket-lib](https://github.com/thebracket/bracket-lib) \n  (rltk) + [specs](https://github.com/amethyst/specs/), utilizando o tutorial desenvolvido por wolverson como base;\n- [x] movimento do jogador @;\n- [x] estrutura básica de um mapa;\n- [x] arquivo separado para a renderização do mapa e das entidades;\n- [x] sistema de fov (_field-of-view_);\n- [x] câmera/viewport (divergências começam aqui);\n- [x] implementar uma ui básica e aproveitar para aprimorar os estados de jogo (game states);\n- [x] mobs e estrutura básica do sistema de combate;\n- [x] alguns métodos construtivos de geração de mapas:\n    - [x] random walkers;\n    - [x] cellular automata (ca);\n        - [x] assegurar conectividade.\n    - [x] bsp (binary space partitioning) dungeons;\n    - [x] diggers/tunnelers.\n        - [x] retoques finais.\n- [x] sistema de geração de mapas (pipeline) híbrido utilizando\n  [wfc](https://github.com/mxgmn/wavefunctioncollapse) em conjunto com outros algoritmos;\n  - [x] carregar mapa externo desenhado manualmente;\n  - [x] aplicar wfc sobre o mapa atual;\n  - [x] assegurar conectividade pelo método do flood-fill (ca);\n- [x] inserção de estruturas pré-fabricadas no mapa;\n- [x] temáticas diferentes de mapas:\n    - [x] tdcl (top-down cavern-like);\n    - [x] tdml (top-down mansion-like);\n    - [x] florestas;\n    - [x] ruínas;\n    - [x] wfc como arquitetura externa/interna.\n- [x] inventário e consumo de itens;\n- [x] equipamento;\n- [x] baús de tesouro;\n- [x] seleção de regiões no mapa para aplicar algoritmos de geração;\n- [x] usar [ron](https://github.com/ron-rs/ron) (e não json) para estruturar os raws;\n- [x] sistema de serialização/desserialização básico usando ron +\n  serde para mobs, itens e cores.\n\nnaturalmente, à medida que vou desenvolvendo posso ter de \nalterar/aprimorar itens da checklist já marcados. isso é um processo natural;\nconsidere que itens marcados já possuem a _estrutura básica_ concluída. \n\n## problemas conhecidos, etc.\n- o sistema de spawning está longe do adequado.\n- distorção dos tiles dependendo da resolução.\n- alguns crashes ocorrem de vez em quando na etapa de geração de mapas.\n    - causa provável: acesso ao índice 0 do mapa (não utilizado).\n- por enquanto, o wfc não reinicia quando há contradição (raro de acontecer). \n\n## contribuições\nse você tiver alguma boa ideia ou sugestão, sinta-se livre para abrir um \n[_issue_](https://github.com/pprobst/tcc-ufsm-2020/issues/new).\n\n## referências e inspirações\nveja o arquivo da minha monografia para a lista de referências. outros projetos do github que tiveram\nporções de código utilizadas (ou que serviram de base para algo) estão referenciados em forma de comentários nos arquivos de código relevantes.\n"
  },
  {
    "readme": "# degree in computer engineering and computer science\n\n![](./image_banner.png)\n\n# Contents\n\n# First year\n\nFirst semester\n\n- linear algebra and analytical geometry - not available\n- [calculation i](./year_1_semester_1/calculation_1) - updated 2022/2023\n- [programming foundations](./year_1_semester_1/programming_foundations) - updated in 2021/2022\n- [introduction to computer engineering](./year_1_semester_1/introduction_a_engineering_informatica) - updated 2021/2022\n- introduction to digital systems - not available\n\n2nd semester\n\n- [calculation ii](./year_1_semester_2/calculation_2) - updated 2021/2022\n- [digital system laboratory](./year_1_semester_2/digital system laboratory) - updated in 2021/2022\n- [computer laboratories](./year_1_semester_2/laboratorios_de_formatica) - updated in 2021/2022\n- discrete mathematics - not available\n- [object-oriented programming](./year_1_semester_2/_oriented_a_objects programming) - updated in 2021/2022\n\n# 2nd year\n\nFirst semester\n\n- [data structures and algorithms](./year_2_semester_1/algorithms_e_data structures) - updated in 2022/2023\n- [computer architecture i](./year_2_semester_1/architecture_of_computers_1) - updated on 2022/2023\n- transferable skills i\n- [design thinking](./year_2_semester_1/design_thinking) - updated on 2022/2023\n- economy i - not available\n- [entrepreneurship and new business](./year_2_semester_1/entrepreneurship_e_new_negocios) - updated 2022/2023\n- business finance - not available\n- [project management](./year_2_semester_1/project management) - updated 2022/2023\n- communication techniques and presentations - not available\n- [mechanics and electromagnetic field](./year_2_semester_1/mechanic_e_field_electromagnetic) - updated 2022/2023\n- [communication networks i](./year_2_semester_1/communications_networks_1) - updated 2022/2023\n\n2nd semester\n\n- [system analysis](./year_2_semester_2/system analysis) - updated 2022/2023\n- [computer architecture ii](./year_2_semester_2/architecture_of_computers_2) - updated on 2022/2023\n- transferable skills ii\n- [renewable energy](./year_2_semester_2/renewable energy) - updated 2022/2023\n- additive manufacture and 3d printing - not available\n- human-computer interaction - not available\n- introduction to finite element method - not available\n- operational research - not available\n- materials and sustainable development - not available\n- [microcontrollers and interaction with sensors and actuators](./year_2_semester_2/microcontrollators_e_interaction_com_sensors_e_actuators) - updated on 2022/2023\n- sustainable mobility - not available\n- [web programming](./year_2_semester_2/programming_web) - updated 2022/2023\n- data visualization - not available\n- [communication networks ii](./year_2_semester_2/communications_networks_2) - updated 2022/2023\n- [electronic signals and systems](./year_2_semester_2/signals_e_systems_electronics) - updated 2022/2023\n\n# Third grade\n\n- computer engineering and computer design - not available\n\nFirst semester\n\n- artificial intelligence - not available\n- probabilistic methods for computer engineering - not available\n- computer security and organizations - not available\n- operating systems - not available\n\n2nd semester\n\n- databases - not available\n- compilers - not available\n- human-computer interaction - not available\n- option i\n- distributed computing - not available\n- introduction to computer graphics - not available\n- introduction to mobile computing - not available\n- standards and software design - not available\n- technologies and web programming - not available\n\n\n# License\n\n[graduation in computer engineering and computer science](https://github.com/miguelovila/ua-leci), by [miguel villa](https://github.com/miguelovila), is licensed under license [cc0 1.0](license).\n\nThis means that there are no copyrights or related rights to the extent permitted by law. that is, this repository belongs to the public domain. thus, you can copy, modify, distribute and execute the work without asking permission or assign any credits (as far as the work developed by me is concerned).",
    "readme_before": "# licenciatura em engenharia de computadores e informática\n\n![](./image_banner.png)\n\n# conteúdos\n\n## 1º ano\n\n### 1º semestre\n\n- álgebra linear e geometria analítica - não disponível\n- [cálculo i](./ano_1_semestre_1/calculo_1) - atualizado em 2022/2023\n- [fundamentos de programação](./ano_1_semestre_1/fundamentos_de_programacao) - atualizado em 2021/2022\n- [introdução à engenharia informática](./ano_1_semestre_1/introducao_a_engenharia_informatica) - atualizado em 2021/2022\n- introdução aos sistemas digitais - não disponível\n\n### 2º semestre\n\n- [cálculo ii](./ano_1_semestre_2/calculo_2) - atualizado em 2021/2022\n- [laboratorio de sistema digitais](./ano_1_semestre_2/laboratorio_de_sistemas_digitais) - atualizado em 2021/2022\n- [laboratórios de informática](./ano_1_semestre_2/laboratorios_de_informatica) - atualizado em 2021/2022\n- matemática discreta - não disponível\n- [programação orientada a objetos](./ano_1_semestre_2/programacao_orientada_a_objetos) - atualizado em 2021/2022\n\n## 2º ano\n\n### 1º semestre\n\n- [algoritmos e estruturas de dados](./ano_2_semestre_1/algoritmos_e_estruturas_de_dados) - atualizado em 2022/2023\n- [arquitetura de computadores i](./ano_2_semestre_1/arquitetura_de_computadores_1) - atualizado em 2022/2023\n- competências transferíveis i\n    - [design thinking](./ano_2_semestre_1/design_thinking) - atualizado em 2022/2023\n    - economia i - não disponível\n    - [empreendedorismo e novos negócios](./ano_2_semestre_1/empreendedorismo_e_novos_negocios) - atualizado em 2022/2023\n    - finanças empresariais - não disponível\n    - [gestão de projetos](./ano_2_semestre_1/gestao_de_projetos) - atualizado em 2022/2023\n    - técnicas de comunicação e apresentações - não disponível\n- [mecânica e campo eletromagnético](./ano_2_semestre_1/mecanica_e_campo_eletromagnetico) - atualizado em 2022/2023\n- [redes de comunicações i](./ano_2_semestre_1/redes_de_comunicacoes_1) - atualizado em 2022/2023\n\n### 2º semestre\n\n- [análise de sistemas](./ano_2_semestre_2/analise_de_sistemas) - atualizado em 2022/2023\n- [arquitetura de computadores ii](./ano_2_semestre_2/arquitetura_de_computadores_2) - atualizado em 2022/2023\n- competências transferíveis ii\n    - [energias renováveis](./ano_2_semestre_2/energias_renovaveis) - atualizado em 2022/2023\n    - fabrico aditivo e impressão 3d - não disponível\n    - interação humano-computador - não disponível\n    - introdução ao método dos elementos finitos - não disponível\n    - investigação operacional - não disponível\n    - materiais e desenvolvimento sustentável - não disponível\n    - [microcontroladores e interação com sensores e atuadores](./ano_2_semestre_2/microcontrololadores_e_interacao_com_sensores_e_atuadores) - atualizado em 2022/2023\n    - mobilidade sustentável - não disponível\n    - [programação web](./ano_2_semestre_2/programacao_web) - atualizado em 2022/2023\n    - visualização de dados - não disponível\n- [redes de comunicações ii](./ano_2_semestre_2/redes_de_comunicacoes_2) - atualizado em 2022/2023\n- [sinais e sistemas eletrónicos](./ano_2_semestre_2/sinais_e_sistemas_eletronicos) - atualizado em 2022/2023\n\n## 3º ano\n\n- projeto em engenharia de computadores e informática - não disponível\n\n### 1º semestre\n\n- inteligência artificial - não disponível\n- métodos probabilísticos para engenharia informática - não disponível\n- segurança informática e nas organizações - não disponível\n- sistemas de operação - não disponível\n\n### 2º semestre\n\n- bases de dados - não disponível\n- compiladores - não disponível\n- interação humano-computador - não disponível\n- opção i\n    - computação distribuída - não disponível\n    - introdução à computação gráfica - não disponível\n    - introdução à computação móvel - não disponível\n    - padrões e desenho de software - não disponível\n    - tecnologias e programação web - não disponível\n\n\n# licença\n\n[licenciatura em engenharia de computadores e informática](https://github.com/miguelovila/ua-leci), por [miguel vila](https://github.com/miguelovila), está licenciado com a licença [cc0 1.0](license).\n\nisto significa que não existem direitos de autor nem direitos conexos na medida permitida por lei. ou seja, este repositório pertence ao domínio público. assim, podes copiar, modificar, distribuir e executar o trabalho sem pedir autorização ou atribuir quaisquer créditos (no que toca a trabalho desenvolvido por mim)."
  },
  {
    "readme": "# Readme\n* * * I'm sorry *\nAbout\nBenkbik warehouse.\n# Directory Notes\n**reports**: including weekly reports, opening questions, interim reports, defence reports, and pre-defined overall document descriptions\nI'm sorry.\n\n**scripts**: Script used to write documents, useless\n\n**thesis**: source paper for the graduation paper and self-modified thuseis template\n\n**workspace**: Code Folder\n\n\n",
    "readme_before": "# readme\n* * * * *\n## 关于\n本科毕设仓库\n## 目录说明\n**reports**： 包括每周报告，开题、中期、答辩报告，还有毕设的整体文档说明\nusage/usage.pdf。\n\n**scripts**: 写文档时使用的脚本，无用\n\n**thesis**: 毕业论文latex源文件和自己修改过的thuthesis模板\n\n**workspace**: 代码文件夹\n\n\n"
  },
  {
    "readme": "playlingua\n= = = = = = = = =\n\n# summary\n\nThe purpose of this work is to design and develop a web application, called playlingua, to improve the process of learning the language through gamification. We will explore three main aspects: natural language processing technologies (pln), gamification and user-centred design (ucd) as a development methodology. in the pln area, we will choose between the different tools available depending on how they can be applied in the final project. to increase the acceptance of the application, we will study the advantages and positive aspects of using gamification in learning applications and how influential it can be in terms of motivation, commitment, quality of learning and entertainment. all will be developed following the process of the ucd, whose aim is to build applications based on the user experience (ux). In addition, we will study the latest web technologies with the aim of developing an application that will be available to all, online and free.\n\n# abstract\n\nthe purpose of this study is to design and develop a web application, named playlingua, to improve the language learning process through gamification. There are three main aspects to explore: natural language process (nlp) technologies, gamification and user dedicated design (ucd) as a developing methodology. in the nlp area, we will choose between the different available tools depending on how they can be applied in the final project. to increase the acceptance of the application, we will study the advances and positive effects of using gamification in learning applications and how it influences users in terms of motivation, engagement, learning quality and entertainment. everything will be developed following the ucd process, whose goal is to build applications based on user experience (ux). in addition, we will study the latest trending web technologies in order to develop a platform that will be available for everyone, online and free.\n\nLicense\n\n< a rel = \"license\" href = \"http: / / creativecommons.org / licenses / by /\" > \"< img alt =\" creative commons license \"style =\" border-wide: 0 \"src =\" https: / / i.creativemons.org / l / \"by:\" a / a / \":\" / a / a / \"/ a\" / a \":\" / a / \"/ a\" / a \"/\" / a \"/\n\ninstructions\n\n* clone the repo\n\n```\ngit clone https://github.com/elenatorro/playlingua.git\n```\n\n* install npm dependencies\n\n```\n$ npm install\n```\n\n* install bower dependencies\n\n```\nbower install\n```\n\n* configure global configuration variables\n\nyou have a sample in config > variables_sample.js (remove '\\_sample')\n\n## run local\n* run mongodb database (you should have mongodb already installed)\n\n```\n$ sudo mongod\n\n```\n\nin your variables.js file, set 'environment' to 'development'.\n\n* run gulp\n\n```\n$ gulp\n```\n\nnow, open localhost in the port you've chosen. you can build the whole project with:\n\n```\n$ gulp build\n```\n\n\n### deploy\n\n* you'll have to tell your server to run app.js. for heroku it's already setted in the procfile.\n* in your variables.js file, set 'environment' to 'production'.\n\n## future work:\n\n* refactor\n* instructions & tools to build playlingua for another language (it's currently in spanish)\n\nany feedback is very welcome!\n",
    "readme_before": "playlingua\n==========================\n\n#resumen\n\nel propósito de este trabajo es diseñar y desarrollar una aplicación web, llamada playlingua, para mejorar el proceso de aprendizaje de la lengua a través de la gamificación. exploraremos tres aspectos principales: las tecnologías de procesamiento del lenguaje natural (pln), la gamificación y el diseño centrado en el usuario (ucd) como metodología de desarrollo. en el área del pln, elegiremos entre las distintas herramientas disponibles dependiendo de cómo pueden ser aplicadas en el proyecto final. para aumentar la aceptación de la aplicación, estudiaremos las ventajas y los aspectos positivos de usar la gamificación en aplicaciones de aprendizaje y cómo de influyente puede ser en términos de motivación, compromiso, calidad de aprendizaje y entretenimiento. todo será desarrollado siguiendo el proceso del ucd, cuyo objetivo es construir aplicaciones basadas en la experiencia del usuario (ux). además, estudiaremos las últimas tecnologías web con el objetivo de desarrollar una aplicación que estará disponible para todos, online y gratis.\n\n#abstract\n\nthe purpose of this study is to design and develop a web application, named playlingua, to improve the language learning process through gamification. there are three main aspects to explore: natural language process (nlp) technologies, gamification and user centered design (ucd) as a developing methodology. in the nlp area, we will choose between the different available tools depending on how they can be applied in the final project. to increase the acceptance of the application, we will study the advantages and positive effects of using gamification in learning applications and how it influences users in terms of motivation, engagement, learning quality and entertainment. everything will be developed following the ucd process, whose goal is to build applications based on user experience (ux). in addition, we will study the latest trending web technologies in order to develop a platform that will be available for everyone, online and free.\n\nlicense\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"creative commons license\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">playlingua</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"https://github.com/elenatorro/playlingua\" property=\"cc:attributionname\" rel=\"cc:attributionurl\">elena torro</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">creative commons attribution 4.0 international license</a>.<br />based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/elenatorro/playlingua\" rel=\"dct:source\">https://github.com/elenatorro/playlingua</a>.\n\ninstructions\n\n* clone the repo\n\n```\ngit clone https://github.com/elenatorro/playlingua.git\n```\n\n* install npm dependencies\n\n```\n$ npm install\n```\n\n* install bower dependencies\n\n```\nbower install\n```\n\n* configure global configuration variables\n\nyou have a sample in config > variables_sample.js (remove '\\_sample')\n\n## run local\n* run mongodb database (you should have mongodb already installed)\n\n```\n$ sudo mongod\n\n```\n\nin your variables.js file, set 'environment' to 'development'.\n\n* run gulp\n\n```\n$ gulp\n```\n\nnow, open localhost in the port you've chosen. you can build the whole project with:\n\n```\n$ gulp build\n```\n\n\n### deploy\n\n* you'll have to tell your server to run app.js. for heroku it's already setted in the procfile.\n* in your variables.js file, set 'environment' to 'production'.\n\n## future work:\n\n* refactor\n* instructions & tools to build playlingua for another language (it's currently in spanish)\n\nany feedback is very welcome!\n"
  },
  {
    "readme": "# safe display-backend - small display platform\n\nsafe ads is a modern small display platform for the exchange of goods, services and digital assets with special focus on usability and security. this project as backend is part of my bachelor work and uses technologies such as node.js, express.js, knex.js and socket.io.\n\n🌐 [live api](https://safeanzeigen-backend.herokuapp.com)\n\n🖥️ [backend repository](https://github.com/safeanzeigen-backend)\n\n🎨 [frontend repository](https://github.com/safeanzeigen/safeanzeigen-frontend)\n\n![alt text](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654598213/backend-filestructure_skagr5.png)\n\n## ✨ features\n\n- offers a node.js backend with restful api with high cohesion and loose coupling\n- implementation of all functional requirements for the 7 resource advertisements, categories, chats, favorites, messages, subcategories users and in a 3-layer architecture from router, controller and service layer\n- autorization-middleware to secure api-endpoints by verifying the signature of the json web token (jwt).\n- Validation-middlware for securing api-endpoints by validating transferred user ids in the parameter or body of a request to the user id in the authentification json web token (jwt).\n- link to heroku postgresql database\n- database migration files and games as seeding data\n- send contact e-mails with nodemailer\n\n## 🤖 Technologies\n\n- [express.js](https://expressjs.com) node-backend-server, which provides a fast and minimalist rest-api\n- [knex.js](http://knexjs.org) query builder for migration, seeding and connection to the database\n- [postgresql](https://www.postgresql.org) as a relational database operated with the help of free hosting via [heroku](https://heroku.com) on amazon aws\n- continuous integration / continuous deployment via [heroku](https://heroku.com)\n- used to train real-time communication [socket.io](https://socket.io)\n- user management and sms-one time password for authentication by [clerk](https://clerk.dev)\n- [jsqr](https://github.com/cozmo/jsqr) as a possibility to check uploaded user images for the presence of a qr code and then extract them\n- e-mail by [nodemailer](https://nodemailer.com) and [mailjet](https://app.mailjet.com)\n\n## 💡 Developments & implemented ideas\n\n- total architecture of the software system\n![architektur](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597759/safeanzeigen-architektur_qdaoq2.png)\n\n- database scheme\n![database scheme](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654592075/safeanzeigen-database-schema-v4_brnejv.png)\n\n- split the rest-api into three separate layers. the router level knows incoming requests the correct function call and if necessary a check through the middleware too. the controller takes care of the validation of the incoming data and the correct response to the requesting person. the service layer handles the processing and extraction of data from the database. exchangeability of individual planes is thus ensured if the interface transfers remain unchanged.\n![3 layer architecture](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597767/safeanzeigen-backend-routing_l9toc1.png)\n\n- Scope of function using a usecase diagram\n![functional scope](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597803/safeanzeigen-usecase-chart_mbd0te.png)\n\n- sequence of validation and token assignment for the article verification by means of qr codes uploaded by the user in addition to its inserat\n![qr-code-tokens](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597783/qr-code-validation_ybcnf.png)\n\n### data structure\n\n- /api\n- contains all files that treat the api to be used from the frontend\n- /middlewares\n- contains middleware functions to authorize users to validate requests\n- / resources\n- contains for each resource of the system the router logic, the controller logic and the service layer logic. each abstraction layer only takes care of its special task.\n- /database\n- contains various files to connect to the database and save its configuration\n- /migrations\n- contains files used for the migration of the database scheme\n- /seeds\n- contains files used for inserting dummy data into the database\n\n### api architecture\n\nall resources of the system are divided into three abstracts of separations:\n\n- router\n- determines which incoming http request is forwarded to which controller function via its http method and route\n- provides a clear overview of all available routes of a particular resource\n- controller\n- manages the check of the incoming and outgoing http request and response data for an api call\n- does not care how the result is calculated or retrieved, but only about data traffic\n- services\n- is the profound business logic that assumes that all data have already been checked and analyzed by the controller level.\n- takes over the work of algorithms and database connections to provide the desired data for the http request\n\n### Conventions & guidelines\n\n- dateinames should be written in \"small letters\", i.e. connected to a binding line.\n- all media files such as images must be optimized and made as small as loss-free before being added to the project\n- prettier.js with team settings should be used for formatting all files with the same structure\n- the indentation of the files should be 2 empty characters\n- the designation of variable should be meaningful and English\n- comments should only be used where they are necessary to explain superior ideas of the code as they quickly outdated\n\n### well known bugs\n\n- the seeds are now outdated and have not been adapted to the current status of the database scheme.\n\nstart your own\n\n###\n\nthe following applications should be installed before performing this software.\n\n```bash\r\ngit\r\nnode\r\ngegegebenfalls postgresql\r\n```\r\n\r\n### 🔒 apis\r\n\r\n- folgende apis und fremddienste sollten eingerichtet werden, bevor das system genutzt wird:\r\n  - clerk\r\n\r\n### 🔧 umgebungsvariablen\r\n\r\nes gibt einige umgebungsvariablen, die benötigt werden, egal ob die anwendung lokal oder im deployment ausgeführt werden soll.\r\n\r\n```bash\r\ndatabase_url=<postgresql url string hier>\r\n\r\ndeployment=\"development\"\r\nport=5000\r\nserver_url=<server url mit port hier>\r\n\r\nfolgend muss der clerk jwt verification key entsprechend aufbereitet werden\r\ndie erste umgebungsvariable muss wie angegeben benannt werden\r\ndie folgenden umgebungsvariablen müssen jeweils eine aufteilung des schlüssels auf exakt 64 zeichen sein\r\ndie letzte umgebungsvariable muss wie angegeben benannt werden\r\nsollte die gesamte schlüssellänge unerwartet abweichen müssen mehr oder weniger umgebungsvariablen erzeugt werden. auch im code sind diese dann zu verändern.\r\n\r\n\r\nclerk_jwt_signature_public_key_line_1=-----begin public key-----\r\nclerk_jwt_signature_public_key_line_2=<clerk jwt_verification_api_key_first_64_chars>\r\nclerk_jwt_signature_public_key_line_3=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_4=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_5=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_6=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_7=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_8=<clerk jwt_verification_api_key_next_chars>\r\nclerk_jwt_signature_public_key_line_9=-----end public key-----\r\n\r\nverification_image_secret=<eigenes geheimes passwort hier>\r\nverification_successful_secret=<weiteres eigenes geheimes passwort hier>\r\n\r\nemail_server_user=<e-mail smtp user>\r\nemail_server_password=<e-mail smtp passwort>\r\nemail_server_host=<e-mail smtp host>\r\nemail_server_port=<e-mail smtp port>\r\nemail_from=<e-mail-absender>\r\n```\r\n\r\nwenn das backend von neu eingerichtet wird, muss das datenbankschema eingerichtet werden. um die dinge einfach zu machen und unleserlich lange datenbank-dump-dateien zu vermeiden, wurden migrationsdateien verwendet. um zu testen, ob alles funktioniert, können die seed-dateien ausgeführt werden, um dummy-daten einzufügen und auf fehler zu prüfen.\r\n\r\n## knex.js funktionen\r\n\r\n### anlage neuer migrationsdateien\r\n\r\n```bash\r\nnpx knex migrate:make init --migrations-directory db/migrations\r\n```\r\n\r\n### ausführen bestehender migrationsdateien\r\n\r\n```bash\r\nnpx knex migrate:latest --knexfile db/knexfile.js\r\n```\r\n\r\n### seed dateien ausführen\r\n\r\n```bash\r\nnpx knex seed:run --knexfile db/knexfile.js\r\n```\r\n\r\n### ausführen des backends in entwicklungsumgebung\r\n\r\ndie entwicklungsumgebung und der startbefehl verwenden die abhängigkeit [nodemon](https://www.npmjs.com/package/nodemon), die den backend-server bei jeder dateiänderung neu startet, um das testen zu erleichtern.\r\n\r\n```bash\r\ngit clone <backend github url>\r\ncd into project\r\nnpm install //abhängigkeiten installieren\r\nnpm run dev //server starten\r\nvisit http://localhost:5000 im browser nutzen oder das frontend verbinden, um den erfolg zu prüfen\r\n```\r\n\r\n### ausführen des backends in produktionsungsumgebung\r\n\r\n```bash\r\ngit clone <backend github url>\r\ncd into project\r\nnpm install //abhängigkeiten installieren\r\nnpm start //server starten\r\nvisit http://localhost:5000 im browser nutzen oder das frontend verbinden, um den erfolg zu prüfen\r\n```\r\n\r\n## 🌊 git flow\r\n\r\n![startseite lighthouse result](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654590112/safeanzeigen-git-flow_npx565.png)\r\n\r\nes wurde git flow mit dem main branch, dem develop branch und verschiedenen feature branchen je user story genutzt\r\n\r\n- main branch (produktionsumgebung)\r\n- develop branch (entwicklungsumgebung)\r\n\r\n## 🔑 lizenz\r\n\r\n[mit license](https://github.com/safeanzeigen/safeanzeigen-backend/blob/main/license)\r\n",
    "readme_before": "# safeanzeigen-backend - kleinanzeigenplattform\r\n\r\nsafeanzeigen ist eine moderne kleinanzeigenplattform für den austausch von waren, dienstleistungen und digitalen assets mit besonderem fokus auf usability und sicherheit. dieses projekt als backend ist teil meiner bachelorarbeit und verwendet technologien wie node.js, express.js, knex.js und socket.io.\r\n\r\n🌐 [live api](https://safeanzeigen-backend.herokuapp.com)\r\n\r\n🖥️ [backend repository](https://github.com/safeanzeigen/safeanzeigen-backend)\r\n\r\n🎨 [frontend repository](https://github.com/safeanzeigen/safeanzeigen-frontend)\r\n\r\n![alt text](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654598213/backend-dateistruktur_skagr5.png)\r\n\r\n## ✨ features\r\n\r\n- bietet ein node.js backend mit restful api mit hoher kohäsion und loser kopplung\r\n- implementierung aller funktionalen anforderungen für die 7 ressourcen advertisements, categories, chats, favorites, messages, subcategories und users in einer 3-schichten-architektur aus router-, controller- und service-layer\r\n- autorisierungs-middleware zur absicherung von api-endpunkten durch eine verifizierung der signatur des json web token (jwt). sie gewährleistet, dass nur eingeloggte benutzer aktionen ausüben können.\r\n- validierungs-middlware zum absichern von api-endpunkten durch eine validierung übergebener user ids im parameter oder body eines requests gegenüber der user id im authentifikations json web token (jwt). sie gewährleistet, dass nutzer nur ihre eigenen ressourcen manipulieren dürfen.\r\n- verbindung zur heroku postgresql-datenbank\r\n- datenbankmigrationsdateien und beispiele als seeding-daten\r\n- versenden von kontakt-e-mails mit nodemailer\r\n\r\n## 🤖 technologien\r\n\r\n- [express.js](https://expressjs.com) node-backend-server, der eine schnelle und minimalistische rest-api bereitstellt\r\n- [knex.js](http://knexjs.org) query builder für migrationen, seeding und verbindung zur datenbank\r\n- [postgresql](https://www.postgresql.org) als relationale datenbank, die mit hilfe des kostenlosen hostings über [heroku](https://heroku.com) auf amazon aws betrieben wird\r\n- continuous integration / continuous deployment pipeline über [heroku](https://heroku.com)\r\n- nutzt zur abbildung der echtzeitkommunikation [socket.io](https://socket.io)\r\n- user management und sms-one time password für authentifizierung durch [clerk](https://clerk.dev)\r\n- [jsqr](https://github.com/cozmo/jsqr) als möglichkeit hochgeladene nutzerbilder auf das vorhandensein eines qr-codes zu prüfen und diesen anschließend zu extrahieren\r\n- emailversand mittels [nodemailer](https://nodemailer.com) und [mailjet](https://app.mailjet.com)\r\n\r\n## 💡 entwicklungen & umgesetzte ideen\r\n\r\n- gesamtarchitektur des softwaresystems\r\n  ![architektur](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597759/safeanzeigen-architektur_qdaoq2.png)\r\n\r\n- datenbankschema\r\n  ![datenbankschema](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654592075/safeanzeigen-database-schema-v4_brnejv.png)\r\n\r\n- aufteilung der rest-api in drei voneinander getrennte schichten. die router-ebene weißt einkommenden requests die richtigen funktionsaufruf und gegebenenfalls einen check durch die middleware zu. der controller kümmer sich um die validierung der einkommenden daten und um die korrekte antwort an den anfragenden. das service-layer kümmert sich um die verarbeitung und extraktion der daten aus der datenbank. somit ist eine austauschbarkeit einzelner ebenen gewährleistet, sofern die schnittstellenübergaben unverändert bleiben.\r\n  ![3-schichte-architektur](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597767/safeanzeigen-backend-routing_l9toc1.png)\r\n\r\n- funktionsumfang anhand eines usecase-diagramms\r\n  ![funktionsumfang](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597803/safeanzeigen-usecase-diagramm_mbd0te.png)\r\n\r\n- ablauf der validierung und tokenvergabe für die artikelverifikation mittels vom nutzer hochgeladenen qr-codes neben seinem inserat\r\n  ![qr-code-tokens](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654597783/qr-code-validation_yybcnf.png)\r\n\r\n### 📁 dateistruktur\r\n\r\n- /api\r\n  - enthält alle dateien, die die vom frontend zu verwendende api behandeln\r\n  - /middlewares\r\n    - enthält middleware-funktionen zur autorisierung von benutzern validieren von anfragen\r\n  - /ressourcen\r\n    - enthält für jede ressource des systems die router-logik, die controller-logik und die service-schicht-logik. jede abstraktionsschicht kümmert sich nur um ihre spezielle aufgabe kümmern.\r\n- /database\r\n  - enthält verschiedene dateien, um eine verbindung zur datenbank herzustellen und ihre konfiguration zu speichern\r\n  - /migrations\r\n    - enthält dateien, die für die migration des datenbankschemas verwendet werden\r\n  - /seeds\r\n    - enthält dateien, die für das einfügen von dummy-daten in die datenbank verwendet werden\r\n\r\n### 📫 api architektur\r\n\r\nalle ressourcen des systems sind in drei abstraktionen von trennungen aufgeteilt:\r\n\r\n- router\r\n  - legt fest, welche eingehende http-anfrage über ihre http-methode und route an welche controller-funktion weitergeleitet wird\r\n  - bietet eine klare übersicht über alle verfügbaren routen einer bestimmten ressource\r\n- controller\r\n  - handhabt die prüfung der eingehenden und ausgehenden http-anfrage- und antwortdaten für einen api-aufruf\r\n  - kümmert sich nicht darum, wie das ergebnis berechnet oder abgerufen wird, sondern nur um den datenverkehr\r\n- services\r\n  - ist die tiefgreifende geschäftslogik, die davon ausgeht, dass alle daten bereits von der controller-ebene geprüft und analysiert wurden.\r\n  - übernimmt die arbeit der algorithmen und datenbankverbindungen, um die gewünschten daten für die http-anfrage bereitzustellen\r\n\r\n### 📏 konventionen & guidelines\r\n\r\n- dateinamen sollten in \"kleinbuchstaben\" geschrieben werden, d.h. mit einem bindestrich verbunden.\r\n- alle mediendateien wie z.b. bilder müssen optimiert und so klein wie verlustfrei möglich gemacht werden, bevor sie dem projekt hinzugefügt werden\r\n- prettier.js mit team-einstellungen sollte für die formatierung aller dateien mit der gleichen struktur verwendet werden\r\n- die einrückung der dateien sollte 2 leerzeichen betragen\r\n- die benennung von variablen sollte aussagekräftig und englisch sein\r\n- kommentare sollten nur dort verwendet werden, wo sie notwendig sind, um übergeordnete ideen des codes zu erklären, da sie schnell veralten\r\n\r\n### 🐛 bekannte bugs\r\n\r\n- die seeds sind inzwischen veraltet und wurde nicht den aktuellen stand des datenbankschemas angepasst.\r\n\r\n## 🏠 selber starten\r\n\r\n### ⏹️ voraussetzungen\r\n\r\ndie folgenden anwendungen sollten vor der ausführung dieser software installiert werden.\r\n\r\n```bash\r\ngit\r\nnode\r\ngegegebenfalls postgresql\r\n```\r\n\r\n### 🔒 apis\r\n\r\n- folgende apis und fremddienste sollten eingerichtet werden, bevor das system genutzt wird:\r\n  - clerk\r\n\r\n### 🔧 umgebungsvariablen\r\n\r\nes gibt einige umgebungsvariablen, die benötigt werden, egal ob die anwendung lokal oder im deployment ausgeführt werden soll.\r\n\r\n```bash\r\ndatabase_url=<postgresql url string hier>\r\n\r\ndeployment=\"development\"\r\nport=5000\r\nserver_url=<server url mit port hier>\r\n\r\nfolgend muss der clerk jwt verification key entsprechend aufbereitet werden\r\ndie erste umgebungsvariable muss wie angegeben benannt werden\r\ndie folgenden umgebungsvariablen müssen jeweils eine aufteilung des schlüssels auf exakt 64 zeichen sein\r\ndie letzte umgebungsvariable muss wie angegeben benannt werden\r\nsollte die gesamte schlüssellänge unerwartet abweichen müssen mehr oder weniger umgebungsvariablen erzeugt werden. auch im code sind diese dann zu verändern.\r\n\r\n\r\nclerk_jwt_signature_public_key_line_1=-----begin public key-----\r\nclerk_jwt_signature_public_key_line_2=<clerk jwt_verification_api_key_first_64_chars>\r\nclerk_jwt_signature_public_key_line_3=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_4=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_5=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_6=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_7=<clerk jwt_verification_api_key_next_64_chars>\r\nclerk_jwt_signature_public_key_line_8=<clerk jwt_verification_api_key_next_chars>\r\nclerk_jwt_signature_public_key_line_9=-----end public key-----\r\n\r\nverification_image_secret=<eigenes geheimes passwort hier>\r\nverification_successful_secret=<weiteres eigenes geheimes passwort hier>\r\n\r\nemail_server_user=<e-mail smtp user>\r\nemail_server_password=<e-mail smtp passwort>\r\nemail_server_host=<e-mail smtp host>\r\nemail_server_port=<e-mail smtp port>\r\nemail_from=<e-mail-absender>\r\n```\r\n\r\nwenn das backend von neu eingerichtet wird, muss das datenbankschema eingerichtet werden. um die dinge einfach zu machen und unleserlich lange datenbank-dump-dateien zu vermeiden, wurden migrationsdateien verwendet. um zu testen, ob alles funktioniert, können die seed-dateien ausgeführt werden, um dummy-daten einzufügen und auf fehler zu prüfen.\r\n\r\n## knex.js funktionen\r\n\r\n### anlage neuer migrationsdateien\r\n\r\n```bash\r\nnpx knex migrate:make init --migrations-directory db/migrations\r\n```\r\n\r\n### ausführen bestehender migrationsdateien\r\n\r\n```bash\r\nnpx knex migrate:latest --knexfile db/knexfile.js\r\n```\r\n\r\n### seed dateien ausführen\r\n\r\n```bash\r\nnpx knex seed:run --knexfile db/knexfile.js\r\n```\r\n\r\n### ausführen des backends in entwicklungsumgebung\r\n\r\ndie entwicklungsumgebung und der startbefehl verwenden die abhängigkeit [nodemon](https://www.npmjs.com/package/nodemon), die den backend-server bei jeder dateiänderung neu startet, um das testen zu erleichtern.\r\n\r\n```bash\r\ngit clone <backend github url>\r\ncd into project\r\nnpm install //abhängigkeiten installieren\r\nnpm run dev //server starten\r\nvisit http://localhost:5000 im browser nutzen oder das frontend verbinden, um den erfolg zu prüfen\r\n```\r\n\r\n### ausführen des backends in produktionsungsumgebung\r\n\r\n```bash\r\ngit clone <backend github url>\r\ncd into project\r\nnpm install //abhängigkeiten installieren\r\nnpm start //server starten\r\nvisit http://localhost:5000 im browser nutzen oder das frontend verbinden, um den erfolg zu prüfen\r\n```\r\n\r\n## 🌊 git flow\r\n\r\n![startseite lighthouse result](https://res.cloudinary.com/dbldlm9vw/image/upload/v1654590112/safeanzeigen-git-flow_npx565.png)\r\n\r\nes wurde git flow mit dem main branch, dem develop branch und verschiedenen feature branchen je user story genutzt\r\n\r\n- main branch (produktionsumgebung)\r\n- develop branch (entwicklungsumgebung)\r\n\r\n## 🔑 lizenz\r\n\r\n[mit license](https://github.com/safeanzeigen/safeanzeigen-backend/blob/main/license)\r\n"
  },
  {
    "readme": "<b>mitrapark</b>\n\n![thumbnail](https://github.com/user-attachments/assets472698f6-0e17-4246-8cf1-6f673b7c50dc)\n",
    "readme_before": "<b>mitrapark</b>\n\n![thumbnail](https://github.com/user-attachments/assets/472698f6-0e17-4246-8cf1-6f673b7c50dc)\n"
  },
  {
    "readme": "# Install git:\n\nIn the command prompt, type 'git version'. if you have git installed, you will receive a response in the style of:\n\"Guit version 2.15.1\"\nIf not, the computer complains that it doesn’t understand what you’re trying to say.\nhttps:/www.atlassian.com/git/tutorials/install-git\nSet your name and email according to the last bit of the windows review; now you’ve been on your computer.\n\nDownload the project:\n\nIn the command prompt, navigate to where you want the project. i would recommend having it somewhere in your matlab-path, but you choose yourself. once you’re there, type in ‘git clone...’ where ‘...’” is what stands on the start page of the Atlassian. Hopefully everything is downloaded and vouila, you have the latest version.\n\n#How do you do?\n\nRead here, they have a good review:\nhttps:/git-scm.com/book/en/v2\nIf you want a little more background, you can practice chapter 1. get started. they explain how to do most via the command prompt. You don’t have to read through super-noga, but if you want to drive through any tool other than the command prompt, you are warmly welcome, but I don’t know how to do it.\nRemember:\n\nPull down the latest version before creating a new branch.\n\ncommit your files when you feel satisfied.\n\nPush your commit when you are satisfied.\n\nEnter your branch in master only if you know it works.\n\nNot working directly in the master branch.\n\nWorkflow for a feature\n\nBranch:\n$ git checkout -b name\n\ncard for:\n\n$ git branch name\n\n$ git checkout name\n\nWork on, code until you get blue when you’re done with a piece of it all:\n\nAdd your files:\n\n$ git add file name.txt film milk.fil...\n\nCommit with a short medium:\n\n$ git commit –m ‘lorem ipsum’\n\nPull: $ git pull\n\nPush: $git push\n\nWork on and comitte more and more until you finish the entire feature.\nMerge the entire feature:\n\nCheck out the master:\n\n$ git checkout master\n\nswitched to branch 'master'\n\n$ git merge name\n\nMade by the 'recursive' strategy.\n\nindex.html | 1 +\n\n1 file changed, 1 insertion(+)\n\n\n",
    "readme_before": "# installera git:\n\ni kommandoprompten, skriv 'git version'. om du har git installerat får du ett svar i stil med:\n'git version 2.15.1'\nom inte så klagar datorn på att den inte förstår vad du försöker säga. följ isåfall denna genomgången:\nhttps://www.atlassian.com/git/tutorials/install-git\nställ in ditt namn och email enligt sista biten i windows genomgången. nu har du git på din dator.\n\n# ladda ner projektet:\n\ni kommandoprompten, navigera till där du vill ha projektet. jag skulle rekomendera att ha det någonstans i din matlab-path, men du väljer själv. när du väl är där, skriver du in 'git clone ...' där '...'' är det som står med på start sidan i atlassian. allting laddas förhoppningsvis ner och vouila, du har senaste versionen.\n\n# hur gör man?\n\nläs på här, dem har en bra genomgång:\nhttps://git-scm.com/book/en/v2\nkolla speciellt kapitel 2. git basics och 3. git branching. om du vill ha lite mer bakgrund kan du ögna igenom kapitel 1. getting started. dem förklarar hur man gör det mesta via kommandoprompten. man behöver inte läsa igenom supernoga, men  om du vill köra via ngt annat verktyg än kommandoprompten är du varmt välkommen, men jag vet inte hur man gör. \nkom ihåg att:\n\n- pulla ner senaste versionen innan du skapar en ny branch. \n\n- commita dina filer när du känner dig nöjd.\n\n- pusha din commit när du är helnöjd.\n\n- mergea in din branch i master endast om du vet att den fungerar. \n\n- inte jobba direkt i master branchen. \n\n# workflow för en feature\n\nbrancha: \n- $ git checkout -b name \n\n\tkort för:\t\n\n\t$ git branch name \n\n\t$ git checkout name\n\n- jobba på, koda tills du blir blå. när du är färdig med en bit av det hela:\n\n\t\tlägg till dina filer:\n\n\t\t$ git add filnamn.txt filmjölk.fil ...\n\n\t\tcommita med ett kort medelande:\n\t\t\n\t\t$ git commit –m ’lorem ipsum’\n\n- pulla: $ git pull\n\n- pusha: $ git push\n\n- jobba på och comitta mer och mer tills du är färdig med hela featuren.\n- mergea hela featuren:\n\t\n\tchecka ut mastern:\n\n\t$ git checkout master \n\n\tswitched to branch 'master’\n\n\t$ git merge name\n\n\tmerge made by the 'recursive' strategy. \n\n\tindex.html | 1 + \n\t\n\t1 file changed, 1 insertion(+)\n\t\n\n"
  },
  {
    "readme": "# Internal thesis project at [elexis](https://elex.is/) at the[ilc-cnr](https://github.com/cnr-ilc): \"developing a sense inventory for word sense disambiguation task: the elexis project\"\n##  in Bachelor in Humanities Information Technology - a.a. 2019/2020\n\n\n<div> <img src=\"https://apre.it/wp-content/uploads/2021/01/logo_uni-pisa.png\" width=\"200\" />\n<img src=\"https://elex.is/wp-content/uploads/2018/10/ilc-400-300x238.png\" width=\"150\" />\n</div\n\n< a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"<img alt=\"creative commons license\" style= \"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15\"\n\n♪\n\n### phases of the thesis project:\ncreating a sense inventory for word sense disambiguation task and extension of ilc4clarin/ilc-cnr-based sense mapping, with manual annotation task of the phrase dataset and resource evaluation used.\n\n## Programmes:\n\n####\n###### repositories: *sense_inventory*\nthe creation of the resource is based on the selection of lemmies from a dateset in conll-u format (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) derived from the Italian translation of a corpus noted of phrases developed in elexis, annotated automatically and then revised manually and through correction tools in babelscape.\nthe program (*corrected.py*) takes into input the dataset, selects the extracts from the phrases of which it composes and searches all the related senses in the online resources open-source ilc4clarin (the Italian lexic [parole-simple-clips](https://dspace-clarin-it.cnr.it/repository/xmlui/handle/20.500\nthe data extrapolated and controlled are then arranged in the formal structure of the sense inventory required for the elexis tasks, such for each lemma pair - pos:\n* senses present in psc, not mapped\n* mapped senses\n* senses present in iwn, not mapped\n\nthe set of dilemmas dealt in the program is stored in the output *newdataset.txt*.\nthe sense inventory is printed in *corrected_si.txt*. The latter output has also been transformed into a *.xslx* extension resource.\n\n######  di extension of sense mapping\n####### repository: *mapping_extension*\nwithin the program (*maps.py*) two phases of test for the mapping of the senses between the lexic italwordnet and words-simple clips through the calculation of the similarity between word vectors through [spacy] (https://github.com/explosion/spacy). in the first part the mappings already present in the *iwnmapdb* database of the ic-cnr are analyzed to reach a threshold of similarity between the senses of the already developed mappings, to be applied to the potential ones. in the second part of the code is analyzed the *similarity* between the senses of different dilemmas (selected manually) without any sense mapped precisely; similarity that was then compared to the threshold found previously.\nthe program takes in input a file with the list of mapped lemmies (*listamapdb.txt*) for a check on selected lemmies manually and the final format of the sense inventory (*corrected_si.txt*) for extrapolation of information on the senses (definition, ids). outputs are *testmapping.txt* for the first part, with the list of scanned mappings and their *similarity*, as well as the arithmetic average of the similarity set that corresponds to the threshold; for the second, instead, *testnonmappati.txt*, in which the list of mapping with the *similarity* is found among all the senses of each lemma.\n\n#####  di resource coverage percentages\n####### repository: *percents*\nsense inventory also acts as a means for an analysis of the current breadth of the databases we have used, in particular to study their effective coverage and efficiency regarding the needs of elexis and their state of art. The program (*rates.py*) serves to collect and process data from the sense inventory, to process the numbers needed to present them and to formulate a more accurate analysis.\nthe program takes into input the dataset from which the sense inventory was obtained (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) and the sense inventory (*correctes_si.txt*) to recreate the process used for the latter, in order to collect data during processing. the results of the analysis are printed in the output (*numbers.txt*).\n\n#####  di selection of manual annotation phrases\n####### repository: *sentences_selector*\nThis simple program (*sceltafrasi.py*) inputs the dataset in conll-u format (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) and assigns to each sentence in it contained the number of dilemmas present in both reference databases, psc and iwn, then print all data in the output (*sentences). This makes it easier to choose phrases for the manual annotation task. the phrases were then selected manually, due to some syntactic peculiarities to be taken into consideration at the non-automatic level.\n\n--\n\n♪\n\n## thesis project phases\nbuilding of a sense inventory for word sense disambiguation tasks and extension of sense mapping based on ilc4clarin/ilc-cnr resources, with tasks for manual annotation of the phrase dataset and evaluation of the resources used.\n\n### programs:\n\n####\n###### repositories: *sense_inventory*\nthe creation of the resource is based on the selection of lemmas from a dataset in conll-u format (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) derived from the italian translation of an annotated corpus of sentences developed in elexis, automatically annotated and then reviewed manually and through correction tools in babelscape.\nthe program (*corrected.py*) takes as input the dataset, selects the lemmas extracted from the sentences of which it is composed and search for all the related senses in the open-source online resources ilc4clarin (the italian lexicons [parole-simple-clips](https://dspace-clarin-it.cnr.it/repository/xmlui)\nthe extrapolated and checked data are then arranged in the formal structure of the sense inventory required for the elexis tasks, such that for each lemma - pos pair:\n* senses present in psc, not mapsd\n* mapd senses\n* senses present in iwn, not mapsd.\n\nthe set of lemmas treated in the program is stapled in the output *newdataset.txt*.\nthe sense inventory is printed in *corrected_si.txt*. the dai output has also been transformed into a resource extension *.xslx*.\n\n################################################################################################################################################################################################################################################################\n####### repository: *mapping_extension*\nwithin the program (*maps.py*) we carry out two tests phases for sense mapping between the italwordnet and word-simple clips lexicons by definition the similarity between word vectors using [spacy](https://github.com/explosion/spacy). in the first part the mappings already present in the ilc-cnr database *iwnmapdb* are analysed to arrive at a threshold of similarity between senses of the mappings already developed, to be applied to potential honest. in the second part of the code the *similarity* between senses of different lemmas (manually selected) without any mapd sense is analyzed; similarity that was then compared with the found previously.\nthe program takes as input a file with the list of mapsd lemmas (*listamapdb.txt*) for a check on the manual selected lemmas and the final format of the sense inventory (*corrected_si.txt*) for the extrapolation of information on the senses (definition, ids). the outputs are equivalent *testmapping.txt* for the first part, with the list of analysed mappings and their *similarity*, as well as the arithmetic mean of the set of similarities corresponding to the threshold; for the second one, instead, *testnonmapped.txt*, where the list of mappings with the *similarity* between all the senses of each lemma is found.\n\n##### 📍 percentages of resource coverage\n####### repository: *percents*\nthe sense inventory also served as a means for an analysis of the current extent of the databases we have used, in particular to study their actual coverage and efficiency with respect to the needs of elexis and their state of the art. the program (*rates.py*) is used to collect and process the data obtained from the sense inventory, to process the numbers needed to present them and to formulate a more accurate analysis.\nthe program takes as input the dataset from which the sense inventory was derived (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) and the sense inventory (*corrected_si.txt*) to invalid the process used for the dai, in order to collect data during the processing. in the output (*numbers.txt*) the results of the analysis are printed.\n\n################################################################################################################################################################################################################################################################\n####### repository: *sentences_selector*\nthis simple program (*sentences_selector.py*) takes as input the dataset in conll-u format (*dataset2000wiki_export_it_2021-02-22_corred_v2.tsv*) and assigns to each sentence contained in it the number of lemmas present in both the reference databases, psc and iwn, and then prints all the data in the output this makes it easier to select sentences for the manual annotation task. the sentences were then selected manually, two to some syntactic peculiarities that had to be taken into account on a non-automatic level.\n\n",
    "readme_before": "# progetto di tesi interno ad [elexis](https://elex.is/) presso l'[ilc-cnr](https://github.com/cnr-ilc): \"sviluppo di un sense inventory per task di word sense disambiguation: il progetto elexis\"\n## 🎓 laurea triennale in informatica umanistica - a.a. 2019/2020\n\n\n<div> <img src=\"https://apre.it/wp-content/uploads/2021/01/logo_uni-pisa.png\" width=\"200\" /> \n<img src=\"https://elex.is/wp-content/uploads/2018/10/ilc-400-300x238.png\" width=\"150\" />\n</div>\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"creative commons license\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a><br />this work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">creative commons attribution-noncommercial-sharealike 4.0 international license</a>. \n\n# ita\n\n### fasi del progetto di tesi:\ncreazione di un sense inventory per task di word sense disambiguation ed estensione del mapping di sensi basato sulle risorse ilc4clarin/ilc-cnr, con task di annotazione manuale del dataset di frasi e valutazione delle risorse utilizzate. \n\n### programmi:\n\n#### 📍 sense inventory\n##### repository: *sense_inventory*\nla creazione della risorsa si basa sulla selezione di lemmi da un dataset in formato conll-u (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) derivato dalla traduzione italiana di un corpus annotato di frasi sviluppato in elexis, annotato automaticamente e poi rivisto manualmente e tramite strumenti di correzione in babelscape.\nil programma (*corrected.py*) prende in input il dataset, seleziona i lemmi estratti dalle frasi di cui quest'ultimo si compone e ne ricerca tutti i sensi correlati nelle risorse online open-source ilc4clarin (i lessici italiani [parole-simple-clips](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ilc-88?show=full) e [italwordnet](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ilc-62)) e ilc-cnr (un database di mapping di sensi dei lessici citati, *iwnmapdb*). \ni dati estrapolati e controllati vengono poi disposti nella struttura formale del sense inventory richiesta per i task elexis, tale per ogni coppia lemma - pos:\n* sensi presenti in psc, non mappati\n* sensi mappati\n* sensi presenti in iwn, non mappati\n\nl'insieme di lemmi trattati nel programma è stamapato nell'output *newdataset.txt*.\nil sense inventory è stampato in *corrected_si.txt*. quest'ultimo output è stato anche trasformato in una risorsa di estensione *.xslx*.\n\n#### 📍 estensione del mapping di sensi\n##### repository: *mapping_extension*\nall'interno del programma (*maps.py*) si svolgono due fasi di test per la mappatura dei sensi tra i lessici italwordnet e parole-simple clips attraverso il calcolo della similarità tra vettori di parole tramite [spacy](https://github.com/explosion/spacy). nella prima parte si analizzano i mapping già presente nel database *iwnmapdb* dell'ilc-cnr per arrivare ad un threshold di similarità tra sensi delle mappature già sviluppate, da applicare a quelle potenziali. nella seconda parte del codice viene analizzata la *similarity* tra sensi di diversi lemmi (selezionati manualmente) senza alcun senso mappato appunto; similarity che poi è stata confrontata col threshold trovato precedentemente.\nil programma prende in input un file con la lista di lemmi mappati (*listamapdb.txt*) per un controllo sui lemmi selezionati manualmente e il formato finale del sense inventory (*corrected_si.txt*) per l'estrapolazione di informazioni sui sensi (definizione, ids). gli output sono rispettivamente *testmapping.txt* per la prima parte, con la lista di mapping analizzati e la loro *similarity*, oltre che la media aritmetica dell'insieme di similarità che corrisponde al threshold; per la seconda, invece, *testnonmappati.txt*, in cui si trova l'elenco di mapping con la *similarity* tra tutti i sensi di ogni lemma. \n\n#### 📍 percentuali di copertura delle risorse \n##### repository: *percents*\nil sense inventory funge anche da mezzo per un’analisi dell’attuale ampiezza dei database di cui abbiamo usufruito, in particolare per studiare la loro effettiva copertura ed efficienza rispetto alle necessità di elexis e il loro stato dell’arte. il programma (*rates.py*) serve alla raccolta e al trattamento dei dati ricavati dal sense inventory, per elaborare i numeri necessari a presentarli e a formulare un'analisi più accurata.\nil programma prende in input il dataset da cui è stato ricavato il sense inventory (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) e il sense inventory (*correctes_si.txt*) per ricreare il processo utilizzato per quest'ultimo, al fine di raccogliere dati durante l'elaborazione. nell'output (*numbers.txt*) sono stampati i risultati dell'analisi.\n\n#### 📍 selezione di frasi per annotazione manuale\n##### repository: *sentences_selector*\nquesto semplice programma (*sceltafrasi.py*) prende in input il dataset in formato conll-u (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) e assegna ad ogni frase in esso contenuta il numero di lemmi presenti in entrambi i database di riferimento, psc e iwn, per poi stampare tutti i dati nell'output (*sentences.txt*). in questo modo rende più semplice la scelta delle frasi per il task di annotazione manuale. le frasi sono state poi selezionate manualmente, a causa di alcune particolarità sintattiche da prendere in considerazione a livello non automatico.\n\n---\n\n# eng\n\n### thesis project phases:\nbuilding of a sense inventory for word sense disambiguation tasks and extension of sense mapping based on ilc4clarin/ilc-cnr resources, with tasks for manual annotation of the phrase dataset and evaluation of the resources used. \n\n### programs:\n\n#### 📍 sense inventory\n##### repository: *sense_inventory*\nthe creation of the resource is based on the selection of lemmas from a dataset in conll-u format (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) derived from the italian translation of an annotated corpus of sentences developed in elexis, automatically annotated and then reviewed manually and through correction tools in babelscape.\nthe program (*corrected.py*) takes as input the dataset, selects the lemmas extracted from the sentences of which it is composed and searches for all the related senses in the open-source online resources ilc4clarin (the italian lexicons [parole-simple-clips](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ilc-88?show=full) and [italwordnet](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ilc-62)) and ilc-cnr (a sense mapping database of the cited lexicons, *iwnmapdb*). \nthe extrapolated and checked data are then arranged in the formal structure of the sense inventory required for the elexis tasks, such that for each lemma - pos pair:\n* senses present in psc, not mapped\n* mapped senses\n* senses present in iwn, not mapped.\n\nthe set of lemmas treated in the program is stapled in the output *newdataset.txt*.\nthe sense inventory is printed in *corrected_si.txt*. the latter output has also been transformed into a resource extension *.xslx*.\n\n#### 📍 sense mapping extension\n##### repository: *mapping_extension*\nwithin the program (*maps.py*) we carry out two test phases for sense mapping between the italwordnet and word-simple clips lexicons by calculating the similarity between word vectors using [spacy](https://github.com/explosion/spacy). in the first part the mappings already present in the ilc-cnr database *iwnmapdb* are analysed to arrive at a threshold of similarity between senses of the mappings already developed, to be applied to potential ones. in the second part of the code the *similarity* between senses of different lemmas (manually selected) without any mapped sense is analysed; similarity that was then compared with the threshold found previously.\nthe program takes as input a file with the list of mapped lemmas (*listamapdb.txt*) for a check on the manually selected lemmas and the final format of the sense inventory (*corrected_si.txt*) for the extrapolation of information on the senses (definition, ids). the outputs are respectively *testmapping.txt* for the first part, with the list of analysed mappings and their *similarity*, as well as the arithmetic mean of the set of similarities corresponding to the threshold; for the second one, instead, *testnonmapped.txt*, where the list of mappings with the *similarity* between all the senses of each lemma is found. \n\n#### 📍 percentages of resource coverage \n##### repository: *percents*\nthe sense inventory also serves as a means for an analysis of the current extent of the databases we have used, in particular to study their actual coverage and efficiency with respect to the needs of elexis and their state of the art. the program (*rates.py*) is used to collect and process the data obtained from the sense inventory, to process the numbers needed to present them and to formulate a more accurate analysis.\nthe program takes as input the dataset from which the sense inventory was derived (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) and the sense inventory (*corrected_si.txt*) to recreate the process used for the latter, in order to collect data during the processing. in the output (*numbers.txt*) the results of the analysis are printed.\n\n#### 📍 selection of sentences for manual annotation\n##### repository: *sentences_selector*\nthis simple program (*sentences_selector.py*) takes as input the dataset in conll-u format (*dataset2000wiki_export_it_2021-02-22_corrected_v2.tsv*) and assigns to each sentence contained in it the number of lemmas present in both the reference databases, psc and iwn, and then prints all the data in the output (*sentences.txt*). this makes it easier to select sentences for the manual annotation task. the sentences were then selected manually, due to some syntactic peculiarities that had to be taken into account on a non-automatic level.\n\n"
  },
  {
    "readme": "# bluerov2 ros\n\n```\n                      +-----------------------+         +------------------------+\n                      |     raspberry pi      |         |    topside commputer   |\n                      |    ip 192.168.2.2     |         |     ip 192.168.2.1     |\n                      |                       |         |                        |\n+-------+  telemetry  | +-------------------+ |         |                        |\n|pixhawk<-------------->usb         mavproxy| |         |                        |\n+-------+    pilot    | +                   + |         | +--------------------+ |\n            control   | |            udpbcast<----------->:14550         mavros| |\n                      | +-------------------+ |  pilot  | |(udp)               | |\n                      |                       | control | |                    | |\n                      | +-------------------+ |         | |       (ros)        | |\n+---------+           | csi+2       raspivid| |         | +------+/mavros+-----+ |\n|raspberry+------------>camera              | |         |           ^            |\n| camera  |           | port                | |         |           |            |\n+---------+           | +                   | |         | +---------v----------+ |\n                      | |                   | |         | |subs.py      pubs.py| |\n                      | +------------+stdout+ |         | |                    | |\n                      |                  +    |         | |                    | |\n                      |             raw  |    |         | |                    | |\n                      |             h264 |    |         | |                    | |\n                      |                  v    |         | |      user.py       | |\n                      | +------------+ fdsrc+ |         | |                    | |\n                      | |gstreamer          | |         | |                    | |\n                      | |                   + |         | :5600 video.py       | |\n                      | |             udpsink+----------->(udp)                | |\n                      | +-------------------+ |  video  | +---------^----------+ |\n                      |                       | stream  |           |            |\n                      +-----------------------+         |           +            |\n                                                        | +--------/joy--------+ |\n                                                        | |joy     (ros)       | |         +--------+\n                                                        | |                  usb<----------+joystick|\n                                                        | +--------------------+ |  pilot  +--------+\n                                                        |                        | control\n                                                        +------------------------+\n```\n\n## installation\n\n### raspberry pi\n\nals verwendetes betriebsystem empfehle ich pi os lite. jedoch kann auch jedes andere system für den pi genutzt werden.\ndas passwort für den pi lautet \"companion\" und der username \"pi\".\n\n#### mavlink\nmavlink dient zur kommunikation zwischen dem topside computer und dem pixhawk. die nötigen bibliotheken können mit folgendem befehl instaliert werden.\n\n```\nsudo apt-get install python3-dev python3-opencv python3-wxgtk4.0 python3-pip python3-matplotlib python3-lxml python3-pygame\n```\n\nnun kann mit hilfe von pip die mavlink-bibliothek installiert werden\n\n```\npip3 install pyyaml mavproxy --user\n```\n\nnach abschluss der installation muss man noch der gewünschten shell die nötigen befehle verlinken.\n\n```\necho \"export path=$path:$home/.local/bin\" >> ~/.bashrc\n```\n\nwenn es zu permissions-problemen kommt, muss man noch die zugrifsrechte für den aktuellen benutzer anpassen\n\n```\nsudo usermod -a -g dialout <username>\n```\n\n#### gstreamer\nder gstreamer wird dafür verwendet, den video-output der integrierten kamera dem topside computer als stream zur verfügung zu stellen. um den gstreamer mit dem gewünschten h264 code zu verwenden, müssen folgende plugins installiert werden.\n\n```\nsudo apt-get install libgstreamer-plugins-base1.0-dev\nsudo apt-get install libgstreamer-plugins-bad1.0-dev \nsudo apt-get install libgstreamer-plugins-good1.0-dev\nsudo apt-get install libgstreamer-plugins-ugly1.0-dev \n```\nfalls probleme auftreten, kann man folgendes versuchen.\n```\nsudo apt-get install gstreamer1.0-plugins-bad\nsudo apt-get install gstreamer1.0-plugins-ugly\nsudo apt-get install gstreamer1.0-libav\n```\n\n#### usbip\ndas letzte programm stellt die usb-schnittstellen des raspberry pi dem topside computer zur verfügung. als erstes muss linux-tools-generic installiert werden, welches unter anderem usbip beinhaltet.\n\n```\nsudo apt-get install linux-tools-generic \n```\n\nnach der installation muss man als erstes das für \"usbip\" wichtige kernelmodul laden.\n\n```\nsudo modprobe usbip-host \n```\num das modul permanent zu laden, muss man /etc/modules editieren und usbip-host hinzufügen.\n\nals nächstes muss ein link von usbutils nach hwdata angelegt werden, damit die usb-geräte richtig angezeigt werden.\n\n```\nsudo mkdir /usr/share/hwdata/\nsudo ln -sf /var/lib/usbutils/usb.ids /usr/share/hwdata/ \n```\n\nnun kann ein \"usbip\" server gestartet werden, was natürlich nach jedem neustart wiederholt werden muss, wenn man dies nicht in den autostart einfügt.\n\n```\nsudo usbipd -d \n```\n\nnun kann mit der eigentlichen konfiguration der usb-geräte begonnen werden. hierfür sollte man sich erst einmal einen überblick über alle usb-geräte verschaffen, dabei sollte man auf die bus-id achten.\n\n```\nlsusb \n```\n\nmit der id oder dem namen kann man nun in der liste von \"usbip\" nach der richtigen bus-id (zahl-zahl; z.b. 1-2; nicht usb-id!) suchen.\n\n```\nusbip list -l \n```\n\nnachdem man nun im nächsten befehl die bus-id eingesetzt hat, ist der server fertig.\n\n```\nsudo usbip bind -b \"bus-id\" \n```\n#### statische ip\nnun muss man dem pi noch eine statische ip-adress zuweisen. dies geschieht über den befehl\n\n```\nsudo nano /etc/dhcpcd.conf\n```\n\nin der datei müssen folgende einträge auskommentiert und verändert werden\n\n```\ninterface eth0\nstatic ip_address=192.168.2.2/24\nstatic routers=192.168.2.1\n```\njetzt ist der pi bereit zum einsatz.\n\n### topside computer\n\nder topside computer benötigt ros kinetic. \n\nhttp://wiki.ros.org/kinetic/installation/ubuntu\n\n#### qgroundcontrol\n\nqgroundcontol kann dazu verwendet werden, den bluerov2 ohne ros direkt fahrbereit zu machen. das programm verfügt über eine mavlink-schnittstelle, sowie kamera- und joystick-integration. die installation erfolgt über folgenden befehl\n\n```\nsudo usermod -a -g dialout $user\nsudo apt-get remove modemmanager -y\nsudo apt install gstreamer1.0-plugins-bad gstreamer1.0-libav gstreamer1.0-gl -y\nsudo apt install libqt5gui5 -y\n```\n\nim anschluss kann [qgroundcontol](https://d176tv9ibo4jno.cloudfront.net/latest/qgroundcontrol.appimage) heruntergeladen werden.\num die video-funktion nutzen zu können, müssen für den gstreamer die plugins bad und libav installiert werden.\n\n#### mavros\num mavros zu installieren werden folgende befehle ausgeführt.\n```\nsudo apt-get install ros-kinetic-mavros ros-kinetic-mavros-extras\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\nsudo bash ./install_geographiclib_datasets.sh\n```\n\n#### pymavlink\npymavlink wird für das core package benötigt. um es zu installieren, werden folgende befehle verwendet.\n```\nsudo apt-get install gcc python-dev libxml2-dev libxslt-dev\nsudo apt-get install python-numpy python-pytest\nsudo python -m pip install --upgrade future lxml\nsudo python -m pip install --upgrade pymavlink\n```\n\n#### netzwerk\n\nder topside computer benötigt die statische ip-adresse ***192.168.2.1*** um mit dem bluerov2 kommunizieren zu können.\n\n---\n## inbetriebnahme\n\n### bluerov2\n1. verbindungsaufbau mit dem bluerov2 über ssh\n2. starten des video-streams\n   ```\n   gst-launch-1.0 v4l2src device=/dev/video2 ! queue ! video/x-h264,width=1920,height=1080,framerate=30/1 ! h264parse ! rtph264pay ! udpsink host=192.168.2.1 port=5600\n   ```\n3. starten des usbip server\n   ```\n    sudo modprobe usbip-host\n    sudo usbipd -d\n    sudo usbip bind -b \"bus-id\"\n    ```\n4. starten von mavlink\n    ```\n    mavproxy.py --master /dev/ttyacm0 --baudrate 921600 --aircraft bluerov --out 192.168.2.1:14550\n    ```\n\n--> die arbeitsschritte 2-4 wurden in einem skript automatisiert. dieses lässt sich durch folgenden befehl ausführen:\n    ```\n    ./startup.bash\n    ```\n\n### topside computer\nje nach anwendungsfall, kann man mit qgroundcontroll oder ros arbeiten.\n\n#### sonar über usbip einbinden\num das sonar über usbip einzubinden, werden folgende befehle ausgeführt.\n```\nsudo modprobe vhci-hcd\nsudo usbip attach -r 192.168.2.2 -b 1-1.4\n```\n\n#### launchfiles übersicht\n\num nur das videobild der kamera zu erfassen, kann man folgendes launchfile starten. dies muss vor dem start des bluerov2_node launchfiles erfolgen.\n```\nroslaunch core video.launch\n```\nfür eine manuelle steuerung des bluerovs mittels joystick startet man\n```\nroslaunch core user_mav.launch\n```\ndas folgende launchfile stellt elementare [topics](https://github.com/vincent1334/bluerov2-ros/tree/main/src/core/src/bridge) für den bluerov2 zur verfügung.\n```\nroslaunch core bluerov2_node.launch\n```\n",
    "readme_before": "# bluerov2 ros\n\n```\n                      +-----------------------+         +------------------------+\n                      |     raspberry pi      |         |    topside commputer   |\n                      |    ip 192.168.2.2     |         |     ip 192.168.2.1     |\n                      |                       |         |                        |\n+-------+  telemetry  | +-------------------+ |         |                        |\n|pixhawk<-------------->usb         mavproxy| |         |                        |\n+-------+    pilot    | +                   + |         | +--------------------+ |\n            control   | |            udpbcast<----------->:14550         mavros| |\n                      | +-------------------+ |  pilot  | |(udp)               | |\n                      |                       | control | |                    | |\n                      | +-------------------+ |         | |       (ros)        | |\n+---------+           | csi+2       raspivid| |         | +------+/mavros+-----+ |\n|raspberry+------------>camera              | |         |           ^            |\n| camera  |           | port                | |         |           |            |\n+---------+           | +                   | |         | +---------v----------+ |\n                      | |                   | |         | |subs.py      pubs.py| |\n                      | +------------+stdout+ |         | |                    | |\n                      |                  +    |         | |                    | |\n                      |             raw  |    |         | |                    | |\n                      |             h264 |    |         | |                    | |\n                      |                  v    |         | |      user.py       | |\n                      | +------------+ fdsrc+ |         | |                    | |\n                      | |gstreamer          | |         | |                    | |\n                      | |                   + |         | :5600 video.py       | |\n                      | |             udpsink+----------->(udp)                | |\n                      | +-------------------+ |  video  | +---------^----------+ |\n                      |                       | stream  |           |            |\n                      +-----------------------+         |           +            |\n                                                        | +--------/joy--------+ |\n                                                        | |joy     (ros)       | |         +--------+\n                                                        | |                  usb<----------+joystick|\n                                                        | +--------------------+ |  pilot  +--------+\n                                                        |                        | control\n                                                        +------------------------+\n```\n\n## installation\n\n### raspberry pi\n\nals verwendetes betriebsystem empfehle ich pi os lite. jedoch kann auch jedes andere system für den pi genutzt werden.\ndas passwort für den pi lautet \"companion\" und der username \"pi\".\n\n#### mavlink\nmavlink dient zur kommunikation zwischen dem topside computer und dem pixhawk. die nötigen bibliotheken können mit folgendem befehl instaliert werden.\n\n```\nsudo apt-get install python3-dev python3-opencv python3-wxgtk4.0 python3-pip python3-matplotlib python3-lxml python3-pygame\n```\n\nnun kann mit hilfe von pip die mavlink-bibliothek installiert werden\n\n```\npip3 install pyyaml mavproxy --user\n```\n\nnach abschluss der installation muss man noch der gewünschten shell die nötigen befehle verlinken.\n\n```\necho \"export path=$path:$home/.local/bin\" >> ~/.bashrc\n```\n\nwenn es zu permissions-problemen kommt, muss man noch die zugrifsrechte für den aktuellen benutzer anpassen\n\n```\nsudo usermod -a -g dialout <username>\n```\n\n#### gstreamer\nder gstreamer wird dafür verwendet, den video-output der integrierten kamera dem topside computer als stream zur verfügung zu stellen. um den gstreamer mit dem gewünschten h264 code zu verwenden, müssen folgende plugins installiert werden.\n\n```\nsudo apt-get install libgstreamer-plugins-base1.0-dev\nsudo apt-get install libgstreamer-plugins-bad1.0-dev \nsudo apt-get install libgstreamer-plugins-good1.0-dev\nsudo apt-get install libgstreamer-plugins-ugly1.0-dev \n```\nfalls probleme auftreten, kann man folgendes versuchen.\n```\nsudo apt-get install gstreamer1.0-plugins-bad\nsudo apt-get install gstreamer1.0-plugins-ugly\nsudo apt-get install gstreamer1.0-libav\n```\n\n#### usbip\ndas letzte programm stellt die usb-schnittstellen des raspberry pi dem topside computer zur verfügung. als erstes muss linux-tools-generic installiert werden, welches unter anderem usbip beinhaltet.\n\n```\nsudo apt-get install linux-tools-generic \n```\n\nnach der installation muss man als erstes das für \"usbip\" wichtige kernelmodul laden.\n\n```\nsudo modprobe usbip-host \n```\num das modul permanent zu laden, muss man /etc/modules editieren und usbip-host hinzufügen.\n\nals nächstes muss ein link von usbutils nach hwdata angelegt werden, damit die usb-geräte richtig angezeigt werden.\n\n```\nsudo mkdir /usr/share/hwdata/\nsudo ln -sf /var/lib/usbutils/usb.ids /usr/share/hwdata/ \n```\n\nnun kann ein \"usbip\" server gestartet werden, was natürlich nach jedem neustart wiederholt werden muss, wenn man dies nicht in den autostart einfügt.\n\n```\nsudo usbipd -d \n```\n\nnun kann mit der eigentlichen konfiguration der usb-geräte begonnen werden. hierfür sollte man sich erst einmal einen überblick über alle usb-geräte verschaffen, dabei sollte man auf die bus-id achten.\n\n```\nlsusb \n```\n\nmit der id oder dem namen kann man nun in der liste von \"usbip\" nach der richtigen bus-id (zahl-zahl; z.b. 1-2; nicht usb-id!) suchen.\n\n```\nusbip list -l \n```\n\nnachdem man nun im nächsten befehl die bus-id eingesetzt hat, ist der server fertig.\n\n```\nsudo usbip bind -b \"bus-id\" \n```\n#### statische ip\nnun muss man dem pi noch eine statische ip-adress zuweisen. dies geschieht über den befehl\n\n```\nsudo nano /etc/dhcpcd.conf\n```\n\nin der datei müssen folgende einträge auskommentiert und verändert werden\n\n```\ninterface eth0\nstatic ip_address=192.168.2.2/24\nstatic routers=192.168.2.1\n```\njetzt ist der pi bereit zum einsatz.\n\n### topside computer\n\nder topside computer benötigt ros kinetic. \n\nhttp://wiki.ros.org/kinetic/installation/ubuntu\n\n#### qgroundcontrol\n\nqgroundcontol kann dazu verwendet werden, den bluerov2 ohne ros direkt fahrbereit zu machen. das programm verfügt über eine mavlink-schnittstelle, sowie kamera- und joystick-integration. die installation erfolgt über folgenden befehl\n\n```\nsudo usermod -a -g dialout $user\nsudo apt-get remove modemmanager -y\nsudo apt install gstreamer1.0-plugins-bad gstreamer1.0-libav gstreamer1.0-gl -y\nsudo apt install libqt5gui5 -y\n```\n\nim anschluss kann [qgroundcontol](https://d176tv9ibo4jno.cloudfront.net/latest/qgroundcontrol.appimage) heruntergeladen werden.\num die video-funktion nutzen zu können, müssen für den gstreamer die plugins bad und libav installiert werden.\n\n#### mavros\num mavros zu installieren werden folgende befehle ausgeführt.\n```\nsudo apt-get install ros-kinetic-mavros ros-kinetic-mavros-extras\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\nsudo bash ./install_geographiclib_datasets.sh\n```\n\n#### pymavlink\npymavlink wird für das core package benötigt. um es zu installieren, werden folgende befehle verwendet.\n```\nsudo apt-get install gcc python-dev libxml2-dev libxslt-dev\nsudo apt-get install python-numpy python-pytest\nsudo python -m pip install --upgrade future lxml\nsudo python -m pip install --upgrade pymavlink\n```\n\n#### netzwerk\n\nder topside computer benötigt die statische ip-adresse ***192.168.2.1*** um mit dem bluerov2 kommunizieren zu können.\n\n---\n## inbetriebnahme\n\n### bluerov2\n1. verbindungsaufbau mit dem bluerov2 über ssh\n2. starten des video-streams\n   ```\n   gst-launch-1.0 v4l2src device=/dev/video2 ! queue ! video/x-h264,width=1920,height=1080,framerate=30/1 ! h264parse ! rtph264pay ! udpsink host=192.168.2.1 port=5600\n   ```\n3. starten des usbip server\n   ```\n    sudo modprobe usbip-host\n    sudo usbipd -d\n    sudo usbip bind -b \"bus-id\"\n    ```\n4. starten von mavlink\n    ```\n    mavproxy.py --master /dev/ttyacm0 --baudrate 921600 --aircraft bluerov --out 192.168.2.1:14550\n    ```\n\n--> die arbeitsschritte 2-4 wurden in einem skript automatisiert. dieses lässt sich durch folgenden befehl ausführen:\n    ```\n    ./startup.bash\n    ```\n\n### topside computer\nje nach anwendungsfall, kann man mit qgroundcontroll oder ros arbeiten.\n\n#### sonar über usbip einbinden\num das sonar über usbip einzubinden, werden folgende befehle ausgeführt.\n```\nsudo modprobe vhci-hcd\nsudo usbip attach -r 192.168.2.2 -b 1-1.4\n```\n\n#### launchfiles übersicht\n\num nur das videobild der kamera zu erfassen, kann man folgendes launchfile starten. dies muss vor dem start des bluerov2_node launchfiles erfolgen.\n```\nroslaunch core video.launch\n```\nfür eine manuelle steuerung des bluerovs mittels joystick startet man\n```\nroslaunch core user_mav.launch\n```\ndas folgende launchfile stellt elementare [topics](https://github.com/vincent1334/bluerov2-ros/tree/main/src/core/src/bridge) für den bluerov2 zur verfügung.\n```\nroslaunch core bluerov2_node.launch\n```\n"
  },
  {
    "readme": "# Laboratory work on programming\n\nWelcome to the repository with my lab programming work! here you will find the completed tasks as well as a description of each lab work.\n\n## Repository structure\n\n\nм ─ c-plus-plus/semester-2/ # folder with materials on laboratory work in c++\n\n←  ─ Task1 # Various Tasks\n\n←  ─ Task 2 # Going After Each Other\n\n← ке ─ task3 # in each folder that contains solutions\n\nversus versus...\n\n←  ─ var-4 # tag variant\n\n♥\n\n\nм─ python/semester-2/ # folder with materials on laboratory work on python\n\n ─ ─ task1 # various tasks\n\n  ─ Task 2 # Going After Each Other\n\nке─ ─ task3 # in each folder that contains solutions\n\nObjective...\n\n ─ var-4 # option label\n\n\n## reviews and suggestions\n\nIf you have feedback, suggestions or comments on the work done, feel free to create an issue or pull request. your feedback will help me improve the quality of the work and make the repository more useful for everyone.\n\n#\n\nIf you have any questions or problems with performing laboratory work, do not hesitate to contact me at the following contacts:\n\n#license\nAll laboratory works are licensed under the mit license, which allows free use of the code for educational and commercial purposes, indicating authorship.\n",
    "readme_before": "# лабораторные работы по программированию\n\nдобро пожаловать в репозиторий с моими лабораторными работами по программированию! здесь вы найдете выполненные задания, а также описание каждой лабораторной работы.\n\n## структура репозитория\n\n\n├── c-plus-plus/semester-2/  # папка с материалами по лабораторным работам по c++\n\n│   ├── task1                # различные задания\n\n│   ├── task2                # идущие друг за другом\n\n│   ├── task3                # в каждой папке которых лежат решения\n\n│   │    ...\n\n│   └── var-4                # метка варианта\n\n│\n\n\n└── python/semester-2/       # папка с материалами по лабораторным работам по python\n\n    ├── task1                # различные задания\n    \n    ├── task2                # идущие друг за другом\n    \n    ├── task3                # в каждой папке которых лежат решения\n    \n    │    ...\n    \n    └── var-4                # метка варианта\n\n\n## отзывы и предложения\n\nесли у вас есть отзывы, предложения или замечания по выполненным работам, не стесняйтесь создать issue или pull request. ваша обратная связь поможет мне улучшить качество работ и сделать репозиторий более полезным для всех.\n\n## связь\n\nесли у вас возникли вопросы или проблемы с выполнением лабораторных работ, не стесняйтесь обращаться ко мне. по следующим контактам:\n\n## лицензия\nвсе лабораторные работы лицензируются под лицензией mit, что позволяет свободно использовать код для образовательных и коммерческих целей с указанием авторства.\n"
  },
  {
    "readme": "# tfg: * cloud computing and optimization: implementation of open cloud data applications *\n\n! [python ci] (https: / / github.com / pablojjimenez / tfg / actions / workflows / python _ ci.yaml / badge.svg)\n(https: / / github.com / pablojjimenez / tfg / actions / workflows / check-spelling.yaml / badge.svg)\n! [build latex] (https: / / github.com / pablojjimenez / tfg / actions / workflows / build-latex.yaml / badge.svg)\n\n- 124; author - 124; guardian - 124;\n- 124; - ---: - 124; - ---: - 124;\n(https: / / github.com / pabloj1808)\n\n# # motivation\nThe motivation is to facilitate studies on the evolution of death by cause of death by taking advantage of the public data published annually.\n\n# # objectives\nThe aim is for the system to be able to give users the ability to know the evolution of the causes of death. so that the stored data can be easily consulted. the causes of death are classified according to the international classification of diseases and to different variables. the system must serve the target users of the app (candidates to use this software in the future), the tool of fictitious people has been used to identify them.\n\n# # people\nIn this way, both for the part of development and for the part of the person concerned in the final product, a better idea of its objectives can be made, but also to justify its creation.\n\nI will try to create three personalities as varied as possible in order to focus even more on the user and give more quality to the final result, so that we can fully cover the environment of influence of the problem.\n\n\n- 124; name - 124; raquel - 124;\n- 124; --- - 124; --- - 124;\n- 124; age - 124; 30 - 124;\n- 124; profession - 124; senior front developed - 124;\n- 124; personality - 124; sportsmanship. - 124;\n- 124; what is your environment? - 124; your friends. his cat. His books. - 124;\n- 124; what devices do you use on your day-to-day? - 124; a laptop. - 124;\n\"124; what is your attitude to technology?\" 124; lazy. - 124;\n\n- 124; name - 124; isabel - 124;\n- 124; --- - 124; ----------------------------------------------------------------------------------- - 124;\n- 124; age - 124; 45 - 124;\n- 124; profession - 124; mathematics - 124;\n- 124; personality - 124; adventure. - 124;\n- 124; what is your environment? - 124; your family, your parents, your work. - 124;\n- 124; what devices do you use on your day-to-day? - 124; a computer on the table. - 124;\n- 124; what was his attitude towards technology? - 124;\n\n# # generation of documentation\nthe documentation is continuously delivered in the [releases] (https: / / github.com / pablojjimenez / tfg / releases / tag / 0.0.1) of the repository.\n\n# # license\nThis project is published under the licence [gnu general public license v3] (https: / / opensource.org / licenses / gpl-3.0)\n\n----\n[inspired by this template] (https: / / github.com / jj / planta-tfg-etsiit)\n",
    "readme_before": "# tfg: *computación y optimización en la nube: implementación de aplicaciones de datos abiertos en la nube*\n\n![python ci](https://github.com/pablojjimenez/tfg/actions/workflows/python_ci.yaml/badge.svg)\n![check spelling](https://github.com/pablojjimenez/tfg/actions/workflows/check-spelling.yaml/badge.svg)\n![build latex](https://github.com/pablojjimenez/tfg/actions/workflows/build-latex.yaml/badge.svg)\n\n| autor | tutor |\n|:---:|:---:|\n| [pablo jiménez jiménez](https://github.com/pablojj1808) | [juan julian merelo guervos](https://github.com/jj) |\n\n## motivación\nla motivación es facilitar los estudios sobre la evolución de las defunciones según causa de muerte aprovechando los datos públicos que se publican anualmente.\n\n## objetivos\nel objetivo es que el sistema sea capaz de darle a los usuarios la capacidad de conocer la evolución de las causas de muerte. de forma que se pueda consultar de forma sencilla los datos almacenados. las causas de muerte están clasificadas según la clasificación internacional de enfermedades y atendiendo a distintas variables. el sistema debe de atender a los usuarios diana de la app (candidatos a utilizar este software en un futuro), para identificarlos se ha utilizado la herramienta de personas ficticias.\n\n## personas\nde esta forma, tanto por la parte del desarrollo como por la del interesado en el producto final, pueden no solo hacerse una mejor idea de los objetivos del mismo, sino también justificar su creación.\n\nvoy a tratar de crear tres personalidades lo más variopintas posibles en aras de enfocarnos más aún en el usuario y dotar de mayor calidad el resultado final, de modo que podamos abarcar por completo el entorno de influencia del problema.\n\n\n| nombre | raquel |\n| --- | --- |\n| edad | 30 |\n| profesión | senior frontend developer |\n| personalidad | deportista. tímida.  lógica. |\n| ¿cuál es su entorno? | sus amigos. su gato. sus libros. |\n| ¿qué dispositivos utiliza en su día a día? | un portátil. un smartphone. |\n| ¿cuál es su actitud hacía la tecnología? | perezosa.  sabe programar. |\n\n| nombre | isabel                                                                     |\n| --- |-------------------------------------------------------------------------------|\n| edad | 45                                                                           |\n| profesión | matemática                                                             |\n| personalidad | aventurada. protagonista.                                            |\n| ¿cuál es su entorno? | su familia. sus padres.  su trabajo.                         |\n| ¿qué dispositivos utiliza en su día a día? | un ordenador de sobre mesa. un smartphone.  |\n| ¿cuál es su actitud hacía la tecnología? | valiente. proactiva.                                                           |\n\n## generación de documentación\nla documentación se entrega continuamente en las [releases](https://github.com/pablojjimenez/tfg/releases/tag/0.0.1) del repositorio.\n\n## license\neste proyecto está publicado bajo la licencia [gnu general public license v3](https://opensource.org/licenses/gpl-3.0)\n\n------\n[inspirado en esta plantilla](https://github.com/jj/plantilla-tfg-etsiit)\n"
  },
  {
    "readme": "# formula-ml\n",
    "readme_before": "# formula-ml\n"
  },
  {
    "readme": "♪ bachelorthesis ♪\n\n## Structure\n\nthe sub-folder __images__ contains the images used in the document.\n\nthe main file to be compiled is ``tesi.tex`.\n\n__bibliogarfia__ was written using the file ``bibliography.bib``.\n\n\n## forehead\nthe __frontespizio__ follows the indications given by the university but the latex has been redeveloped.\n\n#####\n\n_\n_\n_\n* ____\n* __experiments__\n* __conclusions__\n\n",
    "readme_before": "# bachelorthesis\n\n## struttura \n\nla sotto-cartella __images__ contiene le immagini utilizzate nel documento.  \n\nil file principale da compilare è ``tesi.tex``.  \n\nla __bibliogarfia__ è stata scritta ricorrendo al file ``bibliography.bib``.  \n\n\n### frontespizio\nil __frontespizio__ segue le indicazioni fornite dall'università ma è stato rimplementato il latex.\n\n### lista capitoli\n\n* __introduzione__  \n* __contesto__  \n* __neural_network__  \n* __formulazione__  \n* __esperimenti__  \n* __conclusioni__  \n\n"
  },
  {
    "readme": "# Water: a replacement for fire based on version management\n\n## background:\n\nThe workflows used on chalmers should reflect those used at a high level in the industry.\nThis includes modern version management. by incorporating version management into the submission data work\nThere is a solid foundation for working life.\nFire, the current submission data management system, does not encourage structured working methods and deficiencies for the following reasons:\n\nNew user identities for each course\nfile upload works poorly, files must be uploaded one and one\nNo built-in validation\ncommunication between correctors and submissions works poorly\nStiff user interface\n\n## Project description / problem description\n\nThe task is to design water: a submission data management system\nBased on modern version management with git.\nWater is a web application.\n\nThe system’s user interface is segmented to manage the needs of different users; submission can be made through different channels – such as direct push to a repository in the system from the version management client, browser file upload or as attached files in an email message.\n\nStudents can edit the files directly in the browser, can see how the correction work progresses (how many groups have received their submissions corrected) and the possibility is to submit anonymously if the course manager chooses it.\nThe wrists can also interact in different ways with the system. It should be possible to use advanced features relating to version management, but supervisors should also be able to get the data mailed to themselves and be able to approve with an mail response that the system processes.\n\nThe supervisors are also offered other services. flexible definition of data with subtargets. automatic validation can be used to speed up the correction process by directly rejecting submissions that do not meet certain technical requirements – such as folder structure or maximum row width. the course manager can also define unit tests that are automatically run when the task is submitted. The student receives quick feedback if the submission is rejected. Comments can be linked to specific codes, enabling two-way communication between tutors and students. Automatic plagiarism control and advanced collection of statistics are embedded in the system; in returns, the system provides the supervisor with an overview in which there are changes that have occurred.\n\nThe system consists of a backend that handles, among other things, git repositories and a frontend that presents the repositories and enables submission and correction and data. The hills receive the submissions and wrist communications through the various channels and place them in some form of queue managers who process the information and present it on front pages.\n\nThe system should be based on an existing open platform.\n\n## suggestions on features:\n\n- clear overview of differences between a first submission and successive responses to returns - the supervisor quickly sees what has changed\ndeadline for supervisors\nReadme files integrated into the system - a file that meets the definition of a readme file is automatically rendered on the submission data page\nDefinite correction for the wrists\n- a return on lab 1 shall be corrected before a first submission of lab 2.\n\n## costs\nIt may be necessary to rent server resources in the form of vps or any cloud service.\n\n## Proposals\n\n[Linus oleander](http://github.com/oleander)\n[jesper josefsson](http://github.com/jesjos)\n[arash rouhani](https://github.com/tarrasch)",
    "readme_before": "# water: en ersättning för fire, baserad på versionshantering\n\n## bakgrund:\n\narbetsflöden som används på chalmers bör spegla dem som används på hög nivå i branschen.\ndär ingår modern versionhantering. genom att införliva versionhantering i arbetet med inlämningsuppgifter\nläggs en stabil grund inför arbetslivet.\nfire, det nuvarande systemet för hantering av inlämningsuppgifter, uppmuntrar inte till ett strukturerat arbetssätt och brister även av följande anledningar:\n\n- nya användaridentiteter för varje kurs\n- filuppladdningen fungerar dåligt, filer måste laddas upp en och en\n- ingen inbyggd validering\n- kommunikation mellan rättare och inlämnare fungerar dåligt\n- stelt användargränssnitt\n\n## projektbeskrivning / problembeskrivning\n\nuppgiften är att konstruera water: ett system för hantering av inlämningsuppgifter \nsom baserar sig på modern versionshantering med git. \nwater är en webbapplikation.\n\nsystemets användargränssnitt är segmenterat för att hantera olika användares behov. inlämning kan ske genom olika kanaler - till exempel direkt push till ett repositorie i systemet från versionshanteringsklienten, filuppladdning i webbläsare eller som bifogade filer i ett e-postmeddelande.\n\nstudenter kan editera filerna direkt i webbläsaren, kan se hur rättningsarbetet fortskrider (hur många grupper som har fått sina inlämningar rättade) och möjlighet finns att lämna in anonymt om kursansvarig väljer det.\näven handledarna kan interagera på olika sätt med systemet. det ska vara möjligt att använda avancerade funktioner som relaterar till versionshantering, men handledare ska även kunna få uppgifterna mailade till sig och kunna godkänna med ett mailsvar som systemet bearbetar.\n\nhandledarna erbjuds även andra tjänster. flexibel definition av uppgifter med delmål. automatisk validering kan användas för att snabba upp rättningsprocessen genom att direkt förkasta inlämningar som inte uppfyller vissa tekniska krav - till exempel mappstruktur eller maximal radbredd. kursansvarig kan även definiera unittest som automatiskt körs när uppgiften lämnas in. studenten får snabb återkoppling om inlämningen refuseras. kommentarer kan knytas till specifika kodrader vilket möjliggör tvåvägskommunikation mellan handledare och studenter. automatisk plagiatkontroll och avancerad insamling av statistik finns inbyggt i systemet. vid returer ger systemet handledaren en översikt där det framgår vilka förändringar som har skett. \n\nsystemet består av en backend som bland annat hanterar git-repositorier samt en frontend som presenterar repositorierna och möjliggör inlämning och rättning och uppgifterna. backenden tar emot inlämningarna och handledarkommunikation via de olika kanalerna och placerar dem i någon form av köhanterare som behandlar informationen och presenterar den på frontenden.\n\nsystemet ska baseras på en befintlig öppen plattform. \n\n## förslag på features:\n\n- tydlig översikt över skillnader mellan en första inlämning och successiva svar på returer - handledaren ser snabbt vad som har förändrats\n- deadline för handledare\n- readme-filer integrerade i systemet - en fil som uppfyller definitionen av en readme-fil renderas automatiskt på inlämningsuppgiftssidan\n- bestämd rättningsordning för handledarna\n  - en retur på labb 1 ska rättas före en förstainlämning på labb 2.\n\n## kostnader\ndet kan bli nödvändigt att hyra in server-resurser i form av vps eller någon molntjänst.\n\n## förslagslämnare\n\n- [linus oleander](http://github.com/oleander)\n- [jesper josefsson](http://github.com/jesjos)\n- [arash rouhani](https://github.com/tarrasch)"
  },
  {
    "readme": "# guide\n> ** Note:** [the instructions in German](# guide) can be found below.\n\n> **Translated from german by chatgpt\n\nwith the *transit reachability analyser* plugin, public transport reachability can be calculated and visualized. starting from a given point, the fast route to each station in the public transport network is calculated using opentripplanner (otp). as a result, a dataset is created in which each station is represented as a point on the map. in qgis, a dataset comprising points is referred to to as a point layer. various information is provided for each station, including the effort indicators such as travel time, travel time ratio, walking time, and walking distance to the first stop, as well as transfer frequency. additionally, it indicates which public transport connections were identified for the station and which one was selected. information in qgis is referred to as attributes and can be displayed via the attribute table of the point layer.\n\na heatmap can be created for each indicator by coloring the points on the map. in addition to points, areas can thus be colored. these can be isochrones or buildings, for example. an isochrone includes all points that can be reached from a starting point within a specified time frame.\n\n> **note:** the *transit reachability analyser* plugin was developed as part of a bachelor's thesis. the results were only spot-checked for plausibility. a thorough investigation of the results was not conducted. anomalous data should be compared with additional sources.\n\nTable of contents\n\n- [guide](#guide)\n- [quick guide](#quick-guide)\n- [detailed guide](#detailed-guide)\n- [preparing the gtfs feed](#preparing-the-gtfs-feed)\n- [downloading the gtfs feed](#downloading-the-gtfs-feed)\n- [filtering the gtfs feed](#filtering-the-gtfs-feed)\n- [downloading the .osm.pbf file](#downloading-the-osmpbf-file)\n- [starting otp](#starting-otp)\n- [using the transit reachability analyser](#using-the-transit-reachability-analyser)\n- [installation](#installation)\n- [reachability analysis](#reachability-analysis)\n- [layer symbolization](#layer symbolization)\n- [symbolizing isochronous layers](#symbolizing-isochrone layers)\n- [symbolizing building layers](#symbolizing building layers)\n- [evaluating data](#evaluating data)\n- [possible solutions](#possible-solutions)\n- [otp cannot be started](#otp-cannot-be-started)\n- [otp crashes when starting the server](#otp-crashes-when-starting-the-server)\n- [problems with the transit reachability analyser](#problems-with-the-transit-reachability-analyser)\n- [layer not found on the map](#layer-not-found-on-the-map)\n- [distorted representation of layers](#distorted-representation-of-layers)\n- [german version](#instructions)\n\nexample heatmap of the travel time indicator for point and polygon layers, own representation, map data from [openstreetmap](https://www.openstreetmap.org):\n\n![point-polygon_bsp.png](point-polygon_bsp.png)\n\nexcerpt from the attribute table: route main station - dedekindstraße:\n\n** **name** | brown, dedekindstraße |\n...\n**travel time [min]** | 19 |\n**travel time ratio**\n**itinerary frequency [min]** | 30 |\n**walk time [min]**\n**walk distance [m]** 104.1 |\n**number of transfers**\n**travel time car [min]** | 15.6 |\n**max distance station to stop [m]** | 44.5 |\n| **selected routes** | ['walk', '411', 'walk'], duration: 19, frequency: 30.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: browntail main station, laststop: browntail, dedekindstraße; |\n**possible itineraries** | ['walk', '4', 'walk', '421', 'walk'], duration: 35, frequency: 15.0, meters_first_stop: 157.0, walktime_to_first_swalk: 1.9, firststop: brownish, main station/viewegs garden, laststop:> |\n\n# Quick guide\n\n1. prepare the gtfs feed ([details](#preparing-the-gtfs-feed))\n1. download the gtfs feed. For example,\n2. filter the gtfs feed using [gtfstools](https://ipeagit.github.io/gtfstools/) ([details](#filtering-the-gtfs-feed)).\n\n2. download to .osm.pbf file from [protomaps](https://app.protomaps.com/) that correspond to the area of the gtfs feed ([details](#downloading-the-osm-pbf-file)).\n\n3. start [opentripplanner 2.5](https://docs.opentripplanner.org/en/latest/basic-tutorial/) via the terminal ([details](#starting-otp).\n\n4. install and open the *transit reachability analyser*.\n1. reachability analysis ([details](#reachability-analysis))\n1. specify the coordinates of the starting point.\n2. set the investigation date and period.\n3. choose walking speed and maximum walking time.\n4. specify the storage location for the point layer.\n5. start the calculation by clicking the *reachability analysis* button.\n2. optional: create isochronous layers or building layers with attribute values ([details](#symbolizing-isochrone-layers)).\n3. symbolizing the data ([details](#symbolizing-isochrone-layers))\n1. the otp server is not required for this.\n2. choose a layer (point or polygon layer).\n3. specify the indicator to be displayed.\n\ndetailed guide\n\nin the *transit reachability analyser*, the reachability of stops is to be calculated. for simplification, stops with the same name are grouped into one destination. a destination that aggregates multiple stops is referred to as a station in this work. the common name of the stops is used as the name of the station. Typical, a stationary two stops. however, there are bigger stations that encompass more than two stops with the same name.\n\n### preparing the gtfs feed\n\ngtfs feeds enable opentripplanner (otp) to calculate public transport connections. they contain information about the line offerings and travel times, among other things.\n\n#### downloading the gtfs feed\n\nthere are various providers from which gtfs feeds can be downloaded. this plugin requires gtfs schedule feeds. some transport companies offer gtfs feeds directly for their area. for example, the company [connect](https://connect-fahrplanauskunft.de/) provides a gtfs feed for lower saxony, germany. the gtfs feed from delfi e.v. covers all of germany and can be downloaded via the [open data öpnv](https://www.opendata-oepnv.de/ht/de/willkommen) portal. older gtfs feeds are available under the *archive* tab.\n\n♪ filtering the gtfs feed\n\nthe *transit reachability analyser* attempts to calculate a connection to each station from the starting point. the more stops present in the gtfs feed, the longer the calculation takes. **therefore, it is recommended to use a gtfs feed that only covers the area of investigation.** if that is already the case, this section can be skipped. otherwise, the following is required:\n\n- gtfs feed\n- r\n- rstudio (optional)\n- [gtfstools](https://ipeagit.github.io/gtfstools/)\n\nthe goal is to filter all data of a transport company from a larger gtfs feed. the file `agency.txt` in the gtfs feed lists all transport companies whose traffic information is represented in the gtfs feed. in the end, each file of the gtfs feed should only contain information related to that one transport company. to achieve this, gtfstools is used. gtfstools is an r programming language package that allows gtfs feeds to be filtered, among other things, using the `agency_id`. the rstudio ide provides an environment for working with r\n\nafter r and rstudio have been installed, gtfstools is installed with the following command:\n```r\ninstall.packages(\"gtfstools\") \n```\n\nafter that, the lines in the following code block can be executed step by step. please note the following:\n\n- the `agency_id` of the used transport company can be found in the gtfs feed in the file `agency.txt`.\n- the file path must be adjusted. it is important to refer to the .zip file. for windows, the `r` and the parentheses must be retained.\n- the new file name must contain *gtfs*, otherwise otp will not be able to find the file.\n\n```r\nlibrary(gtfstools)\npath <- r\"(c:\\users\\username\\documents\\gtfs_feed_name.zip)\"\ngtfs <- read_gtfs(path)\nsmaller_gtfs <- filter_by_agency_id(gtfs, \"12021\") # hier die agency_id ersetzen.\nfilename <- r\"(c:\\users\\username\\documents\\filtered_gtfs_feed_name.zip)\"\nwrite_gtfs(smaller_gtfs, filename)\n```\n\n### downloading the .osm.pbf file\n\nin addition to a gtfs feed for the public transport offer, otp also requires information about the associated network of paths. this allows, for example, the calculation of walking routes to stops. for this, otp uses the pbf format, which stores the information of a section of the osm map in a file.\n\nthere are various ways to obtain an .osm.pbf file. the following tools will be used for the next steps:\n\n- unzipped gtfs feed\n- qgis\n- quickmapservices plugin\n- protomaps website\n\nit is important at this point that the map in the .osm.pbf file covers at least the area of the gtfs feed. to ensure this, the following steps are necessary:\n\n1. in qgis, open the *data source manager* (ctrl+l).\n2. open the *delimited text* section.\n3. at the top under *file name*, open the stops.txt file of the reduced gtfs feed.\n4. click on *add*.\n5. add the osm map as background using the quickmapservices plugin.\n6. open the [protomaps](https://app.protomaps.com/) website.\n7. protomaps allows the creation of a customized map section. align the section in protomaps with the location of the stops in qgis so that the section includes all stops.\n8. use *create extract* to create and download the .osm.pbf file.\n\n### starting otp\n\n[opentripplanner](https://docs.opentripplanner.org/en/latest/basic-tutorial/) is a multimodal route planner. the plugin uses this as a backend for the calculation of public transport routes. otp calculates a graph representing the transport network based on the gtfs feed and the .osm.pbf file. otp provides a server that can be interacted with through a web browser. before a calculation can be started with the *transit reachability analyser*, this server must be running. to start otp, the following is required:\n\n- java runtime (jre) or java development kit (jdk) version 21 or newer.\n- opentripplanner version otp 2.5.0 or newer. to do this, select the desired version on the linked page and download the file with the extension `shaded.jar` [here](https://repo1.maven.org/maven2/org/opentripplanner/otp/).\n\nthe following steps can be taken to start otp, so that a local server is ready:\n\n1. place the otp file, the gtfs feed, and the .osm.pbf file in a common folder that contains no other files (e.g., `otp_city`).\n2. ensure that the name of the gtfs feed contains *gtfs*.\n3. open the terminal.\n4. with the following command, otp will create a graph:\n   ```bash\n   java -xmx2g -jar c:\\users\\username\\documents\\otp_city\\\n      otp-2.5.0-shaded.jar --build --serve c:\\users\\username\\documents\\otp_city\n   ```\n5. wait until *grizzly server running* appears in the terminal. depending on the file size, this may take several minutes.\n\nnotes:\n\n- the file path is an example for windows.\n- if a folder in the file path contains a space in its name, the terminal may encounter issues.\n- `-xmx` specifies the maximum amount of memory that otp can use. since gtfs feeds and .osm.pbf files are relatively large, otp requires a significant amount of memory.\n- if starting the server fails, it can be attempted again with more than 2 gb of memory, while keeping the computer's limits in mind.\n- in addition to `--build` and `--serve`, there are other execution options available. for example, a graph can be saved and accessed again, saving time for regular use of the same graph. details on this can be found in the [otp documentation](https://docs.opentripplanner.org/en/latest/basic-tutorial/).\n\n### using the transit reachability analyser\n\nthe following sections will explain the installation and usage of the plugin. additionally, the steps needed to color isochrones or buildings using the *transit reachability analyser* will be shown.\n\n#### installation\n\nfor the *transit reachability analyser* to work, the following python packages must be installed in qgis:\n\n- requests\n- json\n- geopandas\n- pandas\n- geopy\n\nit is quite possible that the packages are already installed. if not, qgis will display an error message during the installation of the plugin or when starting it. in that case, the packages must be manually installed via `pip`. the method for doing this in qgis varies by operating system. the following steps are recommended for windows:\n\n- open the osgeo4w shell. this was installed along with qgis.\n- ```bash\n   python -m pip install {package name}\n   ```\n#### reachability analysis\n\nto perform an reachability analysis, a value must be defined for each bolded category.\n\n- the starting point of the calculation must be specified using coordinates. the coordinates of a point can be copied from [openstreetmap](https://www.openstreetmap.org). by right-clicking on the appropriate point, the option *show address* can be selected. this will display the coordinates in the *search field*.\n- a gtfs feed is only valid for a specific time. when choosing the day, the date should fall within this timeframe.\n- when entering values, it is especially important to pay attention to the syntax of the input. the examples in the respective fields can serve as a guide.\n- after selecting the walking speed and walking time, the resulting distance in meters can be calculated. this step is optional and serves as a guideline.\n- if otp is started according to the above instructions, the server will start on port number 8080. this setting only needs to be changed if a different port number was specified when starting otp. if it is unclear whether the connection to otp works, it can be tested using the appropriate button. this step is optional.\n- by confirming the **get all stops** button, a point layer with all stops will be created. the attribute table contains a column listing all departure times of each line within the selected time window.\n- the **get all stations** button creates a point layer where each point summarizes all stops with the same name. no reachability calculations are performed yet, so the runtime is short, but the attribute table remains empty.\n- the **reachability analysis** button performs the reachability analysis. otp calculates various connections from the starting point to each station. the plugin selects the fastest connection from the proposed options. based on the values of this connection, the travel effort indicators are set. the more stations are located in the area, the longer the calculations will take. depending on processing power, it may take a few minutes for the calculations to finish and for qgis to become usable again.\n\n#### layer symbolization\n\nduring symbolization, the columns in the attribute table are used. therefore, it is important that the names of the columns are not changed. the position can be altered. a layer and an indicator to be symbolized must always be selected. symbolization can be modified for both point and polygon layers.\n\n#### symbolizing isochrone layers\n\n**calculating isochrones**\n\n- install the valhalla plugin.\n- open *toolbox - valhalla - pedestrian - isochrones pedestrian*.\n- fossgis should be preset as the *provider*.\n- choose a point layer generated with the transit reachability analyser as the *input point layer*.\n- select the name as the *input layer id field*. this step is important because the rest of the attributes will be correctly assigned later based on this name.\n- the *mode* of *shortest* has proven effective.\n- specify the isochrone size.\n- start the calculation.\n\nin principle, other plugins can also be used. however, an api key is usually required, which must first be created (for free). this is not necessary for fossgis. additionally, relatively many isochrones need to be calculated. some providers set a limit on the number of calculations per minute, which can prolong the process.  \nthe size of the isochrones should correspond to a distance that is to be covered at most, for example, 5 minutes. to define the isochrones in valhalla using a kilometer specification, time and speed must be converted to distance.  \nwhen entering, use a point for decimal values. the comma separates the different sizes of isochrones.\n\n**assigning attributes to isochrones**\n\n- open *toolbox - general vector - link attributes by field value*.\n- *input layer*: polygon layer with the calculated isochrones.\n- *table column*: name.\n- *input layer 2*: point layer with the attribute table generated by the transit reachability analyser.\n- *table field 2*: name.\n- *layer 2 fields to copy*: select all columns to be copied via the button with three dots on the right.\n- start.\n- launch the *transit reachability analyser* and select the isochrone layer for symbolization.\n\nit is crucial that the name column in both the point layer and the isochrone layer are the same. this is definitely true for the layer from which the isochrones were generated. it is advisable to duplicate the isochrone layer to keep an unchanged layer. this way, the isochrones do not need to be recalculated every time.\n\n#### symbolizing building layers\n\n**downloading the buildings layer**\n\n- install the quickosm plugin.\n- open *vector - quickosm - quickosm*.\n- in *map settings*, select *urban*. alternatively, use the *key* *building* in *fast query*.\n- for the download area, select *layer extent* from the dropdown menu and use a point layer from the transit reachability analyser.\n\n**assigning attributes to buildings**\n\n- open *toolbox - general vector - link attributes by location*.\n- *link to objects in*: buildings layer.\n- *location of objects*: select intersects.\n- *by comparing with*: isochrone layer with attributes.\n- *fields to add*: select all desired attributes via the button with three dots.\n- in the dropdown menu, select *create separate object for each matching object (one-to-many)*.\n- start.\n- select the new layer in transit reachability analyser and change symbolization.\n\nit is important that the text field for *prefix for linked fields* remains empty. otherwise, the column names will be altered, and the symbolization of the transit reachability analyser will no longer function.\n\n### evaluating data\n\nwhen evaluating the data, it should be noted that the results only apply to the one starting point. the results cannot and should not be generalized to the entire network and total offering.  \nin a non-representative evaluation of the data, it was found that the connections proposed by otp are optimized for few transfers and not for the shortest travel time.  \nthe information in the attribute table on walking distances refers only to the path to the first stop. the remaining walking paths, such as those during a transfer or between the last stop and the destination, are not directly considered. they only contribute to the travel time.  \nsome calculations of the path length from the last stop to the corresponding station are unrealistically long, which extends the travel time.  \nthe frequency is only calculated based on the first departures of a connection. therefore, a frequency change within a search window is not visible. if the focus of the analysis is on frequency, care should be taken that the frequency at the beginning of the time window is representative of the analyzed period.  \ndue to unexpected returns from otp, the frequency calculation is not always accurate. in some cases, the calculated frequency can be better than the actual frequency. if certain values seem unrealistic, they should be double-checked.\n\n### possible solutions\n\nin the following sections, problems that may occur when using the *transit reachability analyser* will be addressed. if further problems arise, forums for qgis or otp can be consulted. alternatively, a [pull request](https://github.com/thanderjoren/transitreachabilityanalyser/pulls) for the *transit reachability analyser* can also be written.\n\n#### otp cannot be started\n\nin the terminal, spaces in a file path cause errors. there should be no spaces in the entire file path specified when starting otp. if this cannot be avoided, the file path must be enclosed in quotes on windows.\n\n#### otp crashes when starting the server\n\ngtfstools does not always filter the gtfs feed from delfi e.v. correctly. as a result, otp may not be able to start the server. in advance, the gtfs feed can be checked using the [gtfs validator](https://gtfs-validator.mobilitydata.org/). if the report contains *error*, the gtfs feed cannot be used with otp. a few *error* messages can be fixed manually. alternatively, there is the tool [gtfstidy](https://github.com/patrickbr/gtfstidy), which can likely improve gtfs feeds. *warnings* do not need to be addressed.\n\n\n#### problems with transit reachability analyser\n\nif the plugin cannot be executed, checking the qgis log can be helpful. there, the *warning* specifies the error preventing the plugin from running. the *info* above it indicates what needs to be changed to avoid the error.  \nif nothing is calculated despite proper execution, this might be due to the day of calculation. a gtfs feed is only valid for a certain timeframe. if the calculation day falls outside this range, nothing will be calculated, and no error will be reported. to rule out this error, it is best to choose the day the gtfs feed was downloaded as the calculation day.\n\n#### layer not found on the map\n\nif a layer cannot be found on the map, the first step is to check whether the layer is set to be visible. if so, you can right-click on the layer and select the option *zoom to layer*. this will help determine where the layer is displayed. a representation in the wrong location may be due to the choice of the coordinate reference system (crs).\n\n#### distorted representation of layers\n\n*transit reachability analyser* exports point layers using the coordinate reference system (crs) epsg:4326 wgs84. otherwise, the points would be displayed in the wrong location. in contrast, the osm background map uses the crs epsg:3857 wgs84/pseudo-mercator. to ensure this map is displayed without distortion, the crs of the entire project must be set to epsg:3857. this can be adjusted at the bottom right in qgis.\n\n-----------------------\n# anleitung\n\nmit dem plugin *transit reachability analyser* können erreichbarkeiten des öpnv berechnet und dargestellt werden. von einem startpunkt aus wird zu jeder station des öpnv-netzes mithilfe von opentripplanner (otp) die schnellste verbindung berechnet. als ergebnis wird ein datensatz erstellt, indem jede station einen punkt auf der karte repräsentiert. in qgis wird ein datensatz, bestehend aus punkten, punktlayer genannt. zu jeder station werden verschiedene informationen bereitgestellt. dazu gehören die reiseaufwandsindikatoren reisezeit, reisezeitverhältnis, gehzeit und gehdistanz zur ersten haltestelle sowie die umsteigehäufigkeit. zusätzlich wird angegeben, welche öpnv-verbindungen zu der station ermittelt wurden und welche daraus ausgewählt wurde. informationen werden in qgis als attribute bezeichnet und lassen sich über die attributtabelle des punktlayers anzeigen.\n\nfür jeden indikator kann eine heatmap erstellt werden, indem die punkte auf der karte eingefärbt werden. neben punkten können auch flächen eingefärbt werden. das können zum beispiel isochronen oder gebäude sein. eine isochrone beinhaltet alle punkte, die von einem startpunkt aus innerhalb einer vorgegebenen zeitspanne erreichbar sind.\n\n> **hinweis:** das plugin *transit reachability analyser* ist im rahmen einer bachelorarbeit entstanden. die ergebnisse wurden nur in stichproben auf plausibilität geprüft. eine ausführliche untersuchung der ergebnisse wurde nicht durchgeführt. auffällige daten sollten mit zusätzlichen quellen verglichen werden.\n\n## inhaltsverzeichnis\n\n- [anleitung](#anleitung)\n  - [kurzanleitung](#kurzanleitung)\n  - [ausführliche anleitung](#ausführliche-anleitung)\n    - [gtfs-feed vorbereiten](#gtfs-feed-vorbereiten)\n      - [gtfs-feed herunterladen](#gtfs-feed-herunterladen)\n      - [gtfs-feed filtern](#gtfs-feed-filtern)\n    - [.osm.pbf-datei herunterladen](#osmpbf-datei-herunterladen)\n    - [otp starten](#otp-starten)\n    - [transit reachability analyser nutzen](#transit-reachability-analyser-nutzen)\n      - [installation](#installation)\n      - [erreichbarkeitsanalyse](#erreichbarkeitsanalyse)\n      - [layer symbolisierung](#layer-symbolisierung)\n      - [isochronenlayer symbolisieren](#isochronenlayer-symbolisieren)\n      - [gebäudelayer symbolisieren](#gebaeudelayer-symbolisieren)\n    - [daten auswerten](#daten-auswerten)\n    - [mögliche problemlösungen](#moegliche-problemloesungen)\n      - [otp lässt sich nicht starten](#otp-laesst-sich-nicht-starten)\n      - [otp bricht beim starten des servers ab](#otp-bricht-beim-starten-des-servers-ab)\n      - [probleme mit transit reachability analyser](#probleme-mit-transit-reachability-analyser)\n      - [layer ist auf der karte nicht zu finden](#layer-ist-auf-der-karte-nicht-zu-finden)\n      - [verzerrte darstellung der layer](#verzerrte-darstellung-der-layer)\n\n\n\nbeispiel heatmap des indikators reisezeit für punkt- und polygonlayer, eigene darstellung, kartendaten von [openstreetmap](https://www.openstreetmap.org):\n\n![punkt-polygon_bsp.png](punkt-polygon_bsp.png)\n\nauszug aus der attributtabelle: strecke hauptbahnhof - dedekindstraße:\n\n| **name**                                    | braunschweig, dedekindstraße                                                                                                                                                                                                                     |\n|---------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **travel time [min]**                      | 19                                                                                                                                                                                                                                                  |\n| **travel time ratio**                       | 1.2                                                                                                                                                                                                                                                 |\n| **itinerary frequency [min]**               | 30                                                                                                                                                                                                                                                  |\n| **walk time [min]**                         | 1.2                                                                                                                                                                                                                                                 |\n| **walk distance [m]**                       | 104.1                                                                                                                                                                                                                                               |\n| **number of transfers**                     | 0                                                                                                                                                                                                                                                   |\n| **travel time car [min]**                   | 15.6                                                                                                                                                                                                                                                |\n| **max distance station to stop [m]**       | 44.5                                                                                                                                                                                                                                                |\n| **selected itinerary**                      | ['walk', '411', 'walk'], duration: 19, frequency: 30.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: braunschweig hauptbahnhof, laststop: braunschweig, dedekindstraße;                                           |\n| **possible itineraries**                    | ['walk', '4', 'walk', '421', 'walk'], duration: 35, frequency: 15.0, meters_to_first_stop: 157.0, walktime_to_first_stop: 1.9, firststop: braunschweig, hauptbahnhof/viewegs garten, laststop: braunschweig, dedekindstraße;<br> ['walk', '411', '421', 'walk'], duration: 23, frequency: 15.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: braunschweig hauptbahnhof, laststop: braunschweig, dedekindstraße; |\n\n## kurzanleitung\n\n1. gtfs-feed vorbereiten ([details](#gtfs-feed-vorbereiten))\n   1.  gtfs-feed herunterladen. zum beispiel von [delfi e.v.](https://www.opendata-oepnv.de/ht/de/organisation/delfi/startseite?tx_vrrkit_view%5baction%5d=details&tx_vrrkit_view%5bcontroller%5d=view&tx_vrrkit_view%5bdataset_formats%5d%5b0%5d=zip&tx_vrrkit_view%5bdataset_name%5d=deutschlandweite-sollfahrplandaten-gtfs&chash=01414d5793fcd0abb0f3a2e35176752c) oder [connect](https://connect-fahrplanauskunft.de/datenbereitstellung/) ([details](#gtfs-feed-herunterladen)).\n   2. gtfs-feed filtern mithilfe von [gtfstools](https://ipeagit.github.io/gtfstools/) ([details](#gtfs-feed-filtern)).\n\n2. eine .osm.pbf-datei bei [protomaps](https://app.protomaps.com/) herunterladen, die dem gebiet des gtfs-feeds entspricht ([details](#osmpbf-datei-herunterladen)).\n\n3. [opentripplanner 2.5](https://docs.opentripplanner.org/en/latest/basic-tutorial/) über das terminal starten ([details](#otp-starten)).\n\n4. *transit reachability analyser* installieren und öffnen.\n   1. erreichbarkeitsanalyse ([details](#erreichbarkeitsanalyse))\n      1. koordinaten des startpunktes angeben.\n      2. untersuchungstag und -zeitraum festlegen.\n      3. gehgeschwindigkeit und maximale gehzeit wählen.\n      4. speicherort für den punktlayer festlegen.\n      5. berechnung durch button *reachability analysis* starten.\n   2. optional: isochronenlayer oder gebäudelayer mit attributwerten erstellen ([details](#isochronenlayer-symbolisieren)).\n   3. symbolisierung der daten ([details](#isochronenlayer-symbolisieren))\n      1. hierfür wird der otp-server nicht benötigt.\n      2. layer wählen (punkt- oder polygonlayer möglich).\n      3. darzustellenden indikator festlegen.\n\n## ausführliche anleitung\n\nin *transit reachability analyser* soll die erreichbarkeit von haltestellen berechnet werden. zur vereinfachung werden haltestellen mit gleichem namen zu einem ziel zusammengefasst. ein ziel, das mehrere haltestellen zusammenfasst, wird in dieser arbeit station genannt. als name der station wird der gemeinsame name der haltestellen genutzt. in der regel fasst eine station zwei haltestellen zusammen. es gibt aber auch größere stationen, die mehr als zwei haltestellen mit gleichem namen vereinen.\n\n### gtfs-feed vorbereiten\n\ngtfs-feeds ermöglichen es, opentripplanner (otp) öpnv-verbindungen zu berechnen. sie enthalten unter anderem informationen über das linienangebot und die fahrzeiten.\n\n#### gtfs-feed herunterladen\n\nes gibt verschiedene anbieter, über die gtfs-feeds heruntergeladen werden können. für dieses plugin werden gtfs-schedule-feeds benötigt. manche verkehrsunternehmen bieten für ihr gebiet direkt einen gtfs-feed an. häufig gibt es aber gtfs-feeds, die eine größere region abdecken und dadurch das angebot verschiedener verkehrsunternehmen enthalten. für niedersachsen stellt zum beispiel das unternehmen [connect](https://connect-fahrplanauskunft.de/) einen gtfs-feed zur verfügung. der gtfs-feed von delfi e.v. deckt ganz deutschland ab und lässt sich über das portal [open data öpnv](https://www.opendata-oepnv.de/ht/de/willkommen) herunterladen. über den reiter *archiv* sind auch alte gtfs-feeds verfügbar.\n\n#### gtfs-feed filtern\n\n*transit reachability analyser* versucht, vom startpunkt aus zu jeder station eine verbindung zu berechnen. je mehr stops in dem gtfs-feed vorhanden sind, desto länger dauert die berechnung. **deswegen ist es empfehlenswert, einen gtfs-feed zu nutzen, der nur das untersuchungsgebiet abdeckt.** ist das bereits der fall, kann dieser abschnitt übersprungen werden. ansonsten wird folgendes benötigt:\n\n- gtfs-feed\n- r\n- rstudio (optional)\n- [gtfstools](https://ipeagit.github.io/gtfstools/)\n\ndas ziel ist es, alle daten eines verkehrsunternehmens aus einem größeren gtfs-feed zu filtern. in der datei `agency.txt` des gtfs-feeds sind alle verkehrsunternehmen aufgelistet, deren verkehrsinformationen in dem gtfs-feed abgebildet sind. am ende sollen in jeder datei des gtfs-feeds nur noch informationen stehen, die zu dem einen verkehrsunternehmen gehören. um das zu bewerkstelligen, wird gtfstools benutzt. gtfstools ist ein package der programmiersprache r, mit dem gtfs-feeds unter anderem mithilfe der `agency_id` gefiltert werden können. die ide rstudio bietet eine umgebung, in der mit r gearbeitet werden kann.\n\nnachdem r und rstudio installiert wurden, wird mit dem folgendem befehl gtfstools installiert:\n\n```r\ninstall.packages(\"gtfstools\") \n```\n\ndanach können die zeilen in dem folgenden code-block schritt für schritt ausgeführt werden. dabei bitte folgendes beachten:\n\n- die `agency_id` des verwendeten verkehrsunternehmens lässt sich in dem gtfs-feed in der datei `agency.txt` finden.\n- der dateipfad muss angepasst werden. dabei ist es wichtig, auf die .zip-datei zu verweisen. für windows müssen das `r` und die klammern beibehalten werden.\n- der neue dateiname muss *gtfs* enthalten, sonst kann otp die datei nicht finden.\n\n```r\nlibrary(gtfstools)\npath <- r\"(c:\\benutzer\\benutzername\\dokumente\\gtfs_feed_name.zip)\"\ngtfs <- read_gtfs(path)\nsmaller_gtfs <- filter_by_agency_id(gtfs, \"12021\") # hier die agency_id ersetzen.\nfilename <- r\"(c:\\benutzer\\benutzername\\dokumente\\name_gefilterter_gtfs_feed.zip)\"\nwrite_gtfs(smaller_gtfs, filename)\n```\n\n### .osm.pbf-datei herunterladen\n\nneben einem gtfs-feed für das öpnv-angebot benötigt otp auch informationen über das zugehörige wegenetz. damit können zum beispiel fußwege zu haltestellen berechnet werden. dafür nutzt otp das format pbf, welches die informationen eines ausschnitts der osm-karte in einer datei speichert.\n\nes gibt verschiedene wege, an eine .osm.pbf-datei zu kommen. für die nächsten schritte werden folgende tools benutzt:\n\n- entpackter gtfs-feed\n- qgis\n- plugin quickmapservices\n- website protomaps\n\nwichtig ist an dieser stelle, dass die karte in der osm.pbf-datei mindestens das gebiet des gtfs-feeds abdeckt. um das sicherzustellen, sind folgende schritte nötig:\n\n1. in qgis die *datenquellenverwaltung* öffnen (strg+l).\n2. den abschnitt *getrennte texte* öffnen.\n3. ganz oben unter *dateiname* die stops.txt-datei des verkleinerten gtfs-feeds öffnen.\n4. auf *hinzufügen* klicken.\n5. über das plugin quickmapservices die osm-karte als hintergrund hinzufügen.\n6. die website [protomaps](https://app.protomaps.com/) öffnen.\n7. mit protomaps lässt sich ein individueller kartenausschnitt erstellen. den ausschnitt in protomaps mit der lage der stops in qgis abgleichen, damit der ausschnitt alle stops beinhaltet.\n8. über *create extract* die .osm.pbf-datei erstellen lassen und herunterladen.\n\n\n### otp starten\n\n[opentripplanner](https://docs.opentripplanner.org/en/latest/basic-tutorial/) ist ein multimodaler routenplaner. das plugin verwendet diesen als backend für die berechnung der öpnv-routen. otp berechnet auf basis des gtfs-feeds und der .osm.pbf-datei einen graphen, der das verkehrsnetz repräsentiert. otp stellt einen server zur verfügung, mit dem über einen webbrowser interagiert werden kann. bevor eine berechnung mit *transit reachability analyser* gestartet werden kann, muss dieser server gestartet sein. um otp zu starten, wird folgendes benötigt:\n\n- java runtime (jre) oder java development kit (jdk) mindestens in der version java 21 oder neuer.\n- opentripplanner mindestens in der version otp 2.5.0 oder neuer. dafür auf der verlinkten seite die gewünschte version auswählen und die datei mit der endung `shaded.jar` [herunterladen](https://repo1.maven.org/maven2/org/opentripplanner/otp/).\n\nmit den folgenden schritten lässt sich otp starten, sodass ein lokaler server bereitsteht:\n\n1. die otp-datei, den gtfs-feed und die .osm.pbf-datei in einen gemeinsamen ordner legen, der keine weiteren dateien enthält (z.b. `otp_stadt`).\n2. sicherstellen, dass in dem namen des gtfs-feeds *gtfs* vorkommt.\n3. terminal öffnen.\n4. mit dem folgenden befehl erstellt otp einen graphen:\n   ```bash\n   java -xmx2g -jar c:\\benutzer\\benutzername\\dokumente\\otp_stadt\\\n   otp-2.5.0-shaded.jar --build --serve c:\\benutzer\\benutzername\\dokumente\\otp_stadt\n   ```\n5. warten, bis im terminal *grizzly server running* steht. je nach dateigröße kann dies mehrere minuten dauern.\n\nhinweise:\n\n- der dateipfad ist ein beispiel für windows.\n- enthält ein ordner in dem dateipfad ein leerzeichen im namen, kann es passieren, dass das terminal probleme macht.\n- `-xmx` legt fest, wie viel speicher otp maximal nutzen darf. da gtfs-feeds und .osm.pbf-dateien relativ groß sind, braucht otp relativ viel speicher.\n- klappt das starten des servers nicht, kann es mit mehr speicher als 2 gb erneut versucht werden. dabei sollten die grenzen des computers im blick behalten werden.\n- statt `--build` und `--serve` gibt es noch weitere ausführungsmöglichkeiten. ein graph lässt sich zum beispiel speichern und erneut darauf zurückgreifen. dadurch wird bei regelmäßigem nutzen des gleichen graphen zeit gespart. details dazu sind in der [dokumentation von otp](https://docs.opentripplanner.org/en/latest/basic-tutorial/) zu finden.\n\n### transit reachability analyser nutzen\n\nin den folgenden abschnitten wird die installation und nutzung des plugins erläutert. zusätzlich werden die schritte aufgezeigt, die nötig sind, um isochronen oder gebäude mithilfe von *transit reachability analyser* einzufärben.\n\n#### installation\n\ndamit *transit reachability analyser* funktioniert, müssen die folgenden python-packages in qgis installiert sein:\n\n- requests\n- json\n- geopandas\n- pandas\n- geopy\n\nes ist gut möglich, dass die packages bereits installiert sind. ist das nicht der fall, wird qgis bei der installation des plugins oder beim starten eine fehlermeldung einblenden. dann müssen die packages manuell über `pip` installiert werden. wie das in qgis geht, ist für jedes betriebssystem verschieden. folgende schritte werden für windows empfohlen:\n\n- osgeo4w shell öffnen. das wurde zusammen mit qgis installiert.\n- ```bash\n   python -m pip install {package name}\n   ```\n\n#### erreichbarkeitsanalyse\n\num eine erreichbarkeitsanalyse durchzuführen, muss für jede fett gedruckte kategorie ein wert festgelegt werden.\n\n- der startpunkt der berechnung muss über koordinaten angegeben werden. die koordinaten von einem punkt können zum beispiel aus [openstreetmap](https://www.openstreetmap.org) kopiert werden. über einen *rechtsklick* an den entsprechenden punkt kann die option *adresse anzeigen* gewählt werden. dadurch werden die koordinaten in dem *suchfeld* angezeigt.\n- ein gtfs-feed gilt nur für eine bestimmte zeit. bei der wahl des tages sollte das datum in diesem zeitraum liegen.\n- bei der eingabe der werte ist es vor allem wichtig, auf die syntax der eingabe zu achten. dabei kann sich an den beispielen in den jeweiligen feldern orientiert werden.\n- nach auswahl der gehgeschwindigkeit und gehzeit kann die daraus resultierende distanz in metern berechnet werden. dieser schritt ist optional und dient als orientierungshilfe.\n- wird otp nach der obigen anleitung gestartet, startet der server auf der portnummer 8080. diese einstellung muss nur geändert werden, wenn beim starten von otp eine andere portnummer angegeben wurde. ist unklar, ob die verbindung zu otp funktioniert, kann dies über den entsprechenden button ausprobiert werden. dieser schritt ist optional.\n- bei der bestätigung des **get all stops**-buttons wird ein punktlayer mit allen haltestellen erzeugt. die attributtabelle enthält eine spalte, in der alle abfahrtszeiten jeder linie in dem gewählten zeitfenster aufgelistet sind.\n- der **get all stations**-button erstellt einen punktlayer, bei dem je ein punkt alle stops mit gleichem namen zusammenfasst. es werden noch keine erreichbarkeiten berechnet, weswegen die laufzeit kurz ist, die attributtabelle aber leer bleibt.\n- der **reachability analysis**-button führt die erreichbarkeitsanalyse durch. otp berechnet für jede strecke vom startpunkt zu den einzelnen stationen verschiedene verbindungen. das plugin wählt aus den vorgeschlagenen verbindungen die schnellste aus. anhand der werte dieser verbindung werden die reiseaufwandsindikatoren gesetzt. je mehr stationen in dem gebiet liegen, desto länger dauern die berechnungen. je nach rechenleistung kann es einige minuten dauern, bis die berechnung fertig ist und qgis wieder nutzbar ist.\n\n#### layer symbolisierung\n\nbei der symbolisierung werden die spalten in der attributtabelle genutzt. deswegen ist es wichtig, dass die namen der spalten nicht verändert werden. die position kann verändert werden. es muss immer ein layer und ein indikator, der symbolisiert werden soll, ausgewählt werden. es kann sowohl die symbolisierung von punkt- als auch von polygonlayer verändert werden.\n\n#### isochronenlayer symbolisieren\n\n**isochronen berechnen**\n\n- plugin valhalla installieren.\n- *werkzeugkiste - valhalla - pedestrian - isochrones pedestrian* öffnen.\n- als *provider* sollte fossgis voreingestellt sein.\n- als *input point layer* einen punktlayer auswählen, der mit transit reachability analyser berechnet wurde.\n- als *input layer id field* name auswählen. dieser schritt ist wichtig, weil über den namen später die restlichen attribute richtig zugeordnet werden.\n- als *mode* hat sich *shortest* bewährt.\n- isochronengröße angeben.\n- berechnung starten.\n\nprinzipiell können auch andere plugins verwendet werden. meistens ist aber ein api-key nötig, der erst (kostenfrei) erstellt werden muss. das ist bei fossgis nicht nötig. außerdem müssen relativ viele isochronen berechnet werden. manche anbieter haben ein limit an berechnungen pro minute gesetzt, weswegen das relativ lange dauern kann.  \ndie größe der isochronen sollte einer entfernung entsprechen, die am ende maximal gelaufen werden soll, zum beispiel 5 minuten. um die isochronen in valhalla über eine kilometerangabe zu definieren, müssen zeit und geschwindigkeit in entfernung umgerechnet werden.  \nbei der eingabe einen punkt für dezimalwerte nutzen. das komma trennt verschieden große isochronen.\n\n**attribute den isochronen zuweisen**\n\n- *werkzeugkiste - vektoren allgemein - attribute nach feldwert verknüpfen* öffnen.\n- *eingabelayer*: polygonlayer mit den berechneten isochronen.\n- *tabellenspalte*: name.\n- *eingabelayer 2*: punktlayer mit attributtabelle, die über transit reachability analyser berechnet wurde.\n- *tabellenfeld 2*: name.\n- *layer 2 zu kopierende felder*: hier über die drei punkte rechts alle spalten auswählen, die kopiert werden sollen.\n- starte.\n- *transit reachability analyser* starten und isochronenlayer für die symbolisierung auswählen.\n\nhierbei ist es wichtig, dass die namensspalte in dem punkt- und isochronenlayer gleich sind. das trifft auf jeden fall auf den layer zu, über den die isochronen generiert wurden. es empfiehlt sich, den isochronenlayer zu duplizieren und so einen unveränderten layer zu behalten. dadurch müssen die isochronen nicht immer neu berechnet werden.\n\n#### gebäudelayer symbolisieren\n\n**buildingslayer herunterladen**\n\n- plugin quickosm installieren.\n- *vektor - quickosm - quickosm* öffnen.\n- in *kartenvolage* *urban* auswählen. alternativ in *schnelle abfrage* den *schlüssel* *building* nutzen.\n- für den downloadbereich im dropdown menü *layer-ausdehnung* auswählen und einen punktlayer von transit reachability analyser nutzen.\n\n**attribute den gebäuden zuordnen**\n\n- *werkzeugkiste - vektoren allgemein - attribute nach position verknüpfen* öffnen.\n- *mit objekten verknüpfen in*: gebäudelayer.\n- *ort der objekte*: schneidet auswählen.\n- *durch vergleich mit*: isochronenlayer mit attributen.\n- *hinzufügende felder*: über den button mit den drei punkten alle gewünschten attribute auswählen.\n- im dropdown menü *separates objekt für jedes passende objekt erzeugen (eines-zu-vielen)* auswählen.\n- starte.\n- den neuen layer in transit reachability analyser auswählen und symbolisierung verändern.\n\nwichtig ist, dass das textfeld zu *präfix für verknüpfte felder* leer bleibt. sonst werden die spaltennamen verändert und dann funktioniert die symbolisierung von transit reachability analyser nicht mehr.\n\n### daten auswerten\n\nbeim bewerten der daten ist zu beachten, dass die ergebnisse nur für den einen startpunkt gelten. die ergebnisse können und sollten nicht auf das gesamtnetz und gesamtangebot verallgemeinert werden.  \nbei einer nicht repräsentativen auswertung der daten zeigte sich, dass die verbindungen, die von otp vorgeschlagen werden, auf wenig umstiege und nicht auf die kürzeste reisezeit optimiert sind.  \ndie angaben in der attributtabelle zu fußstrecken beziehen sich nur auf den weg zur ersten haltestelle. die restlichen fußwege, zum beispiel bei einem umstieg oder zwischen letzter haltestelle und ziel, werden nicht direkt betrachtet. sie fließen nur in die reisezeit mit ein.  \nmanche berechnungen der weglänge von der letzten haltestelle zur zugehörigen station sind unrealistisch lang. das verlängert die reisezeit.  \nder takt wird nur über die ersten abfahrten einer verbindung berechnet. deswegen ist ein taktwechsel innerhalb eines suchfensters nicht sichtbar. sollte der fokus der analyse auf dem takt liegen, sollte darauf geachtet werden, dass der takt am anfang des zeitfensters repräsentativ für den analysierten zeitraum ist.  \naufgrund von unerwarteten rückgaben von otp ist die taktberechnung nicht immer richtig. an manchen stellen kann der berechnete takt besser sein, als der tatsächliche takt. wirken werte unrealistisch, sollten diese nachgeprüft werden.\n\n### mögliche problemlösungen\n\nin den folgenden abschnitten wird auf probleme eingegangen, die bei der nutzung von *transit reachability analyser* auftreten können. treten weitere probleme auf, kann sich an foren für qgis oder otp gewandt werden. alternativ kann auch ein [pull request](https://github.com/thanderjoren/transitreachabilityanalyser/pulls) für *transit reachability analyser* geschrieben werden.\n\n#### otp lässt sich nicht starten\n\nim terminal führen leerzeichen in einem dateipfad zu fehlern. in dem gesamten dateipfad, der beim starten von otp angegeben wird, darf kein leerzeichen vorkommen. lässt sich das nicht vermeiden, muss bei windows der dateipfad in anführungszeichen angegeben werden.\n\n#### otp bricht beim starten des servers ab\n\ngtfstools filtert nicht immer den gtfs-feed von delfi e.v. richtig. dann kann es sein, dass otp den server nicht gestartet bekommt. im vorhinein kann der gtfs-feed mithilfe des [gtfs-validators](https://gtfs-validator.mobilitydata.org/) untersucht werden. enthält der bericht *error*, lässt sich der gtfs-feed nicht mit otp nutzen. wenige *error* können manuell behoben werden. alternativ gibt es noch das tool [gtfstidy](https://github.com/patrickbr/gtfstidy), mit dem sich wohl gtfs-feeds verbessern lassen. *warnings* müssen nicht behoben werden.\n\n\n#### probleme mit transit reachability analyser\n\nlässt sich das plugin nicht ausführen, hilft es, in das protokoll von qgis zu schauen. dort wird in der *warning* der fehler spezifiziert, weswegen das plugin nicht ausführbar ist. in der *info* darüber wird angezeigt, was geändert werden muss, um den fehler zu vermeiden.  \nwird trotz korrekter ausführung nichts berechnet, kann das an dem tag der berechnung liegen. ein gtfs-feed gilt nur für eine bestimmte zeitspanne. ist der berechnungstag außerhalb dieser spanne, wird nichts berechnet, es kommt aber auch kein fehler. zum ausschließen dieses fehlers sollte am besten als berechnungstag der tag gewählt werden, an dem der gtfs-feed heruntergeladen wurde.\n\n#### layer ist auf der karte nicht zu finden\n\nist ein layer auf der karte nicht zu finden, sollte als erstes kontrolliert werden, ob der layer sichtbar geschaltet ist. ist das der fall, lässt sich nach rechtsklick auf den layer die option *auf layer zoomen* auswählen. so lässt sich herausfinden, wo der layer angezeigt wird. eine darstellung am falschen ort kann an der wahl des koordinatenbezugssystems (kbs) liegen.\n\n#### verzerrte darstellung der layer\n\n*transit reachability analyser* exportiert die punktlayer mit dem koordinatenbezugssystem (kbs) epsg:4326 wgs84. sonst würden die punkte an einem falschen ort angezeigt werden. die osm-hintergrundkarte hat dagegen das kbs epsg:3857 wgs84/pseudo-mercator. damit diese karte verzerrungsfrei dargestellt wird, muss das kbs des gesamten projektes auf epsg:3857 gestellt werden. das lässt sich ganz unten rechts in qgis einstellen.\n\n\n\n\n\n\n\n\n\n\n\n\n[//]: # (# anleitung)\n\n[//]: # ()\n[//]: # (mit dem plugin transit reachability analyser können erreichbarkeiten des öpnv berechnet und dargestellt werden. es wird von einem startpunkt zu jeder station des öpnv-netzes mithilfe von opentripplanner die schnellste verbindung berechnet. als ergebnis wird ein punktlayer mit einer attributtabelle erstellt, der zu jeder station verschiedene informationen bereitstellt. dazu gehören die reiseaufwandsindikatoren reisezeit, reisezeitverhältnis, gehzeit und gehdistanz zur ersten haltestelle sowie die umsteigehäufigkeit. zusätzlich sind in der attributtabelle die gewählte verbindung und weitere mögliche verbindungen sichtbar.  )\n\n[//]: # (für jeden reiseaufwandsindikator stellt das plugin ein farbschema bereit, in dem sich der punktlayer einfärben lässt. wird auf basis des punklayers ein polygonlayer erzeugt, lässt sich auch dieser von dem plugin in den verschiedenen farbschemata einfärben.)\n\n[//]: # ()\n[//]: # (## hinweis)\n\n[//]: # ()\n[//]: # (das plugin transit reachability analyser ist im rahmen einer bachelorarbeit entstanden. das sollte beim nutzen der berechneten daten berücksichtigt werden. die berechnungen wurden nicht systematisch auf plausibilität geprüft. merkwürdige daten sollten mit einer weiteren quelle verglichen werden.)\n\n[//]: # ()\n[//]: # (## kurzanleitung)\n\n[//]: # ()\n[//]: # (- gtfs feed herunterladen. zum beispiel von [delfi e.v.]&#40;https://www.opendata-oepnv.de/ht/de/organisation/delfi/startseite?tx_vrrkit_view%5baction%5d=details&tx_vrrkit_view%5bcontroller%5d=view&tx_vrrkit_view%5bdataset_formats%5d%5b0%5d=zip&tx_vrrkit_view%5bdataset_name%5d=deutschlandweite-sollfahrplandaten-gtfs&chash=01414d5793fcd0abb0f3a2e35176752c&#41; oder [connect]&#40;https://connect-fahrplanauskunft.de/&#41;.)\n\n[//]: # (- gtfs feed vorbereiten mithilfe von [gtfstools]&#40;https://ipeagit.github.io/gtfstools/&#41;.  )\n\n[//]: # (- `.osm.pbf` datei in der ausdehnung des gtfs feeds bei [protomaps]&#40;https://app.protomaps.com/&#41; herunterladen.)\n\n[//]: # (- [opentripplanner]&#40;https://docs.opentripplanner.org/en/latest/basic-tutorial/&#41; im terminal ausführen.)\n\n[//]: # (- transit reachability analyser öffnen.)\n\n[//]: # (    - erreichbarkeitsanalyse)\n\n[//]: # (        - koordinaten des startpunkts angeben.)\n\n[//]: # (        - untersuchungstag und -zeitraum festlegen.)\n\n[//]: # (        - gehgeschwindigkeit und maximale gehzeit wählen.)\n\n[//]: # (        - speicherort für den punktlayer festlegen.)\n\n[//]: # (        - berechnung durch button „reachability analysis“ starten.)\n\n[//]: # (    - optional: isochronenlayer oder buildingslayer mit attributwerten erstellen.)\n\n[//]: # (    - symbolisierung der daten)\n\n[//]: # (        - hierfür wird der otp server nicht benötigt.)\n\n[//]: # (        - layer wählen &#40;punkt- oder polygonlayer möglich&#41;.)\n\n[//]: # (        - darzustellenden indikator festlegen.)\n\n",
    "readme_before": "# guide\n> **hinweis:** [die anleitung auf deutsch](#anleitung) ist weiter unten zu finden.\n\n> **note:** translated from german by chatgpt\n\nwith the *transit reachability analyser* plugin, public transport reachability can be calculated and visualized. starting from a given point, the fastest route to each station in the public transport network is calculated using opentripplanner (otp). as a result, a dataset is created in which each station is represented as a point on the map. in qgis, a dataset consisting of points is referred to as a point layer. various information is provided for each station, including travel effort indicators such as travel time, travel time ratio, walking time, and walking distance to the first stop, as well as transfer frequency. additionally, it indicates which public transport connections were identified for the station and which one was selected. information in qgis is referred to as attributes and can be displayed via the attribute table of the point layer.\n\na heatmap can be created for each indicator by coloring the points on the map. in addition to points, areas can also be colored. these can be isochrones or buildings, for example. an isochrone includes all points that can be reached from a starting point within a specified time frame.\n\n> **note:** the *transit reachability analyser* plugin was developed as part of a bachelor's thesis. the results were only spot-checked for plausibility. a thorough investigation of the results was not conducted. anomalous data should be compared with additional sources.\n\n## table of contents\n\n- [guide](#guide)\n  - [quick guide](#quick-guide)\n  - [detailed guide](#detailed-guide)\n    - [preparing the gtfs feed](#preparing-the-gtfs-feed)\n      - [downloading the gtfs feed](#downloading-the-gtfs-feed)\n      - [filtering the gtfs feed](#filtering-the-gtfs-feed)\n    - [downloading the .osm.pbf file](#downloading-the-osmpbf-file)\n    - [starting otp](#starting-otp)\n    - [using the transit reachability analyser](#using-the-transit-reachability-analyser)\n      - [installation](#installation)\n      - [reachability analysis](#reachability-analysis)\n      - [layer symbolization](#layer-symbolization)\n      - [symbolizing isochrone layers](#symbolizing-isochrone-layers)\n      - [symbolizing building layers](#symbolizing-building-layers)\n    - [evaluating data](#evaluating-data)\n    - [possible solutions](#possible-solutions)\n      - [otp cannot be started](#otp-cannot-be-started)\n      - [otp crashes when starting the server](#otp-crashes-when-starting-the-server)\n      - [problems with the transit reachability analyser](#problems-with-the-transit-reachability-analyser)\n      - [layer not found on the map](#layer-not-found-on-the-map)\n      - [distorted representation of layers](#distorted-representation-of-layers)\n- [german version](#anleitung)\n\nexample heatmap of the travel time indicator for point and polygon layers, own representation, map data from [openstreetmap](https://www.openstreetmap.org):\n\n![punkt-polygon_bsp.png](punkt-polygon_bsp.png)\n\nexcerpt from the attribute table: route main station - dedekindstraße:\n\n| **name**                                    | braunschweig, dedekindstraße                                                                                                                                                                                                                     |\n|---------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **travel time [min]**                      | 19                                                                                                                                                                                                                                                  |\n| **travel time ratio**                       | 1.2                                                                                                                                                                                                                                                 |\n| **itinerary frequency [min]**               | 30                                                                                                                                                                                                                                                  |\n| **walk time [min]**                         | 1.2                                                                                                                                                                                                                                                 |\n| **walk distance [m]**                       | 104.1                                                                                                                                                                                                                                               |\n| **number of transfers**                     | 0                                                                                                                                                                                                                                                   |\n| **travel time car [min]**                   | 15.6                                                                                                                                                                                                                                                |\n| **max distance station to stop [m]**       | 44.5                                                                                                                                                                                                                                                |\n| **selected itinerary**                      | ['walk', '411', 'walk'], duration: 19, frequency: 30.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: braunschweig hauptbahnhof, laststop: braunschweig, dedekindstraße;                                           |\n| **possible itineraries**                    | ['walk', '4', 'walk', '421', 'walk'], duration: 35, frequency: 15.0, meters_to_first_stop: 157.0, walktime_to_first_stop: 1.9, firststop: braunschweig, hauptbahnhof/viewegs garten, laststop: braunschweig, dedekindstraße;<br> ['walk', '411', '421', 'walk'], duration: 23, frequency: 15.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: braunschweig hauptbahnhof, laststop: braunschweig, dedekindstraße; |\n\n## quick guide\n\n1. prepare the gtfs feed ([details](#preparing-the-gtfs-feed))\n   1. download the gtfs feed. for example, from [delfi e.v.](https://www.opendata-oepnv.de/ht/de/organisation/delfi/startseite?tx_vrrkit_view%5baction%5d=details&tx_vrrkit_view%5bcontroller%5d=view&tx_vrrkit_view%5bdataset_formats%5d%5b0%5d=zip&tx_vrrkit_view%5bdataset_name%5d=deutschlandweite-sollfahrplandaten-gtfs&chash=01414d5793fcd0abb0f3a2e35176752c) or [connect](https://connect-fahrplanauskunft.de/datenbereitstellung/) ([details](#downloading-the-gtfs-feed)).\n   2. filter the gtfs feed using [gtfstools](https://ipeagit.github.io/gtfstools/) ([details](#filtering-the-gtfs-feed)).\n\n2. download an .osm.pbf file from [protomaps](https://app.protomaps.com/) that corresponds to the area of the gtfs feed ([details](#downloading-the-osm-pbf-file)).\n\n3. start [opentripplanner 2.5](https://docs.opentripplanner.org/en/latest/basic-tutorial/) via the terminal ([details](#starting-otp)).\n\n4. install and open the *transit reachability analyser*.\n   1. reachability analysis ([details](#reachability-analysis))\n      1. specify the coordinates of the starting point.\n      2. set the investigation date and period.\n      3. choose walking speed and maximum walking time.\n      4. specify the storage location for the point layer.\n      5. start the calculation by clicking the *reachability analysis* button.\n   2. optional: create isochrone layers or building layers with attribute values ([details](#symbolizing-isochrone-layers)).\n   3. symbolizing the data ([details](#symbolizing-isochrone-layers))\n      1. the otp server is not required for this.\n      2. choose a layer (point or polygon layer).\n      3. specify the indicator to be displayed.\n\n## detailed guide\n\nin the *transit reachability analyser*, the reachability of stops is to be calculated. for simplification, stops with the same name are grouped into one destination. a destination that aggregates multiple stops is referred to as a station in this work. the common name of the stops is used as the name of the station. typically, a station combines two stops. however, there are also larger stations that encompass more than two stops with the same name.\n\n### preparing the gtfs feed\n\ngtfs feeds enable opentripplanner (otp) to calculate public transport connections. they contain information about the line offerings and travel times, among other things.\n\n#### downloading the gtfs feed\n\nthere are various providers from which gtfs feeds can be downloaded. this plugin requires gtfs schedule feeds. some transport companies offer gtfs feeds directly for their area. however, there are often gtfs feeds covering larger regions and thus containing the offerings of various transport companies. for example, the company [connect](https://connect-fahrplanauskunft.de/) provides a gtfs feed for lower saxony, germany. the gtfs feed from delfi e.v. covers all of germany and can be downloaded via the [open data öpnv](https://www.opendata-oepnv.de/ht/de/willkommen) portal. older gtfs feeds are also available under the *archive* tab.\n\n#### filtering the gtfs feed\n\nthe *transit reachability analyser* attempts to calculate a connection to each station from the starting point. the more stops present in the gtfs feed, the longer the calculation takes. **therefore, it is recommended to use a gtfs feed that only covers the area of investigation.** if that is already the case, this section can be skipped. otherwise, the following is required:\n\n- gtfs feed\n- r\n- rstudio (optional)\n- [gtfstools](https://ipeagit.github.io/gtfstools/)\n\nthe goal is to filter all data of a transport company from a larger gtfs feed. the file `agency.txt` in the gtfs feed lists all transport companies whose traffic information is represented in the gtfs feed. in the end, each file of the gtfs feed should only contain information related to that one transport company. to achieve this, gtfstools is used. gtfstools is an r programming language package that allows gtfs feeds to be filtered, among other things, using the `agency_id`. the rstudio ide provides an environment for working with r.\n\nafter r and rstudio have been installed, gtfstools is installed with the following command:\n```r\ninstall.packages(\"gtfstools\") \n```\n\nafter that, the lines in the following code block can be executed step by step. please note the following:\n\n- the `agency_id` of the used transport company can be found in the gtfs feed in the file `agency.txt`.\n- the file path must be adjusted. it is important to refer to the .zip file. for windows, the `r` and the parentheses must be retained.\n- the new file name must contain *gtfs*, otherwise otp will not be able to find the file.\n\n```r\nlibrary(gtfstools)\npath <- r\"(c:\\users\\username\\documents\\gtfs_feed_name.zip)\"\ngtfs <- read_gtfs(path)\nsmaller_gtfs <- filter_by_agency_id(gtfs, \"12021\") # hier die agency_id ersetzen.\nfilename <- r\"(c:\\users\\username\\documents\\filtered_gtfs_feed_name.zip)\"\nwrite_gtfs(smaller_gtfs, filename)\n```\n\n### downloading the .osm.pbf file\n\nin addition to a gtfs feed for the public transport offer, otp also requires information about the associated network of paths. this allows, for example, the calculation of walking routes to stops. for this, otp uses the pbf format, which stores the information of a section of the osm map in a file.\n\nthere are various ways to obtain an .osm.pbf file. the following tools will be used for the next steps:\n\n- unzipped gtfs feed\n- qgis\n- quickmapservices plugin\n- protomaps website\n\nit is important at this point that the map in the .osm.pbf file covers at least the area of the gtfs feed. to ensure this, the following steps are necessary:\n\n1. in qgis, open the *data source manager* (ctrl+l).\n2. open the *delimited text* section.\n3. at the top under *file name*, open the stops.txt file of the reduced gtfs feed.\n4. click on *add*.\n5. add the osm map as background using the quickmapservices plugin.\n6. open the [protomaps](https://app.protomaps.com/) website.\n7. protomaps allows the creation of a customized map section. align the section in protomaps with the location of the stops in qgis so that the section includes all stops.\n8. use *create extract* to create and download the .osm.pbf file.\n\n### starting otp\n\n[opentripplanner](https://docs.opentripplanner.org/en/latest/basic-tutorial/) is a multimodal route planner. the plugin uses this as a backend for the calculation of public transport routes. otp calculates a graph representing the transport network based on the gtfs feed and the .osm.pbf file. otp provides a server that can be interacted with through a web browser. before a calculation can be started with the *transit reachability analyser*, this server must be running. to start otp, the following is required:\n\n- java runtime (jre) or java development kit (jdk) version 21 or newer.\n- opentripplanner version otp 2.5.0 or newer. to do this, select the desired version on the linked page and download the file with the extension `shaded.jar` [here](https://repo1.maven.org/maven2/org/opentripplanner/otp/).\n\nthe following steps can be taken to start otp, so that a local server is ready:\n\n1. place the otp file, the gtfs feed, and the .osm.pbf file in a common folder that contains no other files (e.g., `otp_city`).\n2. ensure that the name of the gtfs feed contains *gtfs*.\n3. open the terminal.\n4. with the following command, otp will create a graph:\n   ```bash\n   java -xmx2g -jar c:\\users\\username\\documents\\otp_city\\\n      otp-2.5.0-shaded.jar --build --serve c:\\users\\username\\documents\\otp_city\n   ```\n5. wait until *grizzly server running* appears in the terminal. depending on the file size, this may take several minutes.\n\nnotes:\n\n- the file path is an example for windows.\n- if a folder in the file path contains a space in its name, the terminal may encounter issues.\n- `-xmx` specifies the maximum amount of memory that otp can use. since gtfs feeds and .osm.pbf files are relatively large, otp requires a significant amount of memory.\n- if starting the server fails, it can be attempted again with more than 2 gb of memory, while keeping the computer's limits in mind.\n- in addition to `--build` and `--serve`, there are other execution options available. for example, a graph can be saved and accessed again, saving time for regular use of the same graph. details on this can be found in the [otp documentation](https://docs.opentripplanner.org/en/latest/basic-tutorial/).\n\n### using the transit reachability analyser\n\nthe following sections will explain the installation and usage of the plugin. additionally, the steps needed to color isochrones or buildings using the *transit reachability analyser* will be shown.\n\n#### installation\n\nfor the *transit reachability analyser* to work, the following python packages must be installed in qgis:\n\n- requests\n- json\n- geopandas\n- pandas\n- geopy\n\nit is quite possible that the packages are already installed. if not, qgis will display an error message during the installation of the plugin or when starting it. in that case, the packages must be manually installed via `pip`. the method for doing this in qgis varies by operating system. the following steps are recommended for windows:\n\n- open the osgeo4w shell. this was installed along with qgis.\n- ```bash\n   python -m pip install {package name}\n   ```\n#### reachability analysis\n\nto perform an reachability analysis, a value must be defined for each bolded category.\n\n- the starting point of the calculation must be specified using coordinates. the coordinates of a point can be copied from [openstreetmap](https://www.openstreetmap.org). by right-clicking on the appropriate point, the option *show address* can be selected. this will display the coordinates in the *search field*.\n- a gtfs feed is only valid for a specific time. when choosing the day, the date should fall within this timeframe.\n- when entering values, it is especially important to pay attention to the syntax of the input. the examples in the respective fields can serve as a guide.\n- after selecting the walking speed and walking time, the resulting distance in meters can be calculated. this step is optional and serves as a guideline.\n- if otp is started according to the above instructions, the server will start on port number 8080. this setting only needs to be changed if a different port number was specified when starting otp. if it is unclear whether the connection to otp works, it can be tested using the appropriate button. this step is optional.\n- by confirming the **get all stops** button, a point layer with all stops will be created. the attribute table contains a column listing all departure times of each line within the selected time window.\n- the **get all stations** button creates a point layer where each point summarizes all stops with the same name. no reachability calculations are performed yet, so the runtime is short, but the attribute table remains empty.\n- the **reachability analysis** button performs the reachability analysis. otp calculates various connections from the starting point to each station. the plugin selects the fastest connection from the proposed options. based on the values of this connection, the travel effort indicators are set. the more stations are located in the area, the longer the calculations will take. depending on processing power, it may take a few minutes for the calculations to finish and for qgis to become usable again.\n\n#### layer symbolization\n\nduring symbolization, the columns in the attribute table are used. therefore, it is important that the names of the columns are not changed. the position can be altered. a layer and an indicator to be symbolized must always be selected. symbolization can be modified for both point and polygon layers.\n\n#### symbolizing isochrone layers\n\n**calculating isochrones**\n\n- install the valhalla plugin.\n- open *toolbox - valhalla - pedestrian - isochrones pedestrian*.\n- fossgis should be preset as the *provider*.\n- choose a point layer generated with the transit reachability analyser as the *input point layer*.\n- select the name as the *input layer id field*. this step is important because the rest of the attributes will be correctly assigned later based on this name.\n- the *mode* of *shortest* has proven effective.\n- specify the isochrone size.\n- start the calculation.\n\nin principle, other plugins can also be used. however, an api key is usually required, which must first be created (for free). this is not necessary for fossgis. additionally, relatively many isochrones need to be calculated. some providers set a limit on the number of calculations per minute, which can prolong the process.  \nthe size of the isochrones should correspond to a distance that is to be covered at most, for example, 5 minutes. to define the isochrones in valhalla using a kilometer specification, time and speed must be converted to distance.  \nwhen entering, use a point for decimal values. the comma separates the different sizes of isochrones.\n\n**assigning attributes to isochrones**\n\n- open *toolbox - general vector - link attributes by field value*.\n- *input layer*: polygon layer with the calculated isochrones.\n- *table column*: name.\n- *input layer 2*: point layer with the attribute table generated by the transit reachability analyser.\n- *table field 2*: name.\n- *layer 2 fields to copy*: select all columns to be copied via the button with three dots on the right.\n- start.\n- launch the *transit reachability analyser* and select the isochrone layer for symbolization.\n\nit is crucial that the name column in both the point layer and the isochrone layer are the same. this is definitely true for the layer from which the isochrones were generated. it is advisable to duplicate the isochrone layer to keep an unchanged layer. this way, the isochrones do not need to be recalculated every time.\n\n#### symbolizing building layers\n\n**downloading the buildings layer**\n\n- install the quickosm plugin.\n- open *vector - quickosm - quickosm*.\n- in *map settings*, select *urban*. alternatively, use the *key* *building* in *fast query*.\n- for the download area, select *layer extent* from the dropdown menu and use a point layer from the transit reachability analyser.\n\n**assigning attributes to buildings**\n\n- open *toolbox - general vector - link attributes by location*.\n- *link to objects in*: buildings layer.\n- *location of objects*: select intersects.\n- *by comparing with*: isochrone layer with attributes.\n- *fields to add*: select all desired attributes via the button with three dots.\n- in the dropdown menu, select *create separate object for each matching object (one-to-many)*.\n- start.\n- select the new layer in transit reachability analyser and change symbolization.\n\nit is important that the text field for *prefix for linked fields* remains empty. otherwise, the column names will be altered, and the symbolization of the transit reachability analyser will no longer function.\n\n### evaluating data\n\nwhen evaluating the data, it should be noted that the results only apply to the one starting point. the results cannot and should not be generalized to the entire network and total offering.  \nin a non-representative evaluation of the data, it was found that the connections proposed by otp are optimized for few transfers and not for the shortest travel time.  \nthe information in the attribute table on walking distances refers only to the path to the first stop. the remaining walking paths, such as those during a transfer or between the last stop and the destination, are not directly considered. they only contribute to the travel time.  \nsome calculations of the path length from the last stop to the corresponding station are unrealistically long, which extends the travel time.  \nthe frequency is only calculated based on the first departures of a connection. therefore, a frequency change within a search window is not visible. if the focus of the analysis is on frequency, care should be taken that the frequency at the beginning of the time window is representative of the analyzed period.  \ndue to unexpected returns from otp, the frequency calculation is not always accurate. in some cases, the calculated frequency can be better than the actual frequency. if certain values seem unrealistic, they should be double-checked.\n\n### possible solutions\n\nin the following sections, problems that may occur when using the *transit reachability analyser* will be addressed. if further problems arise, forums for qgis or otp can be consulted. alternatively, a [pull request](https://github.com/thanderjoren/transitreachabilityanalyser/pulls) for the *transit reachability analyser* can also be written.\n\n#### otp cannot be started\n\nin the terminal, spaces in a file path cause errors. there should be no spaces in the entire file path specified when starting otp. if this cannot be avoided, the file path must be enclosed in quotes on windows.\n\n#### otp crashes when starting the server\n\ngtfstools does not always filter the gtfs feed from delfi e.v. correctly. as a result, otp may not be able to start the server. in advance, the gtfs feed can be checked using the [gtfs validator](https://gtfs-validator.mobilitydata.org/). if the report contains *error*, the gtfs feed cannot be used with otp. a few *error* messages can be fixed manually. alternatively, there is the tool [gtfstidy](https://github.com/patrickbr/gtfstidy), which can likely improve gtfs feeds. *warnings* do not need to be addressed.\n\n\n#### problems with transit reachability analyser\n\nif the plugin cannot be executed, checking the qgis log can be helpful. there, the *warning* specifies the error preventing the plugin from running. the *info* above it indicates what needs to be changed to avoid the error.  \nif nothing is calculated despite proper execution, this might be due to the day of calculation. a gtfs feed is only valid for a certain timeframe. if the calculation day falls outside this range, nothing will be calculated, and no error will be reported. to rule out this error, it is best to choose the day the gtfs feed was downloaded as the calculation day.\n\n#### layer not found on the map\n\nif a layer cannot be found on the map, the first step is to check whether the layer is set to be visible. if so, you can right-click on the layer and select the option *zoom to layer*. this will help determine where the layer is displayed. a representation in the wrong location may be due to the choice of the coordinate reference system (crs).\n\n#### distorted representation of layers\n\n*transit reachability analyser* exports point layers using the coordinate reference system (crs) epsg:4326 wgs84. otherwise, the points would be displayed in the wrong location. in contrast, the osm background map uses the crs epsg:3857 wgs84/pseudo-mercator. to ensure this map is displayed without distortion, the crs of the entire project must be set to epsg:3857. this can be adjusted at the bottom right in qgis.\n\n-----------------------\n# anleitung\n\nmit dem plugin *transit reachability analyser* können erreichbarkeiten des öpnv berechnet und dargestellt werden. von einem startpunkt aus wird zu jeder station des öpnv-netzes mithilfe von opentripplanner (otp) die schnellste verbindung berechnet. als ergebnis wird ein datensatz erstellt, indem jede station einen punkt auf der karte repräsentiert. in qgis wird ein datensatz, bestehend aus punkten, punktlayer genannt. zu jeder station werden verschiedene informationen bereitgestellt. dazu gehören die reiseaufwandsindikatoren reisezeit, reisezeitverhältnis, gehzeit und gehdistanz zur ersten haltestelle sowie die umsteigehäufigkeit. zusätzlich wird angegeben, welche öpnv-verbindungen zu der station ermittelt wurden und welche daraus ausgewählt wurde. informationen werden in qgis als attribute bezeichnet und lassen sich über die attributtabelle des punktlayers anzeigen.\n\nfür jeden indikator kann eine heatmap erstellt werden, indem die punkte auf der karte eingefärbt werden. neben punkten können auch flächen eingefärbt werden. das können zum beispiel isochronen oder gebäude sein. eine isochrone beinhaltet alle punkte, die von einem startpunkt aus innerhalb einer vorgegebenen zeitspanne erreichbar sind.\n\n> **hinweis:** das plugin *transit reachability analyser* ist im rahmen einer bachelorarbeit entstanden. die ergebnisse wurden nur in stichproben auf plausibilität geprüft. eine ausführliche untersuchung der ergebnisse wurde nicht durchgeführt. auffällige daten sollten mit zusätzlichen quellen verglichen werden.\n\n## inhaltsverzeichnis\n\n- [anleitung](#anleitung)\n  - [kurzanleitung](#kurzanleitung)\n  - [ausführliche anleitung](#ausführliche-anleitung)\n    - [gtfs-feed vorbereiten](#gtfs-feed-vorbereiten)\n      - [gtfs-feed herunterladen](#gtfs-feed-herunterladen)\n      - [gtfs-feed filtern](#gtfs-feed-filtern)\n    - [.osm.pbf-datei herunterladen](#osmpbf-datei-herunterladen)\n    - [otp starten](#otp-starten)\n    - [transit reachability analyser nutzen](#transit-reachability-analyser-nutzen)\n      - [installation](#installation)\n      - [erreichbarkeitsanalyse](#erreichbarkeitsanalyse)\n      - [layer symbolisierung](#layer-symbolisierung)\n      - [isochronenlayer symbolisieren](#isochronenlayer-symbolisieren)\n      - [gebäudelayer symbolisieren](#gebaeudelayer-symbolisieren)\n    - [daten auswerten](#daten-auswerten)\n    - [mögliche problemlösungen](#moegliche-problemloesungen)\n      - [otp lässt sich nicht starten](#otp-laesst-sich-nicht-starten)\n      - [otp bricht beim starten des servers ab](#otp-bricht-beim-starten-des-servers-ab)\n      - [probleme mit transit reachability analyser](#probleme-mit-transit-reachability-analyser)\n      - [layer ist auf der karte nicht zu finden](#layer-ist-auf-der-karte-nicht-zu-finden)\n      - [verzerrte darstellung der layer](#verzerrte-darstellung-der-layer)\n\n\n\nbeispiel heatmap des indikators reisezeit für punkt- und polygonlayer, eigene darstellung, kartendaten von [openstreetmap](https://www.openstreetmap.org):\n\n![punkt-polygon_bsp.png](punkt-polygon_bsp.png)\n\nauszug aus der attributtabelle: strecke hauptbahnhof - dedekindstraße:\n\n| **name**                                    | braunschweig, dedekindstraße                                                                                                                                                                                                                     |\n|---------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **travel time [min]**                      | 19                                                                                                                                                                                                                                                  |\n| **travel time ratio**                       | 1.2                                                                                                                                                                                                                                                 |\n| **itinerary frequency [min]**               | 30                                                                                                                                                                                                                                                  |\n| **walk time [min]**                         | 1.2                                                                                                                                                                                                                                                 |\n| **walk distance [m]**                       | 104.1                                                                                                                                                                                                                                               |\n| **number of transfers**                     | 0                                                                                                                                                                                                                                                   |\n| **travel time car [min]**                   | 15.6                                                                                                                                                                                                                                                |\n| **max distance station to stop [m]**       | 44.5                                                                                                                                                                                                                                                |\n| **selected itinerary**                      | ['walk', '411', 'walk'], duration: 19, frequency: 30.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: braunschweig hauptbahnhof, laststop: braunschweig, dedekindstraße;                                           |\n| **possible itineraries**                    | ['walk', '4', 'walk', '421', 'walk'], duration: 35, frequency: 15.0, meters_to_first_stop: 157.0, walktime_to_first_stop: 1.9, firststop: braunschweig, hauptbahnhof/viewegs garten, laststop: braunschweig, dedekindstraße;<br> ['walk', '411', '421', 'walk'], duration: 23, frequency: 15.0, meters_to_first_stop: 104.1, walktime_to_first_stop: 1.2, firststop: braunschweig hauptbahnhof, laststop: braunschweig, dedekindstraße; |\n\n## kurzanleitung\n\n1. gtfs-feed vorbereiten ([details](#gtfs-feed-vorbereiten))\n   1.  gtfs-feed herunterladen. zum beispiel von [delfi e.v.](https://www.opendata-oepnv.de/ht/de/organisation/delfi/startseite?tx_vrrkit_view%5baction%5d=details&tx_vrrkit_view%5bcontroller%5d=view&tx_vrrkit_view%5bdataset_formats%5d%5b0%5d=zip&tx_vrrkit_view%5bdataset_name%5d=deutschlandweite-sollfahrplandaten-gtfs&chash=01414d5793fcd0abb0f3a2e35176752c) oder [connect](https://connect-fahrplanauskunft.de/datenbereitstellung/) ([details](#gtfs-feed-herunterladen)).\n   2. gtfs-feed filtern mithilfe von [gtfstools](https://ipeagit.github.io/gtfstools/) ([details](#gtfs-feed-filtern)).\n\n2. eine .osm.pbf-datei bei [protomaps](https://app.protomaps.com/) herunterladen, die dem gebiet des gtfs-feeds entspricht ([details](#osmpbf-datei-herunterladen)).\n\n3. [opentripplanner 2.5](https://docs.opentripplanner.org/en/latest/basic-tutorial/) über das terminal starten ([details](#otp-starten)).\n\n4. *transit reachability analyser* installieren und öffnen.\n   1. erreichbarkeitsanalyse ([details](#erreichbarkeitsanalyse))\n      1. koordinaten des startpunktes angeben.\n      2. untersuchungstag und -zeitraum festlegen.\n      3. gehgeschwindigkeit und maximale gehzeit wählen.\n      4. speicherort für den punktlayer festlegen.\n      5. berechnung durch button *reachability analysis* starten.\n   2. optional: isochronenlayer oder gebäudelayer mit attributwerten erstellen ([details](#isochronenlayer-symbolisieren)).\n   3. symbolisierung der daten ([details](#isochronenlayer-symbolisieren))\n      1. hierfür wird der otp-server nicht benötigt.\n      2. layer wählen (punkt- oder polygonlayer möglich).\n      3. darzustellenden indikator festlegen.\n\n## ausführliche anleitung\n\nin *transit reachability analyser* soll die erreichbarkeit von haltestellen berechnet werden. zur vereinfachung werden haltestellen mit gleichem namen zu einem ziel zusammengefasst. ein ziel, das mehrere haltestellen zusammenfasst, wird in dieser arbeit station genannt. als name der station wird der gemeinsame name der haltestellen genutzt. in der regel fasst eine station zwei haltestellen zusammen. es gibt aber auch größere stationen, die mehr als zwei haltestellen mit gleichem namen vereinen.\n\n### gtfs-feed vorbereiten\n\ngtfs-feeds ermöglichen es, opentripplanner (otp) öpnv-verbindungen zu berechnen. sie enthalten unter anderem informationen über das linienangebot und die fahrzeiten.\n\n#### gtfs-feed herunterladen\n\nes gibt verschiedene anbieter, über die gtfs-feeds heruntergeladen werden können. für dieses plugin werden gtfs-schedule-feeds benötigt. manche verkehrsunternehmen bieten für ihr gebiet direkt einen gtfs-feed an. häufig gibt es aber gtfs-feeds, die eine größere region abdecken und dadurch das angebot verschiedener verkehrsunternehmen enthalten. für niedersachsen stellt zum beispiel das unternehmen [connect](https://connect-fahrplanauskunft.de/) einen gtfs-feed zur verfügung. der gtfs-feed von delfi e.v. deckt ganz deutschland ab und lässt sich über das portal [open data öpnv](https://www.opendata-oepnv.de/ht/de/willkommen) herunterladen. über den reiter *archiv* sind auch alte gtfs-feeds verfügbar.\n\n#### gtfs-feed filtern\n\n*transit reachability analyser* versucht, vom startpunkt aus zu jeder station eine verbindung zu berechnen. je mehr stops in dem gtfs-feed vorhanden sind, desto länger dauert die berechnung. **deswegen ist es empfehlenswert, einen gtfs-feed zu nutzen, der nur das untersuchungsgebiet abdeckt.** ist das bereits der fall, kann dieser abschnitt übersprungen werden. ansonsten wird folgendes benötigt:\n\n- gtfs-feed\n- r\n- rstudio (optional)\n- [gtfstools](https://ipeagit.github.io/gtfstools/)\n\ndas ziel ist es, alle daten eines verkehrsunternehmens aus einem größeren gtfs-feed zu filtern. in der datei `agency.txt` des gtfs-feeds sind alle verkehrsunternehmen aufgelistet, deren verkehrsinformationen in dem gtfs-feed abgebildet sind. am ende sollen in jeder datei des gtfs-feeds nur noch informationen stehen, die zu dem einen verkehrsunternehmen gehören. um das zu bewerkstelligen, wird gtfstools benutzt. gtfstools ist ein package der programmiersprache r, mit dem gtfs-feeds unter anderem mithilfe der `agency_id` gefiltert werden können. die ide rstudio bietet eine umgebung, in der mit r gearbeitet werden kann.\n\nnachdem r und rstudio installiert wurden, wird mit dem folgendem befehl gtfstools installiert:\n\n```r\ninstall.packages(\"gtfstools\") \n```\n\ndanach können die zeilen in dem folgenden code-block schritt für schritt ausgeführt werden. dabei bitte folgendes beachten:\n\n- die `agency_id` des verwendeten verkehrsunternehmens lässt sich in dem gtfs-feed in der datei `agency.txt` finden.\n- der dateipfad muss angepasst werden. dabei ist es wichtig, auf die .zip-datei zu verweisen. für windows müssen das `r` und die klammern beibehalten werden.\n- der neue dateiname muss *gtfs* enthalten, sonst kann otp die datei nicht finden.\n\n```r\nlibrary(gtfstools)\npath <- r\"(c:\\benutzer\\benutzername\\dokumente\\gtfs_feed_name.zip)\"\ngtfs <- read_gtfs(path)\nsmaller_gtfs <- filter_by_agency_id(gtfs, \"12021\") # hier die agency_id ersetzen.\nfilename <- r\"(c:\\benutzer\\benutzername\\dokumente\\name_gefilterter_gtfs_feed.zip)\"\nwrite_gtfs(smaller_gtfs, filename)\n```\n\n### .osm.pbf-datei herunterladen\n\nneben einem gtfs-feed für das öpnv-angebot benötigt otp auch informationen über das zugehörige wegenetz. damit können zum beispiel fußwege zu haltestellen berechnet werden. dafür nutzt otp das format pbf, welches die informationen eines ausschnitts der osm-karte in einer datei speichert.\n\nes gibt verschiedene wege, an eine .osm.pbf-datei zu kommen. für die nächsten schritte werden folgende tools benutzt:\n\n- entpackter gtfs-feed\n- qgis\n- plugin quickmapservices\n- website protomaps\n\nwichtig ist an dieser stelle, dass die karte in der osm.pbf-datei mindestens das gebiet des gtfs-feeds abdeckt. um das sicherzustellen, sind folgende schritte nötig:\n\n1. in qgis die *datenquellenverwaltung* öffnen (strg+l).\n2. den abschnitt *getrennte texte* öffnen.\n3. ganz oben unter *dateiname* die stops.txt-datei des verkleinerten gtfs-feeds öffnen.\n4. auf *hinzufügen* klicken.\n5. über das plugin quickmapservices die osm-karte als hintergrund hinzufügen.\n6. die website [protomaps](https://app.protomaps.com/) öffnen.\n7. mit protomaps lässt sich ein individueller kartenausschnitt erstellen. den ausschnitt in protomaps mit der lage der stops in qgis abgleichen, damit der ausschnitt alle stops beinhaltet.\n8. über *create extract* die .osm.pbf-datei erstellen lassen und herunterladen.\n\n\n### otp starten\n\n[opentripplanner](https://docs.opentripplanner.org/en/latest/basic-tutorial/) ist ein multimodaler routenplaner. das plugin verwendet diesen als backend für die berechnung der öpnv-routen. otp berechnet auf basis des gtfs-feeds und der .osm.pbf-datei einen graphen, der das verkehrsnetz repräsentiert. otp stellt einen server zur verfügung, mit dem über einen webbrowser interagiert werden kann. bevor eine berechnung mit *transit reachability analyser* gestartet werden kann, muss dieser server gestartet sein. um otp zu starten, wird folgendes benötigt:\n\n- java runtime (jre) oder java development kit (jdk) mindestens in der version java 21 oder neuer.\n- opentripplanner mindestens in der version otp 2.5.0 oder neuer. dafür auf der verlinkten seite die gewünschte version auswählen und die datei mit der endung `shaded.jar` [herunterladen](https://repo1.maven.org/maven2/org/opentripplanner/otp/).\n\nmit den folgenden schritten lässt sich otp starten, sodass ein lokaler server bereitsteht:\n\n1. die otp-datei, den gtfs-feed und die .osm.pbf-datei in einen gemeinsamen ordner legen, der keine weiteren dateien enthält (z.b. `otp_stadt`).\n2. sicherstellen, dass in dem namen des gtfs-feeds *gtfs* vorkommt.\n3. terminal öffnen.\n4. mit dem folgenden befehl erstellt otp einen graphen:\n   ```bash\n   java -xmx2g -jar c:\\benutzer\\benutzername\\dokumente\\otp_stadt\\\n   otp-2.5.0-shaded.jar --build --serve c:\\benutzer\\benutzername\\dokumente\\otp_stadt\n   ```\n5. warten, bis im terminal *grizzly server running* steht. je nach dateigröße kann dies mehrere minuten dauern.\n\nhinweise:\n\n- der dateipfad ist ein beispiel für windows.\n- enthält ein ordner in dem dateipfad ein leerzeichen im namen, kann es passieren, dass das terminal probleme macht.\n- `-xmx` legt fest, wie viel speicher otp maximal nutzen darf. da gtfs-feeds und .osm.pbf-dateien relativ groß sind, braucht otp relativ viel speicher.\n- klappt das starten des servers nicht, kann es mit mehr speicher als 2 gb erneut versucht werden. dabei sollten die grenzen des computers im blick behalten werden.\n- statt `--build` und `--serve` gibt es noch weitere ausführungsmöglichkeiten. ein graph lässt sich zum beispiel speichern und erneut darauf zurückgreifen. dadurch wird bei regelmäßigem nutzen des gleichen graphen zeit gespart. details dazu sind in der [dokumentation von otp](https://docs.opentripplanner.org/en/latest/basic-tutorial/) zu finden.\n\n### transit reachability analyser nutzen\n\nin den folgenden abschnitten wird die installation und nutzung des plugins erläutert. zusätzlich werden die schritte aufgezeigt, die nötig sind, um isochronen oder gebäude mithilfe von *transit reachability analyser* einzufärben.\n\n#### installation\n\ndamit *transit reachability analyser* funktioniert, müssen die folgenden python-packages in qgis installiert sein:\n\n- requests\n- json\n- geopandas\n- pandas\n- geopy\n\nes ist gut möglich, dass die packages bereits installiert sind. ist das nicht der fall, wird qgis bei der installation des plugins oder beim starten eine fehlermeldung einblenden. dann müssen die packages manuell über `pip` installiert werden. wie das in qgis geht, ist für jedes betriebssystem verschieden. folgende schritte werden für windows empfohlen:\n\n- osgeo4w shell öffnen. das wurde zusammen mit qgis installiert.\n- ```bash\n   python -m pip install {package name}\n   ```\n\n#### erreichbarkeitsanalyse\n\num eine erreichbarkeitsanalyse durchzuführen, muss für jede fett gedruckte kategorie ein wert festgelegt werden.\n\n- der startpunkt der berechnung muss über koordinaten angegeben werden. die koordinaten von einem punkt können zum beispiel aus [openstreetmap](https://www.openstreetmap.org) kopiert werden. über einen *rechtsklick* an den entsprechenden punkt kann die option *adresse anzeigen* gewählt werden. dadurch werden die koordinaten in dem *suchfeld* angezeigt.\n- ein gtfs-feed gilt nur für eine bestimmte zeit. bei der wahl des tages sollte das datum in diesem zeitraum liegen.\n- bei der eingabe der werte ist es vor allem wichtig, auf die syntax der eingabe zu achten. dabei kann sich an den beispielen in den jeweiligen feldern orientiert werden.\n- nach auswahl der gehgeschwindigkeit und gehzeit kann die daraus resultierende distanz in metern berechnet werden. dieser schritt ist optional und dient als orientierungshilfe.\n- wird otp nach der obigen anleitung gestartet, startet der server auf der portnummer 8080. diese einstellung muss nur geändert werden, wenn beim starten von otp eine andere portnummer angegeben wurde. ist unklar, ob die verbindung zu otp funktioniert, kann dies über den entsprechenden button ausprobiert werden. dieser schritt ist optional.\n- bei der bestätigung des **get all stops**-buttons wird ein punktlayer mit allen haltestellen erzeugt. die attributtabelle enthält eine spalte, in der alle abfahrtszeiten jeder linie in dem gewählten zeitfenster aufgelistet sind.\n- der **get all stations**-button erstellt einen punktlayer, bei dem je ein punkt alle stops mit gleichem namen zusammenfasst. es werden noch keine erreichbarkeiten berechnet, weswegen die laufzeit kurz ist, die attributtabelle aber leer bleibt.\n- der **reachability analysis**-button führt die erreichbarkeitsanalyse durch. otp berechnet für jede strecke vom startpunkt zu den einzelnen stationen verschiedene verbindungen. das plugin wählt aus den vorgeschlagenen verbindungen die schnellste aus. anhand der werte dieser verbindung werden die reiseaufwandsindikatoren gesetzt. je mehr stationen in dem gebiet liegen, desto länger dauern die berechnungen. je nach rechenleistung kann es einige minuten dauern, bis die berechnung fertig ist und qgis wieder nutzbar ist.\n\n#### layer symbolisierung\n\nbei der symbolisierung werden die spalten in der attributtabelle genutzt. deswegen ist es wichtig, dass die namen der spalten nicht verändert werden. die position kann verändert werden. es muss immer ein layer und ein indikator, der symbolisiert werden soll, ausgewählt werden. es kann sowohl die symbolisierung von punkt- als auch von polygonlayer verändert werden.\n\n#### isochronenlayer symbolisieren\n\n**isochronen berechnen**\n\n- plugin valhalla installieren.\n- *werkzeugkiste - valhalla - pedestrian - isochrones pedestrian* öffnen.\n- als *provider* sollte fossgis voreingestellt sein.\n- als *input point layer* einen punktlayer auswählen, der mit transit reachability analyser berechnet wurde.\n- als *input layer id field* name auswählen. dieser schritt ist wichtig, weil über den namen später die restlichen attribute richtig zugeordnet werden.\n- als *mode* hat sich *shortest* bewährt.\n- isochronengröße angeben.\n- berechnung starten.\n\nprinzipiell können auch andere plugins verwendet werden. meistens ist aber ein api-key nötig, der erst (kostenfrei) erstellt werden muss. das ist bei fossgis nicht nötig. außerdem müssen relativ viele isochronen berechnet werden. manche anbieter haben ein limit an berechnungen pro minute gesetzt, weswegen das relativ lange dauern kann.  \ndie größe der isochronen sollte einer entfernung entsprechen, die am ende maximal gelaufen werden soll, zum beispiel 5 minuten. um die isochronen in valhalla über eine kilometerangabe zu definieren, müssen zeit und geschwindigkeit in entfernung umgerechnet werden.  \nbei der eingabe einen punkt für dezimalwerte nutzen. das komma trennt verschieden große isochronen.\n\n**attribute den isochronen zuweisen**\n\n- *werkzeugkiste - vektoren allgemein - attribute nach feldwert verknüpfen* öffnen.\n- *eingabelayer*: polygonlayer mit den berechneten isochronen.\n- *tabellenspalte*: name.\n- *eingabelayer 2*: punktlayer mit attributtabelle, die über transit reachability analyser berechnet wurde.\n- *tabellenfeld 2*: name.\n- *layer 2 zu kopierende felder*: hier über die drei punkte rechts alle spalten auswählen, die kopiert werden sollen.\n- starte.\n- *transit reachability analyser* starten und isochronenlayer für die symbolisierung auswählen.\n\nhierbei ist es wichtig, dass die namensspalte in dem punkt- und isochronenlayer gleich sind. das trifft auf jeden fall auf den layer zu, über den die isochronen generiert wurden. es empfiehlt sich, den isochronenlayer zu duplizieren und so einen unveränderten layer zu behalten. dadurch müssen die isochronen nicht immer neu berechnet werden.\n\n#### gebäudelayer symbolisieren\n\n**buildingslayer herunterladen**\n\n- plugin quickosm installieren.\n- *vektor - quickosm - quickosm* öffnen.\n- in *kartenvolage* *urban* auswählen. alternativ in *schnelle abfrage* den *schlüssel* *building* nutzen.\n- für den downloadbereich im dropdown menü *layer-ausdehnung* auswählen und einen punktlayer von transit reachability analyser nutzen.\n\n**attribute den gebäuden zuordnen**\n\n- *werkzeugkiste - vektoren allgemein - attribute nach position verknüpfen* öffnen.\n- *mit objekten verknüpfen in*: gebäudelayer.\n- *ort der objekte*: schneidet auswählen.\n- *durch vergleich mit*: isochronenlayer mit attributen.\n- *hinzufügende felder*: über den button mit den drei punkten alle gewünschten attribute auswählen.\n- im dropdown menü *separates objekt für jedes passende objekt erzeugen (eines-zu-vielen)* auswählen.\n- starte.\n- den neuen layer in transit reachability analyser auswählen und symbolisierung verändern.\n\nwichtig ist, dass das textfeld zu *präfix für verknüpfte felder* leer bleibt. sonst werden die spaltennamen verändert und dann funktioniert die symbolisierung von transit reachability analyser nicht mehr.\n\n### daten auswerten\n\nbeim bewerten der daten ist zu beachten, dass die ergebnisse nur für den einen startpunkt gelten. die ergebnisse können und sollten nicht auf das gesamtnetz und gesamtangebot verallgemeinert werden.  \nbei einer nicht repräsentativen auswertung der daten zeigte sich, dass die verbindungen, die von otp vorgeschlagen werden, auf wenig umstiege und nicht auf die kürzeste reisezeit optimiert sind.  \ndie angaben in der attributtabelle zu fußstrecken beziehen sich nur auf den weg zur ersten haltestelle. die restlichen fußwege, zum beispiel bei einem umstieg oder zwischen letzter haltestelle und ziel, werden nicht direkt betrachtet. sie fließen nur in die reisezeit mit ein.  \nmanche berechnungen der weglänge von der letzten haltestelle zur zugehörigen station sind unrealistisch lang. das verlängert die reisezeit.  \nder takt wird nur über die ersten abfahrten einer verbindung berechnet. deswegen ist ein taktwechsel innerhalb eines suchfensters nicht sichtbar. sollte der fokus der analyse auf dem takt liegen, sollte darauf geachtet werden, dass der takt am anfang des zeitfensters repräsentativ für den analysierten zeitraum ist.  \naufgrund von unerwarteten rückgaben von otp ist die taktberechnung nicht immer richtig. an manchen stellen kann der berechnete takt besser sein, als der tatsächliche takt. wirken werte unrealistisch, sollten diese nachgeprüft werden.\n\n### mögliche problemlösungen\n\nin den folgenden abschnitten wird auf probleme eingegangen, die bei der nutzung von *transit reachability analyser* auftreten können. treten weitere probleme auf, kann sich an foren für qgis oder otp gewandt werden. alternativ kann auch ein [pull request](https://github.com/thanderjoren/transitreachabilityanalyser/pulls) für *transit reachability analyser* geschrieben werden.\n\n#### otp lässt sich nicht starten\n\nim terminal führen leerzeichen in einem dateipfad zu fehlern. in dem gesamten dateipfad, der beim starten von otp angegeben wird, darf kein leerzeichen vorkommen. lässt sich das nicht vermeiden, muss bei windows der dateipfad in anführungszeichen angegeben werden.\n\n#### otp bricht beim starten des servers ab\n\ngtfstools filtert nicht immer den gtfs-feed von delfi e.v. richtig. dann kann es sein, dass otp den server nicht gestartet bekommt. im vorhinein kann der gtfs-feed mithilfe des [gtfs-validators](https://gtfs-validator.mobilitydata.org/) untersucht werden. enthält der bericht *error*, lässt sich der gtfs-feed nicht mit otp nutzen. wenige *error* können manuell behoben werden. alternativ gibt es noch das tool [gtfstidy](https://github.com/patrickbr/gtfstidy), mit dem sich wohl gtfs-feeds verbessern lassen. *warnings* müssen nicht behoben werden.\n\n\n#### probleme mit transit reachability analyser\n\nlässt sich das plugin nicht ausführen, hilft es, in das protokoll von qgis zu schauen. dort wird in der *warning* der fehler spezifiziert, weswegen das plugin nicht ausführbar ist. in der *info* darüber wird angezeigt, was geändert werden muss, um den fehler zu vermeiden.  \nwird trotz korrekter ausführung nichts berechnet, kann das an dem tag der berechnung liegen. ein gtfs-feed gilt nur für eine bestimmte zeitspanne. ist der berechnungstag außerhalb dieser spanne, wird nichts berechnet, es kommt aber auch kein fehler. zum ausschließen dieses fehlers sollte am besten als berechnungstag der tag gewählt werden, an dem der gtfs-feed heruntergeladen wurde.\n\n#### layer ist auf der karte nicht zu finden\n\nist ein layer auf der karte nicht zu finden, sollte als erstes kontrolliert werden, ob der layer sichtbar geschaltet ist. ist das der fall, lässt sich nach rechtsklick auf den layer die option *auf layer zoomen* auswählen. so lässt sich herausfinden, wo der layer angezeigt wird. eine darstellung am falschen ort kann an der wahl des koordinatenbezugssystems (kbs) liegen.\n\n#### verzerrte darstellung der layer\n\n*transit reachability analyser* exportiert die punktlayer mit dem koordinatenbezugssystem (kbs) epsg:4326 wgs84. sonst würden die punkte an einem falschen ort angezeigt werden. die osm-hintergrundkarte hat dagegen das kbs epsg:3857 wgs84/pseudo-mercator. damit diese karte verzerrungsfrei dargestellt wird, muss das kbs des gesamten projektes auf epsg:3857 gestellt werden. das lässt sich ganz unten rechts in qgis einstellen.\n\n\n\n\n\n\n\n\n\n\n\n\n[//]: # (# anleitung)\n\n[//]: # ()\n[//]: # (mit dem plugin transit reachability analyser können erreichbarkeiten des öpnv berechnet und dargestellt werden. es wird von einem startpunkt zu jeder station des öpnv-netzes mithilfe von opentripplanner die schnellste verbindung berechnet. als ergebnis wird ein punktlayer mit einer attributtabelle erstellt, der zu jeder station verschiedene informationen bereitstellt. dazu gehören die reiseaufwandsindikatoren reisezeit, reisezeitverhältnis, gehzeit und gehdistanz zur ersten haltestelle sowie die umsteigehäufigkeit. zusätzlich sind in der attributtabelle die gewählte verbindung und weitere mögliche verbindungen sichtbar.  )\n\n[//]: # (für jeden reiseaufwandsindikator stellt das plugin ein farbschema bereit, in dem sich der punktlayer einfärben lässt. wird auf basis des punklayers ein polygonlayer erzeugt, lässt sich auch dieser von dem plugin in den verschiedenen farbschemata einfärben.)\n\n[//]: # ()\n[//]: # (## hinweis)\n\n[//]: # ()\n[//]: # (das plugin transit reachability analyser ist im rahmen einer bachelorarbeit entstanden. das sollte beim nutzen der berechneten daten berücksichtigt werden. die berechnungen wurden nicht systematisch auf plausibilität geprüft. merkwürdige daten sollten mit einer weiteren quelle verglichen werden.)\n\n[//]: # ()\n[//]: # (## kurzanleitung)\n\n[//]: # ()\n[//]: # (- gtfs feed herunterladen. zum beispiel von [delfi e.v.]&#40;https://www.opendata-oepnv.de/ht/de/organisation/delfi/startseite?tx_vrrkit_view%5baction%5d=details&tx_vrrkit_view%5bcontroller%5d=view&tx_vrrkit_view%5bdataset_formats%5d%5b0%5d=zip&tx_vrrkit_view%5bdataset_name%5d=deutschlandweite-sollfahrplandaten-gtfs&chash=01414d5793fcd0abb0f3a2e35176752c&#41; oder [connect]&#40;https://connect-fahrplanauskunft.de/&#41;.)\n\n[//]: # (- gtfs feed vorbereiten mithilfe von [gtfstools]&#40;https://ipeagit.github.io/gtfstools/&#41;.  )\n\n[//]: # (- `.osm.pbf` datei in der ausdehnung des gtfs feeds bei [protomaps]&#40;https://app.protomaps.com/&#41; herunterladen.)\n\n[//]: # (- [opentripplanner]&#40;https://docs.opentripplanner.org/en/latest/basic-tutorial/&#41; im terminal ausführen.)\n\n[//]: # (- transit reachability analyser öffnen.)\n\n[//]: # (    - erreichbarkeitsanalyse)\n\n[//]: # (        - koordinaten des startpunkts angeben.)\n\n[//]: # (        - untersuchungstag und -zeitraum festlegen.)\n\n[//]: # (        - gehgeschwindigkeit und maximale gehzeit wählen.)\n\n[//]: # (        - speicherort für den punktlayer festlegen.)\n\n[//]: # (        - berechnung durch button „reachability analysis“ starten.)\n\n[//]: # (    - optional: isochronenlayer oder buildingslayer mit attributwerten erstellen.)\n\n[//]: # (    - symbolisierung der daten)\n\n[//]: # (        - hierfür wird der otp server nicht benötigt.)\n\n[//]: # (        - layer wählen &#40;punkt- oder polygonlayer möglich&#41;.)\n\n[//]: # (        - darzustellenden indikator festlegen.)\n\n"
  },
  {
    "readme": "# Brief description\n\n(imgs/r.png)\n\nSmd is a high-performance grid-protected feature algorithm to recover noise. The data structure based on facet-index reproduces a number of representative papers in this area. As undergraduate design for Sayoriaaa, it contains the reproduction of the following papers:\n\nSlurp, slurp, slur, slur, squeak, squeak, squeez, squeez.\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n[(siggraph'03) bigraph mesh denoising] [https://dl.accm.org/doi/1011145/882262.882368] [siggraph'13) mesh denoising via*l*0 minimization] (https://dl.acm.org/doi/1011145/24619191265) [siggraph'14) decoupling noises and oceans via weighted *l*1-analysis compressed sensing] (http://staff.ustc.edu.c/~lgliu/projects/2014_decouplingnoise/default.htm)\n[(tvcg'11) bilateral nonmal reporting for mesh denoising] (https://dl.acm.org/doi/101109/tvcg.2010.264) [(cad'13) feature-preventing production with l0 gradient surveillance] (https://dl.acm.org/doi/101016/j.cag.2013.10.025)\n[Proc. pg'15) defined mesh normal flying]\n\n\n\n# Use\n\nThis project is more generic and is [detailed] (docs/usage.md)\n\n# Project document description\n\n- `src/ ' Source Document\n- `[Thesis algorithm]/ '\n- `dependences/ '\n- `utils/ '\n- `data/`data sets\n- `docs/ ' Documents\n- `bash/ '\n- `*.bat ' win mission\n- `*.sh ' linux mission\n- `scripts/ ' Some sealed python functions\n- `run/ '\n- `[Specific mandate]/ '\n- `xx.obj ' to the noise grid\n- `time.txt ' records the time spent on each grid to lose noise\n- `Metric.txt ' records the [indicator] of each grid (#noise reduction results assessment)\n\nThe format in `metric.txt ' is as follows:\n```\nname:40359 \ndenoised:run/ir2/40359 \ngt:data/examples/40359 \naad:25.8935\nahd:0.0037325\noep:0.016092\n```\n\n`time.txt`的格式如下（首项和末项格式固定）：\n```\nname:40359edge \nsmd-l0: c++ implementation of \"mesh denoising via l0 minimization\" \naverage dihedral angle: 32.6038\nlambda: 2.10814\nalpha: 0\nexecution time: 139.537 ms\n```\n\n\n# 运行\n\n本项目提供了windows下的一些批处理测试脚本，一键在`run`目录下生成对应的文件。\n\n它们包括\n\n- `test_cube.bat`：测试不同算法在cube模型下的去噪效果，可修改cube的噪声强度等\n- `test_ir.bat`：测试不同非规整网格在不同$l_0$方法下的去噪效果\n- `test_selected.bat`：测试从synthetic、kinect系列数据集中选取的25个模型，在$l_0$方法默认参数下的去噪效果\n- `test_robust.bat`：测试从$l_0$算法超参数$\\lambda$的鲁棒性、亦可用于选取最优参数\n\n这些脚本提供了注释，根据这些注释的提示修改`set=`的内容，便可以进行同类实验。在生成文件后，可以在`make_figure.ipynb`中找到对应任务的可视化代码。如果是自定义任务（即根据bat注释进行了修改），修改cell内的`proj_name`即可。\n\n执行可视化后，在`exp`目录下会保存图像，比如`test_robust.bat`对应的任务可视化图为\n\n![](imgs/robust_block.png)\n\n# 数据集\n\n`test_selected.bat`等脚本需要包含额外的数据集：cnr提供的合成数据集synthetic，扫描数据集kinect v1、kinect v2、kinect f；gcn提供的扫描数据集printdata。\n\n它们可以分别在 https://wang-ps.github.io/denoising.html 和 https://drive.google.com/file/d/1x561-v3z1j0q_1qhyg0fja1w-sqjhypc/view下载\n\n解压后，`data`下的文件为\n\n```\n└── data\n    ├── examples\n    ├── kinect_fusion\n    ├── kinect_v1\n    ├── kinect_v2\n    ├── synthetic\n    └── printeddataset\n```\n\n# 降噪结果评估\n\n## 平均豪斯多夫距离（ahd）\n\n$$\ne_v=\\frac{1}{n_vl_d}\\sum_{v^r_i\\in v^r_m}\n\\min_{\\tilde{v}_j\\in\\tilde{v}_m}\\vert v^r_i-\\tilde{v}_j \\vert\n$$\n\n## 平均法向角距离（aad）\n\n$$\ne_a=\\frac{1}{n_f}\\sum_{f^r_i\\in f^r} \\mathrm{acos}(n^r_i \\cdot \\tilde{n}_i)\n$$\n\n结果以角度为单位\n\n## 翻折边比例（oep）\n\n基于$l_0$论文中folded triangle的可视化，使用边所对应的二面角进行网格评估，给出一个定量度量\n\n$$\ne_f=\\frac{1}{n_e}\\sum_{e^r_i\\in f^r} \\tau(e^r_i)\n\\\\\n\\tau(e)=\\begin{cases}\n1&\\mathrm{dihedral\\ angle}(e)<30^\\circ\n\\\\\n0&\\mathrm{otherwise}\n\\end{cases}\n$$\n\n\n\n\n\n",
    "readme_before": "# 🌈简介\n\n![](imgs/r.png)\n\nsmd是一个高性能的网格保特征算法去噪复现合集。基于facet-index的数据结构复现了该领域的多篇代表性论文。作为sayoriaaa的本科毕业设计，它包含以下论文的复现：\n\n| 滤波                                                         | 稀疏正则化                                                   | 压缩感知                                                     |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [(siggraph'03) bilateral mesh denoising](https://dl.acm.org/doi/10.1145/882262.882368) | [(siggraph'13) mesh denoising via *l*0 minimization](https://dl.acm.org/doi/10.1145/2461912.2461965) | [(siggraph'14) decoupling noises and features via weighted *l*1-analysis compressed sensing](http://staff.ustc.edu.cn/~lgliu/projects/2014_decouplingnoise/default.htm) |\n| [(tvcg'11) bilateral normal filtering for mesh denoising](https://dl.acm.org/doi/10.1109/tvcg.2010.264) | [(cad'13) feature-preserving filtering with l0 gradient minimization](https://dl.acm.org/doi/10.1016/j.cag.2013.10.025) |                                                              |\n| [(proc. pg'15) guided mesh normal filtering](http://staff.ustc.edu.cn/~juyong/guidedfilter.html) |                                                              |                                                              |\n\n\n\n# 使用\n\n本项目使用较为通用，这里是[详细资料](docs/usage.md)\n\n# 项目文件说明\n\n- `src/` 源文件\n  - `[论文算法]/`\n  - `dependencies/` \n  - `utils/` \n- `data/` 数据集\n- `docs/` 文档\n- `bash/`\n  - `*.bat` win下的任务\n  - `*.sh` linux下的任务\n- `scripts/` 一些封装的python函数\n- `run/`\n  - `[具体任务]/`\n    - `xxx.obj` 去噪后的网格\n    - `time.txt` 记录每个网格去噪的时间开销\n    - `metric.txt` 记录每个网格的[指标](#降噪结果评估)\n\n`metric.txt`中的格式如下：\n```\nname:40359 \ndenoised:run/ir2/40359 \ngt:data/examples/40359 \naad:25.8935\nahd:0.0037325\noep:0.016092\n```\n\n`time.txt`的格式如下（首项和末项格式固定）：\n```\nname:40359edge \nsmd-l0: c++ implementation of \"mesh denoising via l0 minimization\" \naverage dihedral angle: 32.6038\nlambda: 2.10814\nalpha: 0\nexecution time: 139.537 ms\n```\n\n\n# 运行\n\n本项目提供了windows下的一些批处理测试脚本，一键在`run`目录下生成对应的文件。\n\n它们包括\n\n- `test_cube.bat`：测试不同算法在cube模型下的去噪效果，可修改cube的噪声强度等\n- `test_ir.bat`：测试不同非规整网格在不同$l_0$方法下的去噪效果\n- `test_selected.bat`：测试从synthetic、kinect系列数据集中选取的25个模型，在$l_0$方法默认参数下的去噪效果\n- `test_robust.bat`：测试从$l_0$算法超参数$\\lambda$的鲁棒性、亦可用于选取最优参数\n\n这些脚本提供了注释，根据这些注释的提示修改`set=`的内容，便可以进行同类实验。在生成文件后，可以在`make_figure.ipynb`中找到对应任务的可视化代码。如果是自定义任务（即根据bat注释进行了修改），修改cell内的`proj_name`即可。\n\n执行可视化后，在`exp`目录下会保存图像，比如`test_robust.bat`对应的任务可视化图为\n\n![](imgs/robust_block.png)\n\n# 数据集\n\n`test_selected.bat`等脚本需要包含额外的数据集：cnr提供的合成数据集synthetic，扫描数据集kinect v1、kinect v2、kinect f；gcn提供的扫描数据集printdata。\n\n它们可以分别在 https://wang-ps.github.io/denoising.html 和 https://drive.google.com/file/d/1x561-v3z1j0q_1qhyg0fja1w-sqjhypc/view下载\n\n解压后，`data`下的文件为\n\n```\n└── data\n    ├── examples\n    ├── kinect_fusion\n    ├── kinect_v1\n    ├── kinect_v2\n    ├── synthetic\n    └── printeddataset\n```\n\n# 降噪结果评估\n\n## 平均豪斯多夫距离（ahd）\n\n$$\ne_v=\\frac{1}{n_vl_d}\\sum_{v^r_i\\in v^r_m}\n\\min_{\\tilde{v}_j\\in\\tilde{v}_m}\\vert v^r_i-\\tilde{v}_j \\vert\n$$\n\n## 平均法向角距离（aad）\n\n$$\ne_a=\\frac{1}{n_f}\\sum_{f^r_i\\in f^r} \\mathrm{acos}(n^r_i \\cdot \\tilde{n}_i)\n$$\n\n结果以角度为单位\n\n## 翻折边比例（oep）\n\n基于$l_0$论文中folded triangle的可视化，使用边所对应的二面角进行网格评估，给出一个定量度量\n\n$$\ne_f=\\frac{1}{n_e}\\sum_{e^r_i\\in f^r} \\tau(e^r_i)\n\\\\\n\\tau(e)=\\begin{cases}\n1&\\mathrm{dihedral\\ angle}(e)<30^\\circ\n\\\\\n0&\\mathrm{otherwise}\n\\end{cases}\n$$\n\n\n\n\n\n"
  },
  {
    "readme": "# bachelor theses project - a plant identification program in python\nfor my bachelor theses at the end of my 4th year of science at nui gallway, in 2012, i programmed a desktop application prototype in python for helping identify plants.\n\n[French version at the bottom]\n\n# background\nthe version here is an updated version (June 2012). after my exams and these submission, i decided to recreate and improve this application to make it more useful, especially by taking into consideration the suggestions and feedback from the reviewers. whereas the prototype for my these used as pilot plant group the species of fabaceae found in ireland, for this second version i thing a more diverse group: irish shrubs and trees in general.\n\n# use\ntwo options exist, as a binary under windows (recommended for testing), or using python interpreter for the source code, under linux\n\na: windows binary\nto run this program and see what it is like, download the zip file containing the binary (floradiversa.exe) and complementary files, unzip them and run the exe. no special libraries are needed, all is included.\n\nb: linux (as source code)\nto launch this python program as source, it is essential to have python imagining library (pil, not pillow) and tkinter installed. i sorted to make it so that this application will work with both python 2.7 and python 3.4, but the installation of pil is not the same in both cases:\n\npython 2.7 : sudo apt-get install python-pil\n\npython 3 : sudo apt-get install python3-pil.imagetk\n\nfor the windows _source_, i have a separate file (not included), which allows functions like correct mouse wheel scrolling. if you want to test this under windows as source (with the libraries installed), let me know and i can add the windows source code.\n\n# tutorial\n1. let's assume that we have a tree like in this image: https://cdn11.bigcommerce.com/s-999jbj41m8/products/112/images/3162/beech__24524.1483234259__00225.1515640010.500.750.jpg\nwith leaves like these: www.organicfacts.net/wp-content/uploads/beechtree.jpg\nand we want to identify it. but we already know it belongs to the order fagales.\n2. start the program (see instructions above)\n3. in the list on the left, we are going to select the characters which corresponds. First, \"fagales\" as the answer for order. then \"tree\" as structure.\n4. looking at the second image, we can note a few things about the leaves. First their form is elliptic. scrolling down, we can find the section for leaf, and expanding it we can choose \"lf(let) shape\" (=leaf or leaflet). clicking on \"chooser\" opens a new window with images. we can then choose the one matching (\"elliptic\"). click ok to return.\n5. you will have already read the list of possible species (right) changes. some become orange or red (indicating created probability). we will try to eliminate some more.\n6. still under the section of \"leaf\", we can click on \"unsure\" to the right of \"leaves\", at the beginning. this also opens a new window, allowing us to compare with some images presented. we can then observe that none seems to match, so select \"definitely not listed\". Okay.\n7. and one more: under \"leaf observations\", \"none of the above\"\n8. now there remains just one green option. but we can click on the others (orange, red) to see their image. further we can click \"highlight mismatching characteristics\" to see why this species is selected against by which characters (the characters are not always visable in the current view on the left, so try a few species to get the idea).\n9. Finally click on \"fagus sylvatica\" in green, and click details to open a new window. here we can see that the photos match. it is evidenced the beech tree. we can also see the similar species, including carpinus betulus (it is a common mixup, people thinking that this is a beech). below we have the possibility to compare the beech with another species. i suggest you try to compare it with carpinus betulus. you will see the characters which are similar highlighted in green, the others in white. it turns out they are not currently that similar!\n10. let me know if you have any difficulties, or you find some bugs.\n\n# porting for python 3\nwhen i was writing this second version of the application, it was not easy to install pil for python 3. so i converted my code to make it work with python 2.7. but now i would like to make it compatible with both, so that you can try it most easily. this turns out to not be so difficult. First it is important to import equivalent books (which have different names), using a \"try...except importer:..\" statement. here you can find a list of equivalents for each version of python: http://python3porting.com/stdlib.html\n\nthere are several other important things to adjust too. for example, dision with \"/\" in python 2.7 gives an int, but in python 3 it gives a float (which causes problems if it is then used as an index of a list, for example!). to get around this, we can just use \"//\" everywhere, which will always return an int (rounded).\n\nthe result is a version of code which works with both python versions!\n\n# limitations\nit seems that i was too ambitious with this project, and i put so many characters for each plant, and so many application features, that it is not so easy to use the application, but also it increases hugely the work needs to define the profiles of each species. the result was much bigger than i had imagined. so, to make this application really useful, i would need to:\n1. dedicate much more time. All right!\n2. organize and clean up the code that i wrote then, remove bugs, add better commentary and make the program more stable.\n3. change the gui. tkinter is handy but it would be much nicer with a more modern looking and adaptable gui, like gtk.\n\n\n\"normal people... believe that if it ain't broke, don't fix it.\nengineers believe that if it ain't broke, it doesn't have enough features yet.\"\n- scott adams\n\n################################################################################################################################################################################################################################################################\n# English version\n\n\n# 2012 memory : plant identification software\nfor my memory of l4, I have programmed a prototype software in python for the identification of plants\n\n# context\nThis is my memory project for my fourth and final year of Nui Galway Science License. However this version is not the same. After my exams and memory defense, I decided to rewrite and improve this software in order to make it more useful, especially by taking into account the suggestions and criticisms I had in the defence.\nAnd when the prototype for my memory understood as an example the species of the fabaceae family, for the second version, I chose a more diverse group: the trees and shrubs of the irland.\n\n# use\n\nTo launch this python program, you must have python imagining library (pil, not pillow) and tkinter installed. I tried to make the software work in python 2.7 and 3.4 but the installation of pil is not the same in both cases:\n\npython 2.7 : sudo apt-get install python-pil\npython 3 : sudo apt-get install python3-pil.imagetk\n\nfor windows, there is a slightly different version (for some functions like the scroll mouse to work). Thank you for asking me if you didn't linux and you want to test this. but if you want to see it just walk, you can download binary windows into the zip file. with this you do not see the code, but the advantage is that there is no need to install modules/libraries etc.\n\n# tutorial\n1. Let's admit we have a tree like this: https://cdn11.bigcommerce.com/s-999jbj41m8/products/112/images/3162/beech__24524.1483234259__00225.1515640010.500.750.jpg\nwith sheets like these: www.organicfacts.net/wp-content/uploads/beechtree.jpg\nAnd we want to identify him. We already know that it belongs to the fagal order.\n2. start the program (see use above).\n3. On the left list, we'll select characters. First \"fagal\" as an orderer. then \"tree\" as a structure.\n4. By looking at the second image (link above), we can see some things on the sheets. first the elliptical form. scrolling through the list, you will find leaf as section title. Click + to show the options. Now later we find \"lf(let) shape\" (English explanation: leaf (lf for short)=sheet, leaflet=foliole (small leaf)). In the options, you can click on chooser to open a new window with the shape choice. So we can choose eliptic and \"okay\" to come back.\n5. you will already see that the list of possible species changes. those that become orange or red are less likely. We'll try to eliminate as much as possible.\n6. again in the leaf section, we will click on \"unsure\" next to leaves. Here we have some images that appear, but nothing matches our image, so we choose \"definitely not listed\", okay.\n7. Finally, one last: under leaf observation: none of the above.\n8. Now there is only one green option as species. but you can already click on the others to see their image, and then \"highlight mismatching characters\" to see what doesn't match in orange (it's not always visible in the main window, so try several).\n9. Finally click on fagus sylvatica and view details. In the new window you can see that the photos match, and you can read some information below. This is beech (beech). In the list of similar species, we find carpinus betulus, and it is true that people take it as beech. below, it is possible to compare beech with other species. I invite you to select \"carpinus betulus\". We see similar characters in green, others in white.\n10. Please report any bugs or problems you find.\n\n# porting for version 3\nWhen I was writing the code for this program, it was not easy to install python 3 pil, so I made the choice to use python 2.7. But now I wanted to make it compatible with both, which is not very complicated. You have to make a \"try...except importror:.\" for the modules to import with the corresponding versions for each version of python. Here you can find a list of modules with equivalents in each version: http://python3porting.com/stdlib.html\n\nThen you have to make sure of some other little tricks, for example devision \"/\" in python 2.7 gives an int, but in python 3, it gives a float. In both cases, use \"//\" everywhere.\n\n# limitations\nIt seems to me that I was too ambitious with this project, and I put so many characters and functions in it that it is not so obvious not only to use it, but it also increases the work of defining profiles for each species. In short, this project is much bigger than I had imagined. To bring it to something really useful, it would take:\n1. devote a lot of time\n2. Set up the code I wrote, eliminate bugs, make it more stable etc.\n3. Go from tkinter to another more modern guise to make it more attractive.\n",
    "readme_before": "# bachelor thesis project - a plant identification program in python\nfor my bachelor thesis at the end of my 4th year of science at nui galway, in 2012, i programmed a desktop application prototype in python for helping identify plants.\n\n[version française en bas]\n\n# background\nthe version here is an updated version (june 2012). after my exams and thesis submission, i decided to recreate and improve this application to make it more useful, especially by taking into consideration the suggestions and feedback from the examinors. whereas the prototype for my thesis used as pilot plant group the species of fabaceae found in ireland, for this second version i chose a more diverse group: irish shrubs and trees in general.\n\n# usage\ntwo options exist, as a binary under windows (recommended for testing), or using python interpreter for the source code, under linux\n\na: windows binary\nto run this program and see what it is like, download the zip file containing the binary (floradiversa.exe) and complementary files, unzip them and run the exe. no special libraries are need, all is included.\n\nb: linux (as source code)\nto launch this python program as source, it is essential to have python imaging library (pil, not pillow) and tkinter installed. i tried to make it so that this application will work with both python 2.7 and python 3.4, but the installation of pil is not the same in both cases:\n\n    python 2.7 : sudo apt-get install python-pil\n\n    python 3 : sudo apt-get install python3-pil.imagetk\n\nfor the windows _source_, i have a separate file (not included), which allows functions like correct mouse wheel scrolling. if you want to test this under windows as source (with the libraries installed), let me know and i can add the windows source code.\n\n# tutorial\n1. let's suppose that we have a tree like in this image: https://cdn11.bigcommerce.com/s-999jbj41m8/products/112/images/3162/beech__24524.1483234259__00225.1515640010.500.750.jpg\nwith leaves like these: www.organicfacts.net/wp-content/uploads/beechtree.jpg\nand we want to identify it. but we already know it belongs to the order fagales.\n2. start the program (see instructions above)\n3. in the list on the left, we are going to select the characters which correspond. firstly, \"fagales\" as the answer for order. then \"tree\" as structure.\n4. looking at the second image, we can note a few things about the leaves. firstly their form is elliptic. scrolling down, we can find the section for leaf, and expanding it we can choose \"lf(let) shape\" (=leaf or leaflet). clicking on \"chooser\" opens a new window with images. we can then choose the one corresponding (\"elliptic\"). click ok to return.\n5. you will have already noticed the list of possible species (right) changes. some become orange or red (indicating decreased probability). we will try to eliminate some more.\n6. still under the section of \"leaf\", we can click on \"unsure\" to the right of \"leaves\", at the beginning. this also opens a new window, allowing us to compare with some images presented. we can then observe that none seem to match, so select \"definitely not listed\". okay.\n7. and one more: under \"leaf observations\", \"none of the above\"\n8. now there remains just one green option. but we can click on the others (orange, red) to see their image. further we can click \"highlight mismatching characteristics\" to see why this species is selected against by which characters (the characters are not always visable in the current view on the left, so try a few species to get the idea).\n9. finally click on \"fagus sylvatica\" in green, and click details to open a new window. here we can see that the photos correspond. it is indeed the beech tree. we can also see the similar species, including carpinus betulus (it is a common mixup, people thinking that this is a beech). below we have the possibility to compare the beech with another species. i suggest you try to compare it with carpinus betulus. you will see the characters which are similar highlighted in green, the others in white. it turns out they are not actually that similar!\n10. let me know if you have any difficulties, or you find some bugs.\n\n# porting for python 3\nwhen i was writing this second version of the application, it was not easy to install pil for python 3. so i converted my code to make it work with python 2.7. but now i would like to make it compatible with both, so that you can try it most easily. this turns out to not be so difficult. firstly it is important to import equivalent libraries (which have different names), using a \"try...except importerror:..\" statement. here you can find a list of equivalents for each version of python: http://python3porting.com/stdlib.html\n\nthere are several other important things to adjust too. for example, dedision with \"/\" in python 2.7 gives an int, but in python 3 it gives a float (which causes problems if it is then used as an index of a list, for example!). to get around this, we can just use \"//\" everywhere, which will always return an int (rounded). \n\nthe result is a version of code which works with both python versions!\n\n# limitations\nit seems that i was too ambitious with this project, and i put so many characters for each plant, and so many application features, that it is not so easy to use the application, but also it increases hugely the work needed to define the profiles of each species. the result was much bigger than i had imagined. so, to make this application really useful, i would need to:\n1. dedicate much more time. a lot!\n2. organise and clean up the code that i wrote then, remove bugs, add better commentary and make the program more stable.\n3. change the gui. tkinter is handy but it would be much nicer with a more modern looking and adaptable gui, like gtk.\n\n\n\"normal people... believe that if it ain't broke, don't fix it. \nengineers believe that if it ain't broke, it doesn't have enough features yet.\"\n                                                                                                      - scott adams\n\n##########################################################################################\n# version française\n\n\n# 2012 memoire : logiciel d'identification des plantes\npour mon mémoire de l4, j'ai programmé un logiciel prototype en python pour l'identification des plantes\n\n# contexte\nil s'agit de mon projet de mémoire pour mon quatrième et dernière année de licence science à nui galway. cependant cette version n'est pas la même. après mes examens et ma soutenance de mémoire , j'ai décidé de réecrire et améliorer ce logiciel afin de le rendre plus utile, surtout en prennant compte des suggestions et critiques que j'ai eu dans la soutenance. \net lorsque le prototype pour mon mémoire comprennait comme exemple les espèces de la famille fabaceae, pour la deuxième version, j'ai choisit un groupe plus divers : les arbres et arbrisseaux de l'irlande. \n\n# usage\n\npour lancer cette programme python, il faut obligatoirement avoir python imaging library (pil, et non pas pillow) et tkinter installé. j'ai essayé de faire en sorte que le logiciel marche dans python 2.7 et 3.4 mais l'installation de pil n'est pas la même dans les deux cas :\n\n    python 2.7 : sudo apt-get install python-pil\n    python 3 : sudo apt-get install python3-pil.imagetk\n\npour windows, il existe une version un peu different (pour que certaines fonctionallités comme le scroll souris marchent). merci de me demander si vous avez pas linux et vous voulez tester ceci. mais si vous voulez le voir marcher simplement, vous pouvez télécharger le binaire windows dans le fichier zip. avec ceci vous voyez pas le code, mais l'avantage est qu'il n'y a pas besoin d'installer des modules/bibliothèques etc. \n\n# tutoriel\n1. admettons qu'on as un arbre comme ceci : https://cdn11.bigcommerce.com/s-999jbj41m8/products/112/images/3162/beech__24524.1483234259__00225.1515640010.500.750.jpg\navec des feuilles comme ceux-ci : www.organicfacts.net/wp-content/uploads/beechtree.jpg\net qu'on veut l'identifier. or on sait déjà que ça appartient à l'ordre fagales.\n2. commencez la programme (voir usage plus haut).\n3. sur la liste gauche, on va selectionner des characters. premièrement \"fagales\" comme order. puis \"tree\" comme structure.\n4. en consultant la second image (lien ci-dessus), on peut constater quelques choses sur les feuilles. premièrement la forme elliptique. en défilant la liste, vous trouverez leaf comme titre de section. cliquer sur + pour montrer les options. maintenant plus loin on trouve \"lf(let) shape\" (explication d'anglais : leaf (lf pour court)=feuille, leaflet=foliole (petite feuille)). dans les options, on peut cliquer sur chooser pour ouvrir une nouvelle fenêtre avec le choix de forme. on peut donc choisir eliptic et \"okay\" pour revenir. \n5. vous constaterez déjà que la liste des \"possible species\" change. celles qui devient orange ou rouge sont moins probable. on va essayer d'éliminter autant que possible.\n6. encore dans la section leaf, on va cliquer sur \"unsure\" à côté de leaves. ici on a quelques images qui s'affiche, mais rien ne correspond à notre image, donc on choisit \"definitely not listed\", okay.\n7. enfin, un dernier : sous leaf observation : none of the above.\n8. maintenant il reste seulement une option verte comme espèce. mais déjà on peut cliquer sur les autres pour voir leur image, et puis \"highlight mismatching characters\" pour voir ce qui ne correspond pas en orange (c'est pas toujours visible dans la fenêtre principale, donc essayez plusieurs).\n9. enfin cliquer sur fagus sylvatica et view details. dans la nouvelle fenêtre on peut voir que les photos correspondent, et on peut lire quelques informations dessous. il s'agit bien de beech (l'hêtre). dans la liste des espèces semblable, on trouve carpinus betulus, et c'est vrai que les gens prennent ce dernier pour des hêtres. plus bas, on à la possibilité de comparer l'hêtre avec des autres espèces. je vous invite à selectionner \"carpinus betulus\". on voit les caracters semblables en vert, les autres en blanc.\n10. merci de me signaler des bugs ou problèmes que vous trouvez. \n\n# porting pour version 3\nquand j'écrivais le code de cette programme, ce n'étais pas facile d'installer pil pour python 3, donc j'ai fait le choix d'utiliser python 2.7. mais maintenant je voulais le rendre compatible avec les deux, ce qui n'est pas très compliqué. il faut faire un \"try...except importerror:..\" pour les modules à importer avec les versions correspondantes à chaque version de python. ici on peut trouver une liste de modules avec les équivalents dans chaque version : http://python3porting.com/stdlib.html\n\npuis il faut s'assurer de quelques autres petits trucs, par exemple devision \"/\" en python 2.7 donne un int, mais en python 3, ça donne un float. pour un int dans les deux cas, il suffit d'utiliser \"//\" partout. \n\n# limitations\nil me semble que j'étais trop ambitious avec ce projet, et j'ai mis tant de caractères et de fonctionalités dedans qu'il n'est pas si évident non seulement de l'utiliser, mais aussi ça augment le travail de définir les profils pour chaque espèce. en somme ce projet est beaucoup plus grand que je n'avais imaginé. pour l'amèner à quelque chose de vraiment utile, il faudrait :\n1. y consacrer beaucoup, beaucoup de temps\n2. mettre en ordre le code que j'ai écrit, éliminer les bugs, le rendre plus stable etc.\n3. passer de tkinter à un autre gui plus moderne pour que ça soit plus attractif. \n"
  },
  {
    "readme": "♪ pinns\n\nhere are the programmes written in the framework of the work.\n\nthe .py files are for the following chapters:\n\nschroedingernonlin.py - nonlineare schrödingervergleich forward pinn\n\nschroedingernonlininvers.py - nonlineare schrödingergleichung inverse pinn\n\noszillator1d.py - 1d harmonic oscillator forward pinn, with rimbed. 0, coherent condition\n\noszillator1dinvers.py - 1d harmonic oscillator inverse pinn\n\noszillator2d.py - 2d harmonic oscillator forward pinn, with rimbd. 0\n\noszillator2dinvers.py - 2d harmonic oscillator inverse pinn\n\noszillator3d.py - 3d harmonic oscillator forward pinn\n\ntunneleq.py - program to create a special function for the tunnel problem\n\ntunnel.py - tunnelproblem forward pinn\n\ntunnelfinite.py - program for simulation of a particle with casting initial conditions with implicit finite differential method\n\ntunnelgauss.py - tunnelproblem forward pinn with randbed. 0 with casting initial conditions\n\ntunneltest.py - program for testing the tunnel problem forward pinn with randbed. 0\n\nthe .h5 files are the stored neural networks:\n\nnonlin.h5 - nonlinear spine equation forward pinn\n\noszi1d.h5 - 1d harmonic oscillator forward pinn\n\noszi1d_0.h5 - 1d harmonic oscillator forward pinn with rimbed. 0\n\ngauss_paket.h5 - 1d harmonic oscillator in coherent condition forward pinn\n\noszi1dgauss_0.h5 - 1d harmonic oscillator in coherent forward pinn with rimbed. 0\n\ngausstunnel2.h5 - tunnelproblem forward pinn with randbed. 0 with casting initial conditions\n\n\n\n",
    "readme_before": "# pinns\n\nhier sind die im rahmen der arbeit geschriebenen programme zu finden.\n\ndie .py dateien sind für folgende kapitel:\n\nschroedingernonlin.py - nichtlineare schrödingergleichung forward pinn\n\nschroedingernonlininvers.py - nichtlineare schrödingergleichung inverse pinn\n\noszillator1d.py - 1d harmonischer oszillator forward pinn, mit randbed. 0, kohärenter zustand\n\noszillator1dinvers.py - 1d harmonischer oszillator inverse pinn\n\noszillator2d.py - 2d harmonischer oszillator forward pinn, mit randbd. 0\n\noszillator2dinvers.py - 2d harmonischer oszillator inverse pinn\n\noszillator3d.py - 3d harmonischer oszillator forward pinn\n\ntunneleq.py - programm zum erstellen einer eigenfunktion für das tunnelproblem\n\ntunnel.py - tunnelproblem forward pinn\n\ntunnelfinite.py - programm zur simulation eines teilchens mit gauß-anfangsbedingungen mit impliziter finite-differenzen-methode\n\ntunnelgauss.py - tunnelproblem forward pinn mit randbed. 0 mit gauß-anfangsbedingungen\n\ntunneltest.py - programm zum testen der tunnelproblem forward pinn mit randbed. 0\n\ndie .h5 dateien sind die abgspeicherten neuronalen netze:\n\nnonlin.h5 - nichtlineare schrödingergleichung forward pinn\n\noszi1d.h5 - 1d harmonischer oszillator forward pinn\n\noszi1d_0.h5 - 1d harmonischer oszillator forward pinn mit randbed. 0\n\ngauss_paket.h5 - 1d harmonischer oszillator in kohärentem zustand forward pinn\n\noszi1dgauss_0.h5 - 1d harmonischer oszillator in kohärentem zustand forward pinn mit randbed. 0\n\ngausstunnel2.h5 - tunnelproblem forward pinn mit randbed. 0 mit gauß-anfangsbedingungen\n\n\n\n"
  },
  {
    "readme": "♪ t1 check mates\n\n[![quality gate status](https://sonarqube.t1-check-mates.moo.com/api/project_badges/measure?project=t1-check-mates_monorepo_aytipbbvumsodm8riwyg&metric=alert_status&token=sqb_f6d3edbac06a89 id=t1-check-mates_monorepo_aytipbbumsodm8riwyg [![coverage](https://sonarqube.t1-check-mates.mooo.com/api/project_badges/measure?project=t1-check-mates_monorepo_aytipbbumsodm8riw id=t1-check-mates_monorepo_aytipbbumsodm8riwyg [![lines of code](https://sonarqube.t1-check-mates.moooo.com/api/project_badges/measure) id=t1-check-mates_monorepo_aytipbbvumsodm8riwyg)\n\n## Project description\n\nthe project consists in the realization of a back-end and a front end that allows the game of two variants of chess\n- darkchess\n- invisible chess\n\nor other, depending on the decisions of the group\nwill allow to play online, computer-human, or human,\nand will allow connection with social media.\n\n## members of the group\n- nardon filippo 1020635\n- admirable roberto diego 1021216\n- black alessandro 1087314\n- swordsmen Thursday 1021270\n- emanuele battal 1019620\n- bernard monts 1020402\n- huang xuanqiang 1030271\n",
    "readme_before": "# t1 check mates\n\n[![quality gate status](https://sonarqube.t1-check-mates.mooo.com/api/project_badges/measure?project=t1-check-mates_monorepo_aytipbbvumsodm8riwyg&metric=alert_status&token=sqb_250d6d3edbac06a8908c16e9a275691fb3d37d19)](https://sonarqube.t1-check-mates.mooo.com/dashboard?id=t1-check-mates_monorepo_aytipbbvumsodm8riwyg) [![coverage](https://sonarqube.t1-check-mates.mooo.com/api/project_badges/measure?project=t1-check-mates_monorepo_aytipbbvumsodm8riwyg&metric=coverage&token=sqb_250d6d3edbac06a8908c16e9a275691fb3d37d19)](https://sonarqube.t1-check-mates.mooo.com/dashboard?id=t1-check-mates_monorepo_aytipbbvumsodm8riwyg) [![lines of code](https://sonarqube.t1-check-mates.mooo.com/api/project_badges/measure?project=t1-check-mates_monorepo_aytipbbvumsodm8riwyg&metric=ncloc&token=sqb_250d6d3edbac06a8908c16e9a275691fb3d37d19)](https://sonarqube.t1-check-mates.mooo.com/dashboard?id=t1-check-mates_monorepo_aytipbbvumsodm8riwyg)\n\n## descrizione del progetto\n\nil progetto consiste nella realizzazione di un back-end e un front end che permetta il gioco di due varianti di scacchi\n- darkchess\n- invisible chess\n\no altro, a seconda delle decisioni del gruppo\npermetterà di giocare online, computer-human, o human-human,\ne permetterà collegamento con i social.\n\n## membri del gruppo\n- nardon\tfilippo\t1020635\n- ammirabile \tdiego roberto \t1021216\n- neri    \talessandro \t1087314\n- spadaccini   \tgiovanni \t1021270\n- pischetola   \temanuele \t1019620\n- macchioni montini\tbernardo\t1020402\n- huang    \txuanqiang \t1030271\n"
  },
  {
    "readme": "# Bachelor of computer science\n## Algorithms, works and projects carried out during computer science graduation since 2017.1\n\n* [programming language i](https://github.com/jaimelay/uerj/tree/master/lp1)\n* [programming language ii](https://github.com/jaimelay/uerj/tree/master/lp2)\n* [data structures and algorithms](https://github.com/jaimelay/uerj/tree/master/aed/)\n* [language structures](https://github.com/jaimelay/uerj/tree/master/edl)",
    "readme_before": "# bacharelado ciência da computação\n### algoritmos, trabalhos e projetos realizados durante a graduação de ciência da computação desde 2017.1\n\n* [linguagem de programação i](https://github.com/jaimelay/uerj/tree/master/lp1)\n* [linguagem de programação ii](https://github.com/jaimelay/uerj/tree/master/lp2)\n* [algoritmos e estruturas de dados](https://github.com/jaimelay/uerj/tree/master/aed/)\n* [estruturas de linguagens](https://github.com/jaimelay/uerj/tree/master/edl)"
  },
  {
    "readme": "# final task\n[!] [journals] (https: / / img.shields.io / badge / paper-icadeis-blue.svg] (http: / / ijaseit.insightsociy.org / index. Php? options = com _ content & view = Article & id = 9 & itemid = 1 & Article _ id = 8894)\n[!] [journals] (https: / / img.shields.io / badge / journal -telkom-red.svg] (https: / / drive.google.com / d / 12hs- 1cebcyjyse- 0thvurubvu / view?\n[! [datasset] (/ / img.shields.io / badge / datadset -brightgreen.svg] (https: / / drive.google.com / open? id = 1hinke1e0z1h1h2b _ qndndbrnpjBel1 _ ovu8)\n[!\n[!] [references] (/ img.shields.io / badge / reference -reports -yellow.svg] (https: / / drive.google.com / open? id = 1224meakq0t0qudgoygyzyfru7l)\n[!\n\n# step to run the program\n\n# # # # 1. The main program for running files is * * _ play. * * *\n# # # # 2. before running file * * _ main.py * *:\ndownload word2vec models and postag models to the following links.\n- [model word2vec - cbow] (https: / / drive.google.com / drive / folders / 194nv9gy8mtchintti187v7vxxx2V1vfey? usp = sharing) -- then keep it in the input / cbow folder\n- [model word2vec] - skipgram] (https: / / drive.google.com / drive / Folders / 1dfeds -12wurquqqh1p4f1efqxaok26? usp = sharing) -- then store it in the input / skipgram folder\n- [postag model] (https: / / drive.google.com / drive / folks / 1sndp4tlr3r3l5hxbjlvs _ j6fc1r9m? usp = sharing) -- then keep it in the input / tagger folder\n# # # # 3. modules required on this project are:\n- [nltk] (https: / / pypi.org / project / nltk /) - > ('nltk.download (' punkt '))\n- [gensim] (https: / / pypi.org / project / gensim /) (for word2vec)\n- [numpy] (https: / / pypi.org / project / numpy /) (mathematical library)\n- [pandas] (https: / / pypi.org / project / pandas /) (data manipulation csv)\n- [scicit-learn] (https: / / pypi.org / project / scicit-learn /) (classification using svm)\n- [sastrawi] (https: / / pypi.org / project / sastrawi /) (remove stopword and stemmer in indonesia)\n- [crf-tagger] (https: / / pypi.org / project / python-crfsuite /) (for posttager)\n# # # # 4. program using python version 3.\nContact: [neg mediamer] (https: / / www.linkedin.com / in / gugunmdr)\n\n---\n\n> * hopefully useful. Life is only once, sometimes opportunities come untold, do it before you regret it!\n",
    "readme_before": "# final task\r\n[![jurnal](https://img.shields.io/badge/paper-icadeis-blue.svg)](http://ijaseit.insightsociety.org/index.php?option=com_content&view=article&id=9&itemid=1&article_id=8894)\r\n[![jurnal](https://img.shields.io/badge/jurnal-telkom-red.svg)](https://drive.google.com/file/d/12hs-1cebcyjyse-0thvzrurnag44ubvu/view?usp=sharing)\r\n[![dataset](https://img.shields.io/badge/dataset-hadits-brightgreen.svg)](https://drive.google.com/open?id=1hinke1ue0z1ih2b_qndnpwjbel1_ovu8)\r\n[![poster](https://img.shields.io/badge/poster-laporan-teal.svg)](https://drive.google.com/open?id=1htmi08mmc2037v297vldijdjz43jij36)\r\n[![referensi](https://img.shields.io/badge/referensi-laporan-yellow.svg)](https://drive.google.com/open?id=1y24meakq5wt0qudgoylefgyzywfhru7l)\r\n[![present](https://img.shields.io/badge/materi-presentasi-orange.svg)](https://drive.google.com/open?id=1lzrbeibmlzfqwxlpdo8p2wkhrnysc2b5py3d4hjgfxg)\r\n\r\n# step untuk menjalankan program\r\n\r\n#### 1. program utama untuk running file yaitu **_main.py**\r\n#### 2. sebelum running file **_main.py** :\r\ndownload model word2vec dan model postag pada link berikut.\r\n  - [model word2vec - cbow](https://drive.google.com/drive/folders/194nv9gy8mtchti18w7vu7gxxz21vfety?usp=sharing) -- lalu simpan di folder input/cbow\r\n  - [model word2vec - skipgram](https://drive.google.com/drive/folders/1dfed-1wuurqxuiqh1pb4f1efdqxaok26?usp=sharing) -- lalu simpan di folder input/skipgram\r\n  - [model postag](https://drive.google.com/drive/folders/1sndp4tlr3cyl5hx7htbjlvs_j6fc1r9m?usp=sharing) -- lalu simpan di folder input/tagger\r\n#### 3. modules yang dibutuhkan pada project ini yaitu : \r\n- [nltk](https://pypi.org/project/nltk/) -> ('nltk.download('punkt')')\r\n- [gensim](https://pypi.org/project/gensim/) (untuk word2vec)\r\n- [numpy](https://pypi.org/project/numpy/) (library matematika)\r\n- [pandas](https://pypi.org/project/pandas/) (manipulasi data csv)\r\n- [scikit-learn](https://pypi.org/project/scikit-learn/) (klasifikasi menggunakan svm)\r\n- [sastrawi](https://pypi.org/project/sastrawi/) (remove stopword dan stemmer dalam bahasa indonesia)\r\n- [crf-tagger](https://pypi.org/project/python-crfsuite/) (untuk posttager)\r\n#### 4. program menggunakan python versi 3.\r\ncontact : [gugun mediamer](https://www.linkedin.com/in/gugunmdr)\r\n\r\n---\r\n\r\n> *semoga bermanfaat. hidup hanya sekali, terkadang kesempatan datang tak berkabar, lakukan sebelum kau menyesal!*\r\n"
  },
  {
    "readme": "translation error",
    "readme_before": "[english version](#baxter-robot-manipulative-tasks-using-machine-learning)\n\n# izvedba manipulacijskih zadataka baxter robota primjenom strojnog učenja\nza poznati problem rješavanja hanojskih tornjeva u najmanjem broju koraka razvijen je algoritam upravljanja zasnovan na tehnici podržanog strojnog učenja q-learning. nakon simulacije na računalu, algoritam je potvrđen eksperimentalno na robotu baxter. robot uz pomoć optitrack sustava lokalizira predmete u radnom prostoru te transformira njihove lokacije u vlastiti koordinatni sustav. zatim pomoću već razvijenog modela upravljanja izvršava slijed radnji potrebnih za premještanje kolutova. upravljanje robotom te međusobna komunikacija između računala, robota i optitrack sustava ostvareni su korištenjem ros-a.\n\niako je ovaj paket namijenjen korištenju uz baxter robota, implementacija q-learning algoritma se može koristiti nezavisno.\n\n### upute za instalaciju:\n**napomena:** svugdje gdje se traži ros verzija koristiti 'kinetic' (često umjesto 'indigo')\n1. instalirati ros (kinetic): http://wiki.ros.org/kinetic/installation/ubuntu\n2. instalirati baxter sdk prema [uputama](http://sdk.rethinkrobotics.com/wiki/workstation_setup#step_3:_create_baxter_development_workspace)\n3. instalirati moveit! za ros kinetic prema [uputama](http://moveit.ros.org/install/)\n4. instalirati vrpn prema [uputama](#upute-za-instalaciju-vrpn-a--instructions-for-installing-vrpn)\n5. instalirati ovaj paket sljedećim naredbama:\n```\nroscd\ncd ../src\ngit clone https://github.com/mkrizmancic/qlearn_baxter.git\ncd ..\ncatkin_make\n```\n6. radi lakše interakcije s robotom preporuka je dodati sljedeće linije u ~/.bashrc:\n```\nalias baxter=\"./baxter.sh\"  // postavlja baxter ros environment\nalias sonar=\"rostopic pub /robot/sonar/head_sonar/set_sonars_enabled std_msgs/uint16 0\" // gasi sonar\nalias bax_enable=\"rosrun baxter_tools enable_robot.py -e\" // uključi robota\nalias bax_disable=\"rosrun baxter_tools enable_robot.py -d\" // isključi robota\n```\n\n### upute za pokretanje\nu datoteci [across.launch](../launch/across.launch) po potrebi promijeniti adresu servera.\n\nprilikom svakog otvaranja nove konzole:\n```\nroscd\ncd ..\n.\\baxter.sh\n```\n\n**za pronalažanje transformacija:**\n- u prvu konzolu: ```roslaunch qlearn_baxter find_transformations.launch```\n- u drugu konzolu: ```rosrun qlearn_baxter interpolate.py```\n- pogledati upute u docstringu u ```interpolate.py```\n\n\n**za testiranje:**\n- ```roslaunch qlearn_baxter testing.launch```\n\n**za izvedbu zadatka:**\n- ```roslaunch qlearn_baxter main.launch```\n\n**za pokretanje samo q-learning algoritma:**\n- ```python qlearning.py```\n\n\n# baxter robot manipulative tasks using machine learning\nin order to solve a well-known tower of hanoi problem, an algorithm based on reinforcement machine learning technique q-learning is developed. after simulation on computer, the algorithm is experimentally confirmed using baxter robot. using optitrack localization system, the robot finds objects in its working area and transforms their locations in its own coordinate system. then, using already implemented control model, it performs a set of moves necessary to solve the problem. control of the robot, as well as the communication between computer, robot and optitrack system are implemented using ros.\n\nalthough this package is intended to be used with baxter robot, q-learning algorithm is stand-alone.\n\n### installation:\n**note:** everywhere ros version is asked, use 'kinetic' (often instead of 'indigo')\n1. install ros (kinetic): http://wiki.ros.org/kinetic/installation/ubuntu\n2. install baxter sdk following this [instructions](http://sdk.rethinkrobotics.com/wiki/workstation_setup#step_3:_create_baxter_development_workspace)\n3. install moveit! for ros kinetic following this [instructions](http://moveit.ros.org/install/)\n4. install vrpn following this [instructions](#upute-za-instalaciju-vrpn-a--instructions-for-installing-vrpn)\n5. install this package with follwing commands:\n```\nroscd\ncd ../src\ngit clone https://github.com/mkrizmancic/qlearn_baxter.git\ncd ..\ncatkin_make\n```\n6. for easier interaction with the robot, it is recommended to add following lines to ~/.bashrc:\n```\nalias baxter=\"./baxter.sh\"  // set up baxter ros environment\nalias sonar=\"rostopic pub /robot/sonar/head_sonar/set_sonars_enabled std_msgs/uint16 0\" // disable sonar\nalias bax_enable=\"rosrun baxter_tools enable_robot.py -e\" // enable robot\nalias bax_disable=\"rosrun baxter_tools enable_robot.py -d\" // disable robot\n```\n\n### execution\nif needed, change the server adress in [across.launch](../launch/across.launch).\n\n**finding transformations:**\n- in first console: ```roslaunch qlearn_baxter find_transformations.launch```\n- in second console: ```rosrun qlearn_baxter interpolate.py```\n- follow the instructions given in docstring of ```interpolate.py```\n\n**testing:**\n- ```roslaunch qlearn_baxter testing.launch```\n\n**starting complete system:**\n- ```roslaunch qlearn_baxter main.launch```\n\n**only q-learning algorithm**\n- ```python qlearning.py```\n\n### upute za instalaciju vrpn-a / instructions for installing vrpn\n```\ncd ~\nmkdir custompackages\ncd custompackages\ngit clone https://github.com/vrpn/vrpn.git\ncd vrpn\nmkdir build\ncd build\ncmake ..\nmake\nsudo make install\nroscd\ncd ../src\ngit clone https://github.com/larics/vrpn_client_ros.git\ncd ..\ncatkin_make\n```\n"
  },
  {
    "readme": "translation error",
    "readme_before": "trenger gulp og browsersync installert for att fungera.\n"
  },
  {
    "readme": "# Integrator project of the first semester of the school year 2023-2024 in the law-isep #\n\nthis is the project model for the first half of the second year of the law (licenciatura em engenharia informática) (http://www.isep. ipp.pt/course/course/26) in 2023/2024.\n\ncontains didactic artifacts relevant to the integrative project to be developed during the first semester of the academic year 2023-2024 in the computer engineering course of the [porto's higher engineering institute (isep)] (http://www.isep.ipp.pt).\n\n\nProject organization\n\n\nthis project uses java and maven.\n\nto configure maven to run tests, it is necessary to declare the \"maven-surefire-plugin\" plugin in the \"pom.xml\" file and configure its dependencies. for this purpose, the following dependencies are necessary:\n* Apache poi\n- https://mvnrepository. with/artifact/org.apache.poi/poi\n- required to work with .xlsx files\n\n\n# Codes maven #\n\n♪ compile the code ♪\n```\nmvn clean package\n```\n#### executa o codigo\n```\nmvn exec:java\n```\n### verificar a cobertura dos testes\n```\nmvn clean verify\n```\n### executar o programa final (.jar)\n```\ncd target\n```\n```\njava -jar lapr3-project-1.0.0-jar-with-dependecies.jar\n```\n\n## executar o programa de arqcp (c)\n```\ncd src/main/arqcp/sprint3/main\n```\n```\nmake run\n```\n\n## lista de conteúdos \n\n* [artefactos globais](./docs/global-artifacts/readme.md)\n* [diagramas bddad](./docs/bddad/models/diagrams.md)\n* [estrutura do armazém (fsiap)](docs/fsiap/readme.md)\n\n## burndown chart\n\n![x](./docs/scrum/image.png)\n\n## elementos do grupo \n\n\n| número de estudante | nome            |\n|---------------------|-----------------|\n| **1221694**         | joão pinto      |\n| **1220612**         | josé sá         | \n| **1211883**         | mariana correia |          \n| **1201804**         | rafael araújo   |\n| **1221700**         | vasco sousa     |\n",
    "readme_before": "# projeto integrador do primeiro semestre do ano letivo 2023-2024 na lei-isep #\n\neste é o modelo do projeto para o primeiro semestre do segundo ano do lei [(licenciatura em engenharia informática)](http://www.isep.ipp.pt/course/course/26) em 2023/2024.\n\ncontém artefatos didáticos relevantes para o projeto integrativo a ser desenvolvido durante o primeiro semestre do ano acadêmico de 2023-2024 no curso de engenharia informática do [instituto superior de engenharia do porto (isep)](http://www.isep.ipp.pt).\n\n\n## organização do projeto \n\n\neste projeto utiliza java e o maven.\n\npara configurar o maven para executar testes, é necessário declarar o plugin \"maven-surefire-plugin\" no arquivo \"pom.xml\" e configurar suas dependências. para este propósito, são necessárias as seguintes dependências:\n* apache poi\n    - https://mvnrepository.com/artifact/org.apache.poi/poi\n        - necessário para trabalhar com ficheiros .xlsx\n \n\n### codigos maven \n\n#### compila o codigo\n```\nmvn clean package\n```\n#### executa o codigo\n```\nmvn exec:java\n```\n### verificar a cobertura dos testes\n```\nmvn clean verify\n```\n### executar o programa final (.jar)\n```\ncd target\n```\n```\njava -jar lapr3-project-1.0.0-jar-with-dependecies.jar\n```\n\n## executar o programa de arqcp (c)\n```\ncd src/main/arqcp/sprint3/main\n```\n```\nmake run\n```\n\n## lista de conteúdos \n\n* [artefactos globais](./docs/global-artifacts/readme.md)\n* [diagramas bddad](./docs/bddad/models/diagrams.md)\n* [estrutura do armazém (fsiap)](docs/fsiap/readme.md)\n\n## burndown chart\n\n![x](./docs/scrum/image.png)\n\n## elementos do grupo \n\n\n| número de estudante | nome            |\n|---------------------|-----------------|\n| **1221694**         | joão pinto      |\n| **1220612**         | josé sá         | \n| **1211883**         | mariana correia |          \n| **1201804**         | rafael araújo   |\n| **1221700**         | vasco sousa     |\n"
  },
  {
    "readme": "# bachelor project\n\nGroup 2:\n---------------------------------------------------\n* Andreas holm jørgensen, andjo16\n* food kempf, makem16\n* jaff gyldenbrand forest jørgensen, jegyl16\n\nThe translator is available as binary file on toplevel in this folder.\n\nthe translator is run commonly with the command\n```\n./compiler  \n```\ninput programmet, der skal oversættes, læses fra standard input.  \noutput assembler programmet skrives til standard output.  \nevt. fejlmeddelelser skrives til standard error.  \n\noversætteren kan køres med følgende flag  \n-dbody (printer det abstrakte syntakstræ for programmet, genereret under oversættelsen, med typer)  \n-dasm (printer den interne repræsentation af det genererede assemblerprogram)  \n-noruncheck (oversætter programmet uden at indsætte runtimecheck)  \n-nooptimize (oversætter programmet uden at udføre liveness analyse og peephole optimering)  \n\nalle flag kan bruges i den kombination der ønskes.\n\nønskes oversætteren oversat til binær på ny, kan dette gøres med de følgende kommandoer fra mappen compiler (topniveau)`\n```\nmake parser  \nmake\n```\nkommandoen 'make parser' oversætter scanneren og parseren til lex.yy.c, y.tab.h og y.tab.c og lægger dem i mappen src/scanparse  \nkommandoen 'make' genererer en build-mappe på top-niveau med oversætteren som binær fil kaldet compiler\n\n\nønskes oversætteren oversat på ny fra bunden kan dette gøres med  \n```\nmake cleanparser  \nmake clean  \n```\nefterfulgt af de før beskrevne kommandoer\n\negne tests  \nder medfølger et udkast til en test suite som ligger i mappen test.  \ndet kan køres ved at stå i mappen test og køre kommandoen:  \n```\n./testsuite.sh\n```  \ndet crasher en gang imellem så vi anbefaler man køre  \n```\n./testsuite.sh clean\n```  \nefter hver kørsel.",
    "readme_before": "# bachelor-project\n\ngruppe 2:\n---------------------------------------\n* andreas holm jørgensen, andjo16\n* mads kempf, makem16\n* jeff gyldenbrand skov jørgensen, jegyl16\n\noversætteren findes som binær fil på topniveu i denne mappe.\n\noversætteren køres almindeligt med kommandoen  \n```\n./compiler  \n```\ninput programmet, der skal oversættes, læses fra standard input.  \noutput assembler programmet skrives til standard output.  \nevt. fejlmeddelelser skrives til standard error.  \n\noversætteren kan køres med følgende flag  \n-dbody (printer det abstrakte syntakstræ for programmet, genereret under oversættelsen, med typer)  \n-dasm (printer den interne repræsentation af det genererede assemblerprogram)  \n-noruncheck (oversætter programmet uden at indsætte runtimecheck)  \n-nooptimize (oversætter programmet uden at udføre liveness analyse og peephole optimering)  \n\nalle flag kan bruges i den kombination der ønskes.\n\nønskes oversætteren oversat til binær på ny, kan dette gøres med de følgende kommandoer fra mappen compiler (topniveau)`\n```\nmake parser  \nmake\n```\nkommandoen 'make parser' oversætter scanneren og parseren til lex.yy.c, y.tab.h og y.tab.c og lægger dem i mappen src/scanparse  \nkommandoen 'make' genererer en build-mappe på top-niveau med oversætteren som binær fil kaldet compiler\n\n\nønskes oversætteren oversat på ny fra bunden kan dette gøres med  \n```\nmake cleanparser  \nmake clean  \n```\nefterfulgt af de før beskrevne kommandoer\n\negne tests  \nder medfølger et udkast til en test suite som ligger i mappen test.  \ndet kan køres ved at stå i mappen test og køre kommandoen:  \n```\n./testsuite.sh\n```  \ndet crasher en gang imellem så vi anbefaler man køre  \n```\n./testsuite.sh clean\n```  \nefter hver kørsel."
  },
  {
    "readme": "# sibuker topsis\n< p align = justice > this project is the result of my script which is a working exchange information system with a decision-supporting system using a topsis. There are some features that: the list should be activated by email, looking for the vacancy that the alumni wants, can bridge between the company's side and the alumni in the job label and the email notification when there is a review of the company that the alumni and the alumni notification of the alumni are calling for the opening of the company. This project was created using template (frontend and backend), bootstrap 4, javascomb, codeigliter 4. < / p >\n\n# server requests\nPhp version 7.3 or recommended using most recent. The server is adjusted with a codegiter specification to run properly.\n\n# installation\nPlease follow the steps below to travel the project.\n1. Make sure it's installed composer in the device used. if not installed, can [here] (https: / / getcomposer.org /) install composer.\n2 uncomment # before \"'; extension = intl\"' becomes \"'extension = intl\"'.\n3. login to the project directory, then open the terminal / cmd type \"'composer update\"'.\n4. Imports db file is located in db folder.\n5. edit config using file env change env file renv renname to .env then adjust:\n* insert corresponding base _ url - > \"'app.baseurl =\"'\n* insert suitable dbms hostname - > \"'databas.default.hostname =\" \"'.\n* enter suitable dbms name - > \"'databace.default.hostname =\"'.\n* enter the corresponding dbms username - > \"'databas.default.ussername =\" \"'.\n* enter appropriate dbms password - > \"'databace.defoult.password =\" \"'.\n6. To get into the backend there are 3 permissions which are\n* company: (username: tirta) (password: 1)\n* admin: (username: admin) (password: admin)\n* alumni: (username: 1718006) (password: 1)\nLast seven. Type \"'fp spark serve\"' to run the program and the program is ready for use.\n\n# demo\n< br > video about the app: https: / / www.youtube.com / watch? v = o3qvmxbdd9e & t = 16s\n\n\n",
    "readme_before": "# sibuker topsis\n<p align=justify>projek ini adalah hasil dari skripsi saya yaitu sistem informasi bursa kerja dengan sistem pendukung keputusan menggunakan topsis. terdapat beberapa fitur yaitu: daftar harus aktivasi dengan email, mencari rekomendasi lowongan yang sesuai dengan kriteria yang diinginkan oleh alumni, bisa menjembatani antara pihak perusahaan dengan alumni dalam masalah lamar pekerjaan dan notifikasi email saat ada review dari perusahaan yang dilamar lowongannya oleh alumni serta notifikasi dari alumni saat melamar lowongan dari pihak perusahaan. projek ini dibuat menggunakan template(frontend dan backend), bootstrap 4, javascript, codeigniter 4.</p>\n\n# server requirements\nphp version 7.3 atau direkomendasikan menggunakan yang paling terbaru. server disesuaikan dengan spesifikasi codeigniter untuk bisa berjalan dengan baik.\n\n# instalasi\nsilahkan ikuti langkah-langkah di bawah ini untuk menjalan projek.\n1. pastikan sudah terinstall composer di device yang dipakai. jika belum terinstall, bisa ke [sini](https://getcomposer.org/) untuk menginstall composer.\n2. uncomment # sebelum ```;extension=intl``` menjadi ```extension=intl```.\n3. masuk ke directory project, kemudian buka terminal/cmd ketik ```composer update```.\n4. import db file nya terletak di folder db.\n5. edit config menggunakan file env rubah file env ganti nama menjadi .env kemudian sesuaikan : \n   * masukkan base_url yang sesuai -> ```app.baseurl = ''``` \n   * masukkan hostname dbms yang sesuai -> ```database.default.hostname = ''``` .\n   * masukkan nama dbms yang sesuai -> ```database.default.hostname = ''``` .\n   * masukkan username dbms yang sesuai -> ```database.default.username = ''``` .\n   * masukkan password dbms yang sesuai -> ```database.default.password = ''``` .\n6. untuk masuk ke halaman backend terdapat 3 hak akses yaitu\n   * perusahaan  : (username : tirta) (password : 1)\n   * admin       : (username : admin) (password : admin)\n   * alumni      : (username : 1718006) (password : 1)\n7. terakhir ketik ```php spark serve``` untuk menjalankan programnya dan program siap digunakan.\n\n# demo\n<br>video about the app : https://www.youtube.com/watch?v=o3qvmxbdd9e&t=16s\n\n\n"
  },
  {
    "readme": "bitcoincode\n",
    "readme_before": "bitcoincode\n"
  },
  {
    "readme": "we use:\nscipy 0.8.0\nnumpy 1.5.1\nawesumpy 3.12\n\na simple framework has now been built that should be generic enough.\n\nthe main.py script can now be run as follows:\nmain.py < index >\n\nwhere index corresponds to that element in the list from proc.py\n",
    "readme_before": "vi benytter:\nscipy 0.8.0\nnumpy 1.5.1\nawesumpy 3.12\n\nder er nu bygget et simpelt framework der burde være generisk nok.\n\nscriptet main.py kan nu køres således:\nmain.py <index>\n\nhvor index svarer til det element i listen fra proc.py\n"
  },
  {
    "readme": "# shiva's quests\nThis adventure game features a fictional avatar of the shiva god, who fights against the forces of evil to save the earth.\ndeveloped by Damodarane jean-baptist, elumalai sriguru and zhang victor, bachelor's 2 computer students, this project promises an immersive and thrilling experience.\n\n## game description\nshiva's quests is an adventure game where players embody a shiva avatar. The player must navigate through different levels, facing enemies and solving puzzles to progress in his ultimate quest: saving the land from the evil that threatens him.\n\n## main features\n- avatar of shiva: embody the power of god and use mythical powers to fight the forces of evil.\n\n- various levels: explore a variety of levels, each with its own challenges and obstacles to overcome.\n\n- fight and puzzles: face formidable enemies and solve puzzles to advance in the game.\n\n- graphics: enjoy quality sprites and graphics for an immersive visual experience.\n\n# installation\nTo play shiva's quests, follow these simple steps:\n\nclone this github repository on your local machine:\n```\r\nhttps://github.com/jeanbaptiste02/shivas-quests-jeu-d-aventure.git\r\n```\r\n\r\nassurez-vous d'avoir ```java se 11``` ou une version ultérieure installée sur votre système.\r\n\r\nlancez le jeu en exécutant le fichier principal ```shivasquests.java```.\r\n\r\n## contenu du projet\r\nce dépôt github contient les éléments suivants :\r\n\r\n- sprites : images des personnages pour leurs mouvements et actions.\r\n\r\n- autres png : autres ressources graphiques nécessaires au jeu.\r\n\r\n- map : cartes et environnements pour les différents niveaux du jeu.\r\n\r\n- code source : le code source du jeu, écrit en javase-11.\r\n\r\n## licence\r\nce projet est sous licence gnu affero general . consultez le fichier license pour plus de détails.\r\n\r\npour toute contribution ou réutilisation de ce projet, veuillez mentionner les noms des développeurs de ce projet : [damodarane jean-baptiste](https://github.com/jeanbaptiste02), [elumalai sriguru](https://github.com/sriguru95) et [zhang victor](https://github.com/seed4616). pour collaborer, veuillez les contacter pour obtenir leur consentement formel.\r\n",
    "readme_before": "# shiva's quests\r\nce jeu d'aventure met en scène un avatar fictif du dieu shiva, qui se bat contre les forces du mal pour sauver la terre. \r\ndéveloppé par damodarane jean-baptiste, elumalai sriguru et zhang victor, étudiants en licence 2 informatique, ce projet promet une expérience immersive et palpitante.\r\n\r\n## description du jeu\r\nshiva's quests est un jeu d'aventure où les joueurs incarnent un avatar de shiva. le joueur doit naviguer à travers différents niveaux, affrontant des ennemis et résolvant des énigmes pour progresser dans sa quête ultime : sauver la terre du mal qui la menace.\r\n\r\n## fonctionnalités principales\r\n- avatar de shiva : incarnez la puissance de dieu et utilisez des pouvoirs mythiques pour combattre les forces du mal.\r\n\r\n- niveaux variés : explorez une variété de niveaux, chacun avec ses propres défis et obstacles à surmonter.\r\n\r\n- combat et énigmes : affrontez des ennemis redoutables et résolvez des énigmes pour avancer dans le jeu.\r\n\r\n- graphismes : profitez de sprites et de graphismes de qualité pour une expérience visuelle immersive.\r\n\r\n# installation\r\npour jouer à shiva's quests, suivez ces étapes simples :\r\n\r\nclonez ce dépôt github sur votre machine locale :\r\n```\r\nhttps://github.com/jeanbaptiste02/shivas-quests-jeu-d-aventure.git\r\n```\r\n\r\nassurez-vous d'avoir ```java se 11``` ou une version ultérieure installée sur votre système.\r\n\r\nlancez le jeu en exécutant le fichier principal ```shivasquests.java```.\r\n\r\n## contenu du projet\r\nce dépôt github contient les éléments suivants :\r\n\r\n- sprites : images des personnages pour leurs mouvements et actions.\r\n\r\n- autres png : autres ressources graphiques nécessaires au jeu.\r\n\r\n- map : cartes et environnements pour les différents niveaux du jeu.\r\n\r\n- code source : le code source du jeu, écrit en javase-11.\r\n\r\n## licence\r\nce projet est sous licence gnu affero general . consultez le fichier license pour plus de détails.\r\n\r\npour toute contribution ou réutilisation de ce projet, veuillez mentionner les noms des développeurs de ce projet : [damodarane jean-baptiste](https://github.com/jeanbaptiste02), [elumalai sriguru](https://github.com/sriguru95) et [zhang victor](https://github.com/seed4616). pour collaborer, veuillez les contacter pour obtenir leur consentement formel.\r\n"
  },
  {
    "readme": "# abd-motors - vehicle management application\n\nComplete web application for vehicle management, including rental and sale, developed for abd-motors.\n\nOverview\n\nabd-motors is a full-stack application to manage a fleet of vehicles and related folders (rent/sale). It includes a modern user interface and a robust api rest.\n\nKey features\n\n- complete vehicle management (addition, modification, deletion)\n- rental and sales system\n- management of client files\n- administration interface\n- authentication and role management\n- upload and storage of documents on aws s3\n- responsive and modern interface\n- **genia** : generative ii interface for querying documents\n\n## genia - ia interface for document analysis\n\ngenia is an integrated feature allowing sales representatives to interview pdf documents (rental contracts, sales records) in natural language.\n\nFeatures\n- upload pdf documents (stored on aws s3)\n- automatic extraction of document text\n- direct import from the tank s3\n- conversational interface with the ia\n- contextual responses based on document content\n\nTechnology\n- ollama (llama model2) for natural language processing\n- aws s3 for storing documents\n- pypdf2 for text extraction\n- React for user interface\n\n## use\n1. access the genia page from the menu\n2. upload a pdf document or import it from s3\n3. Ask a natural language question about the document\n4. receive an answer generated by the ia, based on the content of the document\n\nThis tool allows traders to quickly extract relevant information from documents without having to read them in full, thereby improving the efficiency and quality of customer service.\n\nArchitecture\n\nThe project is divided into two main parts:\n\n- **frontend** : react application with material-ui\n- **backend** : api rest django with postgresql\n\nDetailed documentation\n\n- [frontend documentation] (frontend/readme.md)\n- [backend documentation] (backend/readme.md)\n\nTechnical stack\n\n### frontend\n- React 18\n- material-ui v5\n- react router v6\n- axios\n- jwt authentication\n\n##backend\n- python 3.13\n- django 4.2.19\n- django rest framework\n- postgresql\n- jwt authentication\n- aws s3 for storage\n- ollama for the generative i\n\n## infrastructure\n- aws rds for the database\n- aws s3 for storing files\n- aws lightsail for accommodation\n\nPrerequisites\n\n- python 3.13+\n- node.js 16+\n- postgresql\n- aws account (s3 and rds)\n- ollama (for genia functionality)\n\nFast installation\n\n1. **closing the restitory**\n```bash\ngit clone https://github.com/beytullahsnk/abd-motors.git\ncd abd-motors\n```\n\n2. **installez et lancez le backend**\n```bash\ncd backend\npython -m venv venv\nsource venv/bin/activate  # ou `venv\\scripts\\activate` sous windows\npip install -r requirements.txt\npython manage.py migrate\npython manage.py runserver\n```\n\n3. **installez et lancez le frontend**\n```bash\ncd frontend\nnpm install\nnpm start\n```\n\npour des instructions d'installation détaillées, consultez les readme respectifs du [frontend](frontend/readme.md) et du [backend](backend/readme.md).\n\n## 🌍 environnement de développement\n\n1. configurez les variables d'environnement (voir `.env.example`)\n2. assurez-vous que postgresql est en cours d'exécution\n3. configurez vos credentials aws\n4. installez et démarrez ollama pour la fonctionnalité genia\n\n## 🚀 déploiement\n\nle projet est configuré pour être déployé sur aws lightsail. un script de déploiement automatisé (`deploy.sh`) est fourni et configure:\n- l'environnement python et npm\n- nginx et gunicorn\n- ollama avec le modèle llama2\n- des services systemd pour assurer que tous les composants démarrent automatiquement\n\npour déployer:\n```bash\n# sur votre instance lightsail\ncd abd-motors\nchmod +x deploy.sh\nsudo ./deploy.sh\n```\n\n## 👥 équipe\n\n### groupe 9 - hetic\n\n- **elijah traore** -\n- **abdallah saoud** - \n- **beytullah sonkaya** - \n- **juan manoel ndegue** - \n- **siaka k. doumbia** - \n- **yanis abbar** - \n\n## 📝 licence\n\nce projet est sous licence mit - voir le fichier [license](license) pour plus de détails.\n\n",
    "readme_before": "# 🚗 abd-motors - application de gestion de véhicules\n\napplication web complète pour la gestion de véhicules, incluant la location et la vente, développée pour abd-motors.\n\n## 🌟 vue d'ensemble\n\nabd-motors est une application full-stack permettant de gérer un parc de véhicules et les dossiers associés (location/vente). elle comprend une interface utilisateur moderne et une api rest robuste.\n\n## 🚀 fonctionnalités principales\n\n- gestion complète des véhicules (ajout, modification, suppression)\n- système de location et de vente\n- gestion des dossiers clients\n- interface d'administration\n- authentification et gestion des rôles\n- upload et stockage de documents sur aws s3\n- interface responsive et moderne\n- **genia** : interface d'ia générative pour interroger les documents\n\n## 🧠 genia - interface d'ia pour l'analyse de documents\n\ngenia est une fonctionnalité intégrée permettant aux représentants commerciaux d'interroger des documents pdf (contrats de location, dossiers de vente) en langage naturel.\n\n### fonctionnalités\n- upload de documents pdf (stockés sur aws s3)\n- extraction automatique du texte des documents\n- importation directe depuis le bucket s3\n- interface conversationnelle avec l'ia\n- réponses contextuelles basées sur le contenu des documents\n\n### technologies\n- ollama (modèle llama2) pour le traitement du langage naturel\n- aws s3 pour le stockage des documents\n- pypdf2 pour l'extraction de texte\n- react pour l'interface utilisateur\n\n### utilisation\n1. accédez à la page genia depuis le menu\n2. uploadez un document pdf ou importez-le depuis s3\n3. posez une question en langage naturel concernant le document\n4. recevez une réponse générée par l'ia, basée sur le contenu du document\n\ncet outil permet aux commerciaux de rapidement extraire des informations pertinentes des documents sans avoir à les lire intégralement, améliorant ainsi l'efficacité et la qualité du service client.\n\n## 🏗️ architecture\n\nle projet est divisé en deux parties principales :\n\n- **frontend** : application react avec material-ui\n- **backend** : api rest django avec postgresql\n\n## 📚 documentation détaillée\n\n- [documentation frontend](frontend/readme.md)\n- [documentation backend](backend/readme.md)\n\n## 🛠️ stack technique\n\n### frontend\n- react 18\n- material-ui v5\n- react router v6\n- axios\n- jwt authentication\n\n### backend\n- python 3.13\n- django 4.2.19\n- django rest framework\n- postgresql\n- jwt authentication\n- aws s3 pour le stockage\n- ollama pour l'ia générative\n\n### infrastructure\n- aws rds pour la base de données\n- aws s3 pour le stockage des fichiers\n- aws lightsail pour l'hébergement\n\n## 🚦 prérequis\n\n- python 3.13+\n- node.js 16+\n- postgresql\n- compte aws (s3 et rds)\n- ollama (pour la fonctionnalité genia)\n\n## 🔧 installation rapide\n\n1. **clonez le repository**\n```bash\ngit clone https://github.com/beytullahsnk/abd-motors.git\ncd abd-motors\n```\n\n2. **installez et lancez le backend**\n```bash\ncd backend\npython -m venv venv\nsource venv/bin/activate  # ou `venv\\scripts\\activate` sous windows\npip install -r requirements.txt\npython manage.py migrate\npython manage.py runserver\n```\n\n3. **installez et lancez le frontend**\n```bash\ncd frontend\nnpm install\nnpm start\n```\n\npour des instructions d'installation détaillées, consultez les readme respectifs du [frontend](frontend/readme.md) et du [backend](backend/readme.md).\n\n## 🌍 environnement de développement\n\n1. configurez les variables d'environnement (voir `.env.example`)\n2. assurez-vous que postgresql est en cours d'exécution\n3. configurez vos credentials aws\n4. installez et démarrez ollama pour la fonctionnalité genia\n\n## 🚀 déploiement\n\nle projet est configuré pour être déployé sur aws lightsail. un script de déploiement automatisé (`deploy.sh`) est fourni et configure:\n- l'environnement python et npm\n- nginx et gunicorn\n- ollama avec le modèle llama2\n- des services systemd pour assurer que tous les composants démarrent automatiquement\n\npour déployer:\n```bash\n# sur votre instance lightsail\ncd abd-motors\nchmod +x deploy.sh\nsudo ./deploy.sh\n```\n\n## 👥 équipe\n\n### groupe 9 - hetic\n\n- **elijah traore** -\n- **abdallah saoud** - \n- **beytullah sonkaya** - \n- **juan manoel ndegue** - \n- **siaka k. doumbia** - \n- **yanis abbar** - \n\n## 📝 licence\n\nce projet est sous licence mit - voir le fichier [license](license) pour plus de détails.\n\n"
  },
  {
    "readme": "# dadiu bachelor project\n\nwe do it!\n",
    "readme_before": "# dadiu bachelorprojekt\n\nwe do it!\n"
  },
  {
    "readme": "# blockchain and cloud single sign-on (sso) for worldcoin\n\n## 🌐 project overview\nthis repository contains the source code for a blockchain and cloud-based single sign-on (sso) solution in the example of worldcoin, developed as part of the bachelor work in the study program of business informatics. the aim of this project is to demonstrate the implementation and use of blockchain technologies for authentication and identity management.\n\n## 💻 technology stack\n- **next.js**: a react framework for production-ready applications.\n- **nextauth.js**: a library for easy authentication in next.js applications.\n- **connectkit**: a user-friendly interface for connecting wallets.\n\n##\n### blockchain\nthe blockchain-based implementation uses smart contracts to perform identity checks and authentications. Users can verify their identity by means of a blockchain wallet and biometric data (iris-scan).\n\n### cloud\ncloud implementation uses nextauth.js for authentication via traditional web technologies and supports oauth-based flows to create a bridge between the decentralized and centralized world.",
    "readme_before": "\n# blockchain und cloud single sign-on (sso) für worldcoin\n\n## 🌐 projektübersicht\ndieses repository enthält den quellcode für eine blockchain- und cloud-basierte single sign-on (sso) lösung am beispiel von worldcoin, entwickelt als teil der bachelorarbeit im studiengang wirtschaftsinformatik. das ziel dieses projekts ist es, die implementierung und nutzung von blockchain-technologien zur authentifizierung und identitätsverwaltung zu demonstrieren.\n\n## 💻 technologie-stack\n- **next.js**: ein react-framework für produktionsbereite anwendungen.\n- **nextauth.js**: eine bibliothek für einfache authentifizierung in next.js-anwendungen.\n- **connectkit**: eine benutzerfreundliche schnittstelle für das verbinden von wallets.\n\n## 🔄 funktionsweise\n### blockchain\ndie blockchain-basierte implementierung verwendet smart contracts, um identitätsprüfungen und authentifizierungen durchzuführen. nutzer können ihre identität mittels einer blockchain-wallet und biometrischen daten (iris-scan) verifizieren.\n\n### cloud\ndie cloud-implementierung nutzt nextauth.js für die authentifizierung über traditionelle webtechnologien und unterstützt oauth-basierte flows, um eine brücke zwischen der dezentralisierten und zentralisierten welt zu schaffen."
  },
  {
    "readme": "# php-todo-list\n\n<p>\nphp project carried out during the 2nd year of the university bachelor of technology.\n</p>\n<p>\nwe have made a to-do list in which we can create lists composed of tasks. These lists may be private or public and a task can be validated when carried out.\n</p>\n<img src=\"style/welcome.jpg\">\n\n\n## Techologies used\n\n- php\n- sql(phpmyadmin)\n- html\n- css\n- js\n\n\nInstallation and use\nstart by clone the deposit\nreproduce the database and enter the logs (dsn, login and password) of the database in config/config.php\nWe go through:\n- ***landres.uca.local/phpmyadmin*** for the database\n- ***landres.uca.local/~login/chemindevotredepotcloné*** to see page\n\n## Features\n\n***!! the following actions are available by all! Hey! ***\n- create a public to-do list\n- change the name of a public to-do list\n- display the tasks of a public to-do list\n- delete a public to-do list\n- add a task to a public to-do list\n- change the name of a task and whether or not it is done for a public to-do list\n- register\n- connect\n\n***!! the following actions are only available if you are connected !! * * *\n- create a private to-do list of the connected user\n- change the name of a user's private to-do list\n- show the tasks of a user's private to-do list\n- delete a private to-do list from the connected user\n- add a task to a user's private to-do list\n- change the name of a task and whether or not it is done for a private to-do list of the connected user\n- disconnect\n\n\nEnglish version ----------------------------\n\n<p>\nphp project carried out during the 2nd year of the university bachelor of technology.\n</p>\n<p>\nwe have created a to-do list in which you can create lists made up of tasks. these lists can be private or public and it is possible to validate a task when it is performed.\n</p>\n<img src=\"style/welcome.jpg\">\n\n## technologies used\n\n- php\n- sql(phpmyadmin)\n- html\n- css\n- js\n\n\n## installation and use\n\nstart by clone the restitory\nreproduce the database then enter the logs (dsn, login and password) of it in config/config.php\nat the iut we go through:\n- ***landres.uca.local/phpmyadmin*** to access to the database\n- ***landres.uca.local/~login/chemindevotredepotcloné*** to see the web page\n\n\n## features\n\n***!! the following actions are available to everyone !!! ***\n- create a public to-do list\n- modify the name of a public to-do list\n- display the tasks of a public to-do list\n- delete a public to-do list\n- add a task to a public to-do list\n- change the name of a task and where it is done or not for a public to-do list\n- Sign up\n- sign in\n\n***!! the following actions are only available if you are logged in!***\n- create a private to-do list for the logged in user\n- change the name of a private to-do list of the logged-in user\n- display the tasks of a private to-do list of the logged-in user\n- delete a private to-do list of the logged-in user\n- add a task to a private to-do list of the connected user\n- change the name of a task and where it is done or not for a private to-do list of the logged-in user\n- log out\n",
    "readme_before": "# php-todo-list\n\n<p>\nprojet php réalisé au cours de la 2ème année du bachelor universitaire de technologie. \n</p>\n<p>\nnous avons réalisé une to-do liste dans laquelle on peut creer des listes composées de tâches. ces listes peuvent être privées ou publique et il est possible de valider une tâche lorsque celle-ci est effectuée.  \n</p>\n<img src=\"style/accueil.jpg\">\n\n\n## techologies utilisées  \n\n- php \n- sql(phpmyadmin)\n- html\n- css\n- js\n\n\n## installation et utilisation\ncommencez par cloner le depot  \nreproduire la base de donnée puis rentrer les logs (dsn, login et mot de passe) de celle-ci dans config/config.php\na l'iut nous passons par:\n- ***londres.uca.local/phpmyadmin***  pour la base de donnée  \n- ***londres.uca.local/~login/chemindevotredepotcloné*** pour voir la page\n\n## fonctionnalitées\n\n***!! les actions suivantes sont disponibles par tous !!***\n- créer une to-do list publique\n- modifier le nom d'une to-do list publique\n- afficher les tâches d'une to-do list publique\n- supprimer une to-do list publique\n- ajouter une tâche à une to-do list publique\n- modifier le nom d'une tâche et si elle est réalisée ou non pour une to-do list publique\n- s'inscrire\n- se connecter\n\n***!! les actions suivantes ne sont disponibles seulement si on est connecté !!***\n- créer un to-do list privée de l'utilisateur connecté\n- modifier le nom d'une to-do list privée de l'utilisateur connecté\n- afficher les tâches d'une to-do list privée de l'utilisateur connecté\n- supprimer une to-do list privée de l'utilisateur connecté\n- ajouter une tâche à une to-do list privée de l'utilisateur connecté\n- modifier le nom d'une tâche et si elle est réalisée ou non pour une to-do list privée de l'utilisateur connecté\n- se déconnecter\n\n\n# --------------------------- english version ---------------------------\n\n<p>\nphp project carried out during the 2nd year of the university bachelor of technology.\n</p>\n<p>\nwe have created a to-do list in which you can create lists made up of tasks. these lists can be private or public and it is possible to validate a task when it is performed.\n</p>\n<img src=\"style/accueil.jpg\">\n\n## technologies used\n\n- php\n- sql(phpmyadmin)\n- html\n- css\n- js\n\n\n## installation and use\n\nstart by cloning the repository  \nreproduce the database then enter the logs (dsn, login and password) of it in config/config.php\nat the iut we go through:\n- ***londres.uca.local/phpmyadmin***  to access to the database\n- ***londres.uca.local/~login/chemindevotredepotcloné*** to see the web page\n\n\n## features\n\n***!! the following actions are available to everyone !!!***\n- create a public to-do list\n- modify the name of a public to-do list\n- display the tasks of a public to-do list\n- delete a public to-do list\n- add a task to a public to-do list\n- change the name of a task and whether it is done or not for a public to-do list\n- sign up\n- sign in\n\n***!! the following actions are only available if you are logged in!***\n- create a private to-do list for the logged in user\n- change the name of a private to-do list of the logged-in user\n- display the tasks of a private to-do list of the logged-in user\n- delete a private to-do list of the logged-in user\n- add a task to a private to-do list of the connected user\n- change the name of a task and whether it is done or not for a private to-do list of the logged-in user\n- log out\n"
  },
  {
    "readme": "[![java](https://img.shields.io/badge/java-1.8%2b-lightgrey.svg?style=flat-square)](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n[![eclipse](https://img.shields.io/badge/eclipse-neon-lightgrey.svg?style=flat-square)](http://www.eclipse.org/downloads/eclipse-packages/)\n[![github release](https://img.shields.io/badge/release-v1.0-blue.svg?style=flat-square)](https://github.com/stummk/psp-eclipse/releases)\n[![license](https://img.shields.io/badge/license-mit-blue.svg?style=flat-square)](https://github.com/stummk/psp-eclipse/blob/master/license)\n\n\n# psp-eclipse\n[english](#description) | [english](#description)\n\nDescription\n\nthis project was created in the beige of a bachelor work. it provides an implementation of an eclipse plugin to integrate the personal software process. the personal software process (psp) was developed by watts s. humphrey and aims to help software developers optimize their own development process. psp is based on historical data whose collection is quite complex. this plugin automates the data collection to part and thus allows easier data collection.\n\nthe plugin supports the programming language java. for further programming languages, the complete range of functions cannot be guaranteed. the following functionalities are offered:\n\n#### backup and data synchronization\nthe recorded data can be synchronized with different versions or with other devices when using a version management. for this purpose, the recorded data can be stored manually in the psp.csv file. this can be used to synchronize the data.\n\n♪\ntasks represent tasks in a software project. in the case of creating a task, estimated values can be specified here. estimate the time, the inserted and removed defective, as well as the number of written code lines when performing the task.\n\n#### time recording\nthe plugin offers automated time recording. the time recording is started when a task is executed.\n\n#### defect detection\ndefects can be added manually in this plugin. Defects can be added to either a single file, an ordner or an entire project.\n\n#### count the code lines\nthe number of written code lines are counted automatically in this plugin when a executed task is stopped.\n\ntest report\nthe test report represents the executed unit tests in a software project. this is generated automatically when unit tests are executed. for time only java-unit tests are supported.\n\n#### earned value tracking\nthe plugin allows automated detection of the project progress. the number of points is calculated when creating a task and credited when completing the task.\n\n#### schedule energization\nthe schedule, which represents a week overview in a software project, is generated completely automatically.\n\n#### calculations for project plan summary\nthe project plan summary represents a complete overview of a project. it is generated automatically and all calculations are executed automatically.\n\n\n#### more information\nthe [user manual](https://github.com/stummk/psp-eclipse/wiki/user manual) describes a closer use of the plugin.\n\na built version can be found in the folder [binary](./binary). more information for installation and midnest requirements can be taken [here](./binary/readme.md).\n\nthe source code can be found in the folder [source](./source). how to use it can be taken from [readme](./source/readme.md).\n\n---\n\n♪\n\nthis project is part of a bachelor thesis. it provides an implementation of an eclipse-plugin to integrate the personal software process. the personal software process (psp) was developed by watts s. humphrey and is intended to help software developers to optimize their own development process. psp is based on historical data, the capturing of which is quite complex. this plugin partly automates the data capturing and thus enabling simple data acquisition.\n\nthe plugin supports the programming language java. the complete functional range can not be guaranteed for other programming languages. the following functionalities are offered:\n\n#### backup and data trigger\nthe captured data can be synchronized with different devices. for this, the captured data can be stored manually in the psp.csv file. this can be used to synchronize the data.\n\n♪\ntasks represent tasks in a software project. when creating a task, you can specify estimated values for this task. estimation of the donation time, inserted and removed defects, as well as the number of written code lines when the task is executed.\n\n♪ time recording\nthe plugin provides an automated time recording. the time recording is started when a task is executed.\n\n#### defect detection\ndefects can be added manually in this plug-in. defects can be added to either a single file, a folder, or an entire project.\n\n#### counting code lines\nthe number of written code lines is automatically counted in this plugin when a running task is stopped.\n\ntest report\nthe test report represents the alignment unit tests in a software project. this is generated automatically when unit tests are currently run., only java unit tests are supported.\n\n#### earned value tracking\nthe plug-in request the automated recording of project progress. the score is calculated when a task is created and credited when the task is completed.\n\n#### schedule generation\nthe schedule plan, which is a weekly overview a software project, is generated completely automatically.\n\n#### calculations for project plan summary\nthe project plan summary provides a general of a project. it is automatic generated and all calculations are automatic.\n\n#### further information\nthe [user manual](https://github.com/stummk/psp-eclipse/wiki/user-manual) visa a closer use of the plugin.\n\na built version can be found in the folder [binary](./binary). more detailed information on installation and mid-term requirements can be found [here](./binary/readme.md).\n\nsourcecode can be found in the folder [source](./source). how to use this can be found in the [readme](./source/readme.md).\n",
    "readme_before": "[![java](https://img.shields.io/badge/java-1.8%2b-lightgrey.svg?style=flat-square)](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n[![eclipse](https://img.shields.io/badge/eclipse-neon-lightgrey.svg?style=flat-square)](http://www.eclipse.org/downloads/eclipse-packages/)\n[![github release](https://img.shields.io/badge/release-v1.0-blue.svg?style=flat-square)](https://github.com/stummk/psp-eclipse/releases)\n[![license](https://img.shields.io/badge/license-mit-blue.svg?style=flat-square)](https://github.com/stummk/psp-eclipse/blob/master/license)\n\n\n# psp-eclipse\n[deutsch](#beschreibung) | [english](#description)\n\n## beschreibung\n\ndieses projekt ist im zuge einer bachelorarbeit entstanden. es liefert eine implementierung eines eclipse-plugins zur integration des persönlichen softwareprozesses. der persönliche softwareprozess (psp) wurde von watts s. humphrey entwickelt und soll softwareentwicklern dabei helfen den eigenen entwicklungsprozess zu optimieren. psp basiert auf historischen daten, deren erhebung ziemlich aufwendig ist. dieses plugin automatisiert die datenerhebung zum teil und ermöglicht somit eine einfachere erfassung der daten.\n\ndas plugin unterstützt die programmiersprache java. für weitere programmiersprachen kann der komplette funktionsumfang nicht garantiert werden. es werden folgende funktionalitäten angeboten:\n\n#### backup und datensynchronisation\ndie erfassten daten können bei der verwendung einer versionsverwaltung mit verschiedenen versionen oder auch mit anderen geräten synchronisert werden. dafür können die erfassten daten manuell in die psp.csv datei gespeichert werden. diese kann zum synchronisieren der daten benutzt werden.\n\n#### tasks\ntasks stellen aufgaben in einem softwareprojekt dar. beim anlegen einer task können hier schätzwerte zu dieser angegeben werden. schätzungen zur zeit, der eingefügten und entfernten defekte, sowie anzahl der geschriebenen codezeilen beim ausführen der task.\n\n#### zeiterfassung\ndas plugin bietet eine automatisierte zeiterfassung an. die zeiterfassung wird gestartet, wenn eine task ausgeführt wird.\n\n#### defekterfassung\ndefekte können in diesem plugin manuell hinzugefügt werden. defekte können entweder einer einzelnen datei, einem ordner oder einem ganzen projekt hinzugefügt werden.\n\n#### zählen der codezeilen\ndie anzahl der geschriebenen codezeilen werden in diesem plugin automatisch gezählt, wenn eine ausgeführte task gestoppt wird.\n\n#### test report\nder test-report stellt die ausgeführten unit-tests in einem softwareprojekt dar. dieser wird automatisch generiert, wenn unit-tests ausgeführt werden. zur zeit werden nur java-unit tests unterstützt.\n\n#### earned value tracking\ndas plugin ermöglicht die automatisierte erfassung des projektfortschrittes. die punktzahl wird beim erstellen einer task berechnet und beim abschließen der task gutgeschrieben.\n\n#### schedule plan generierung\nder schedule plan, der eine wochenübersicht in einem softwareprojekt darstellt, wird komplett automatisch generiert.\n\n#### berechnungen für project plan summary\ndie project plan summary stellt eine gesamtübersicht über ein projekt dar. es wird automatisch generiert und alle berechnungen werden automatisch ausgeführt.\n\n\n#### weitere informationen\ndas [benutzerhandbuch](https://github.com/stummk/psp-eclipse/wiki/benutzerhandbuch) beschreibt eine nähere benutzung des plugins.\n\neine gebaute version kann in dem ordner [binary](./binary) gefunden werden. nähere informationen zur installation und midnestanforderungen können [hier](./binary/readme.md) entnommen werden. \n\nder quellcode kann in dem ordner [source](./source) gefunden werden. wie dieser zu benutzen ist, kann aus der [readme](./source/readme.md) entnommen werden.\n\n---\n\n## description\n\nthis project is part of a bachelor thesis. it provides an implementation of an eclipse-plugin to integrate the personal software process. the personal software process (psp) was developed by watts s. humphrey and is intended to help software developers to optimize their own development process. psp is based on historical data, the capturing of which is quite complex. this plugin partly automates the data capturing and thus enabling simple data acquisition.\n\nthe plugin supports the programming language java. the complete functional range can not be guaranteed for other programming languages. the following functionalities are offered:\n\n#### backup and data synchronization\nthe captured data can be synchronized with different devices. for this, the captured data can be stored manually in the psp.csv file. this can be used to synchronize the data.\n\n#### tasks\ntasks represent tasks in a software project. when creating a task, you can specify estimated values for this task. estimation of the spend time, inserted and removed defects, as well as the number of written code lines when the task is executed.\n\n#### time recording\nthe plugin provides an automated time recording. the time recording is started when a task is executed.\n\n#### defect detection\ndefects can be added manually in this plug-in. defects can be added to either a single file, a folder, or an entire project.\n\n#### counting code lines\nthe number of written code lines is automatically counted in this plugin when a running task is stopped.\n\n#### test report\nthe test report represents the executed unit tests in a software project. this is generated automatically when unit tests are run. currently, only java unit tests are supported.\n\n#### earned value tracking\nthe plug-in enables the automated recording of project progress. the score is calculated when a task is created and credited when the task is completed.\n\n#### schedule plan generation\nthe schedule plan, which is a weekly overview in a software project, is generated completely automatically.\n\n#### calculations for project plan summary\nthe project plan summary provides a general overview of a project. it is automatically generated and all calculations are executed automatically.\n\n#### further information\nthe [user manual](https://github.com/stummk/psp-eclipse/wiki/user-manual) describes a closer use of the plugin.\n\na built version can be found in the folder [binary](./binary). more detailed information on installation and mid-term requirements can be found [here](./binary/readme.md).\n\nsourcecode can be found in the folder [source](./source). how to use this can be found in the [readme](./source/readme.md).\n"
  },
  {
    "readme": "# gitsnake\n\n- own implementation of known game Snake.\n- the project serves as an example of work in the git system.",
    "readme_before": "# gitsnake\n\n- vlastní implementace známé hry snake.\n- projekt slouží jako ukázka práce v systému git."
  },
  {
    "readme": "# credit-union\n< p >\nThis is a final task project that I created using php (native) programming (native) language, in which this application was created to make officers and operatives easy by creating online payment systems and also\nA reminder of installments. This system also aims to replace the manual system, which is to log all the data in the book into a system that\nAll the data is stored in the database and accessible anywhere.\n< / p >\n\n# features\n< p >\nOn this application there are some features in between:\n< / p >\n< ol >\n< li > midtrans payments < / li >\n< li > text & wa gateway < / li >\n< / ol >\n\n# login page\n< p >\n< img width = \"500\" src = \"https: / / githumbu.com / fauzanamad11 / credit -union / main / assets / img / ui / login.jpg\" / >\n< / p >\n< p >\nin login page also exists a menu to register as new admin. In this section that can register is a new admin that's already registered to operatives\n< / p >\n\n# dashboard admin\n< p >\n< img width = \"500\" src = \"https: / / gitphu.com / fauzanahmad11 / creidi -union / main / assets / img / ui / dashboard.jpg\" / >\n< / p >\n< p >\nIn this section there are 2 cards containing data members who have a mortgage on them and members who have deposits ready to melt. in this section there\nbutton sends a function message to send a reminder message to pay and cash.\n< / p >\n\n# dashboard cooperative member\n< p >\n< img width = \"500\" src = \"https: / / gitphu.com / fauzanahmad11 / credit -union / main / assets / img / ui / client-dashboard.jpg\" / >\n< / p >\n< p >\nIn this section are card@-@ card related to the kind of cooperative programs that operatives have. and in the cash card it can be clicked to pay installments (if any)\n< / p >\n\n# halama checkout\n< p >\n< img width = \"500\" src = \"https: / / githumbu.com / fauzanamad11 / credit -union / main / assets / img / ui / checkout.jpg\" / >\n< / p >\n< p >\nOn this section is a page for making payments, at this part a cooperative member can make online payments using midtrans with qris gopay\n< / p >\n\n# halama payback\n< p >\n< img width = \"500\" src = \"https: / / gitphu.com / fauzanahmad11 / creudiama -union / main / assets / img / ui / payment.jpg\" / >\n< / p >\n< p >\nOn this page the operatives only scan qr codes to make transactions. and when successfully making payments then the system is automatically directed to the success transmission page.\nand directively a transaction message will enter whatsapp operatives\n< / p >\n\n# message reminder (reminder)\n< p >\nHere is a reminder of the loan installment message\n< / p >\n< p >\n< img width = \"200\" src = \"https: / / gitphu.com / fauzanahmad11 / credit -union / main / assets / img / ui / retingu.jpg\" / >\n< / p >\n\n# Follow me\n< p align = \"center\" >\nfollow me on social media\n< / p >\n< p align = \"center\" >\n< a href = \"https: / / instagram.com / _ fauzanahmad _\" style = \"margin-right:\" 30px; \"> < img width =\" 78 \"src =\" https: / / cdn-icons-pn.pn.flaticon.com / 128 / 211111 / 2146png \"alt\"\n< a href = \"https: / / githu.com / fauzanahmad11\" style = \"margin-left: 30px;\" > < img width = \"7g\" src = \"https: / / cdn-icons-pn.fn.flaticon.com / 128 / 73535png\" alt = \"github\" >\n< / p >\n",
    "readme_before": "# credit-union\n<p>\n  ini adalah projek tugas akhir yang saya buat menggunakan bahasa programming php (native), pada aplikasi ini dibuat dengan tujuan mempermudah petugas dan anggota koperasi dengan membuat sistem pembayaran online dan juga\n  pengingat pembayaran angsuran. sistem ini juga bertujuan untuk menggantikan sistem manual yaitu pencatatan seluruh data didalam buku menjadi sistem yang\n  seluruh datanya tersimpan di database dan dapat diakses darimana saja\n</p>\n\n# fitur\n<p>\n  pada aplikasi ini terdapat beberapa fitur diantaranya :\n</p>\n<ol>\n  <li>midtrans payments</li>\n  <li>sms & wa gateway</li>\n</ol>\n\n# login page\n<p>\n  <img width=\"500\" src=\"https://github.com/fauzanahmad11/credit-union/blob/main/assets/img/ui/login.jpg\"/>\n</p>\n<p>\n  pada login page juga terdapat menu untuk mendaftar sebagai admin baru. pada bagian ini yang dapat mendaftar adalah admin baru yang telah terdaftar pada koperasi\n</p>\n\n# dashboard admin\n<p>\n  <img width=\"500\" src=\"https://github.com/fauzanahmad11/credit-union/blob/main/assets/img/ui/dashboard.jpg\"/>\n</p>\n<p>\n  pada bagian ini terdapat 2 card yang berisikan data anggota yang memiliki tanggungan membayar angsuran dan anggota yang memiliki deposit yang siap dicairkan. pada bagian ini terdapat\n  button kirim pesan yang berfungsi untuk mengirimkan pesan pengingat untuk membayar dan mencairkan dana. \n</p>\n\n# dashboard anggota koperasi\n<p>\n  <img width=\"500\" src=\"https://github.com/fauzanahmad11/credit-union/blob/main/assets/img/ui/client-dashboard.jpg\"/>\n</p>\n<p>\n  pada bagian ini terdapat card-card terkait jenis program koperasi yang dimiliki anggota koperasi. dan pada card angsuran dapat diklik untuk membayar angsuran (jika ada)\n</p>\n\n# halama checkout\n<p>\n  <img width=\"500\" src=\"https://github.com/fauzanahmad11/credit-union/blob/main/assets/img/ui/checkout.jpg\"/>\n</p>\n<p>\n  pada bagian ini adalah halaman untuk melakukan pembayaran, pada bagian ini anggota koperasi dapat melakukan pembayaran online menggunakan midtrans dengan qris gopay\n</p>\n\n# halama payment\n<p>\n  <img width=\"500\" src=\"https://github.com/fauzanahmad11/credit-union/blob/main/assets/img/ui/payment.jpg\"/>\n</p>\n<p>\n  pada halaman ini anggota koperasi hanya melakukan scan qr code untuk melakukan transaksi. dan ketika berhasil melakukan pembayaran maka sistem secara automatis direct ke halaman success transaction.\n  dan secara direct pesan transaksi akan masuk whatsapp anggota koperasi\n</p>\n\n# pesan reminder (pengingat)\n<p>\n  berikut adalah pesan pengingat angsuran pinjaman\n</p>\n<p>\n  <img width=\"200\" src=\"https://github.com/fauzanahmad11/credit-union/blob/main/assets/img/ui/reminder.jpg\"/>\n</p>\n\n# follow me\n<p align=\"center\">  \n  follow me on social media\n</p>\n<p align=\"center\">\n<a href=\"https://instagram.com/_fauzanahmad_\" style=\"margin-right:30px;\"><img width=\"70\" src=\"https://cdn-icons-png.flaticon.com/128/2111/2111463.png\" alt=\"instagram\"></a>\n<a href=\"https://github.com/fauzanahmad11\"  style=\"margin-left:30px;\"><img width=\"70\" src=\"https://cdn-icons-png.flaticon.com/128/733/733553.png\" alt=\"github\"></a>\n</p>\n"
  },
  {
    "readme": "mini project 2\n-\n\n\nFrench theron and sidonie buttout\n\nrolling of a part\n\ninteractive menu:\n-\n- play the character with the right and left arrows,\nto play the team of your choice \"mount\" in the tank by stopping for a second on the tank. this step can be skip using the n key, you will be assigned the team ally automatically.\n- thanks to the space key the character can take a bike and move faster! fantastic, right?\n\nGame:\n-\n- each player has 4 units of different types (tank, soldier, rocket, ambulance).\n\nAllied players can:\n-\n- move the cursor with the arrows.\n- select a unit by entering.\n- then choose an end position in the range (with the help of arrows) and press enter again.\n- select an action from the proposed one\naction desired: no effect\naction attack (all units): select an enemie unit using arrows and press enter\naction heal (ambulance only): select an allied unit with the help of arrows and press enter.\n- the units used are shaded (each can be used once per turn).\n- the player can finish his turn with the tab key.\n\ngame mechanics:\n-\n- putting your units on certain components of the game will allow you to win defense but also win the game! Use your cursor to see which spots bring the most defense.\n\nia:\n-\n- the enemy player plays automatically by bringing each of his units as close as possible to an opponent and then attacking him (note: the ambulance heals instead).\n\nGame system:\n-\n- the tricks go on until a player has no unity. the area then changes for a second part. at the end of the game, the game ends and displays game over.\n\nkeys for the curious:\n-\n- tab can be used to finish the current player's turn at any time.\n- n allows you to start the next part (only works on the menu and the first area, since then there is no next part).\n- r allows to reset the game and therefore restart the first part.\n\nSpecific features of extensions:\n-\n- the rocket has the peculiarity of little to move (ray of 1) but to be able to shoot away and strong (ray of attack of 5, damage of 8).\n- the ambulance helps to heal its allies (healing of 3), but can only attack weakly (damage of 1).\n- at the beginning of the game the player looks away, enjoy as once moved he will no longer look at the landscape. :)\nDon't forget to make him win so he comes back to admire the landscape more often.\n\n\n\n",
    "readme_before": "mini projet 2\n-\n\n\nfrançois theron et sidonie bouthors\n\nderoulement d'une partie\n\nmenu interactif :\n-\n- jouer le personnage a l'aide des flèches droite et gauche,\npour jouer l'équipe de votre choix \"montez\" dans le tank en vous arretant une seconde sur le tank. cette étape peut etre skip au moyen de la touche n, vous vous verrez attribué l'equipe allié automatiquement.\n- grâce à la touche espace le personnage peut prendre un vélo et avancer plus rapidement ! fantastique pas vrai ?\n\njeu:\n-\n- chaque joueur a 4 unités de types différent (tank, soldier, rocket, ambulance).\n\nles joueur allié peut :\n-\n- déplacer son curseur au moyen des flèches.\n- selectionner une unité au moyen de enter.\n- choisir alors une position d'arrivée dans le range (a l'aide des flèches) et appuyer de nouveau sur enter.\n- selectionner une action parmis celle proposée\naction wait: aucun effet\naction attack (tous units): selectionner une unité enemie a l'aide des flèches et appuyer sur enter\naction heal (uniquement ambulance): selectionner une unité alliée a l'aide des flèches et appuyer sur enter.\n- les units utilisés sont grisés (chacun peut être utilisé une fois par tour).\n- le joueur peut finir son tour à l'aide de la touche tab.\n\nmécanique du jeu :\n-\n- mettre vos unités sur certain des composants du jeu vous permettra de gagner en defense mais aussi de gagner la partie ! utilisez votre curseur pour voir quelles sont les spots qui apportent le plus de défense.\n\nia :\n-\n- le joueur ennemi joue automatiquement en rapprochant chacune de ses unité le plus possible d'un adversaire puis en l'attaquant (note: l'ambulance soigne à la place).\n\nsystème de jeu :\n-\n- les tours s'enchaînent jusqu'a ce qu'un joueur n'aie plus d'unité. l'aire change alors pour une deuxième partie. a l'issue de celle-ci, le jeu se termine et affiche game over.\n\ntouches pour les curieux :\n-\n- tab peut être utilisé pour finir le tour du joueur actuel a n'importe quel moment.\n- n permet de démarrer la partie suivante (ne marche que sur le menu et la première aire, puisque ensuite il n'y a plus de partie suivante).\n- r permet de reset le jeu et donc de redémarrer à la première partie.\n\nspécificités particulières des extensions :\n-\n- la rocket a la particularité de peu se déplacer (rayon de 1) mais pouvoir tirer loin et fort (rayon d'attaque de 5, damage de 8).\n- l'ambulance permet de soigner ses alliés (healing de 3), mais ne peut attaquer que faiblement (damage de 1).\n- au début de la partie le joueur regarde au loin, profitez en car une fois bougé il ne regardera plus le paysage. :)\n  n'oubliez pas de le faire gagner pour qu'il revienne admirer le paysage plus souvent.\n\n\n\n"
  },
  {
    "readme": "# bachelor-project: networking during infectious diseases model (nidm) simulator in julia\n_ Based on the model written in java by hendrik nunner: https://github.com/hnunner/nidm-simulation_\n\n## how to start the simulation?\n1. model.jl (im ordner nidm\\lib) run\n2. with 'shift' and ';' in the shell: cd nidm\n3. with 'backspace' back to julia\n4. Run routes.jl (in ordner nidm)\n\n## group members\n* katinka feltes\n* pius good\n♪ helen kuswik\n* erik luda",
    "readme_before": "# bachelor-project: networking during infectious diseases model (nidm) simulator in julia\n_basierend auf dem in in java geschriebenen modell von hendrik nunner: https://github.com/hnunner/nidm-simulation_\n\n## wie startet man die simulation?\n1. model.jl (im ordner nidm\\lib) ausführen\n2. mit 'shift' und ';' in die shell: cd nidm \n3. mit 'backspace' zurück zu julia\n4. routes.jl (im ordner nidm) ausführen\n\n## gruppenmitglieder\n* katinka feltes\n* pius gutsche\n* helen kuswik\n* erik luda"
  },
  {
    "readme": "application of methods for generating three-dimensional regular grids to account for the curvilinear anisotropy of the material\n####**The essence of work**\nvisualization of dynamic deformation of composite material with specified strength properties\n####**The purpose of the job**\ncalculation, construction and correct visualization of *** surfaces of kunsa*** (2d case), as well as the extension of the two-dimensional representation to the three-dimensional case, i.e. the composite itself.\n#### **annotation and visual results**\n\nThe file `coonslinearsurface_2d.js` presents the construction of the surface of the kunsa, 4 boundaries of which are given by natural cubic splines, in several ways:\nalgebraic method consisting in transfinite interpolation of boundary curves,\nparametric coordinates can be given in three different ways: uniform, chord and centripetal;\n- differential method based on the method of solving a two-dimensional quasi-static problem mdt from the MS course using a mechanical analogy,\nand solving the obtained equations through finite-difference schemes.\n\n* undeformed grid in (x,y)*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194700379-810d2b72-3e9a-4aae-9c80-e3f25a790701.png\">\n</p>\n\n*undeformed mesh (counce surface) in (x,y,z)*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194701517-a2321ac8-6d74-405a-9fd7-ac135517a549.png\">\n</p>\n\n*laying nets on the deformed surface of the kunsa in (x,y,z) at ν=0.4*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194701597-8f563900-53bc-49a7-a424-4379d6d8b0ae.png\">\n</p>\n\nDeformed mesh (coon surface) in (x,y,z)*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194701705-1a14fa6b-1e70-4ae5-9d91-26ced445dea8.png\">\n</p>\n\nThe file `coonslinearsurface_3d.js` reflects the results of extending these methods to a three-dimensional case.\n\n* undeformed grid of a unit cube in (x,y,z)*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702742-44377cc9-a7c4-4be6-be98-c47896d1e2b1.png\">\n</p>\n\nDeformed grid in (x,y,z) at ν=0.4*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702761-68b38f0a-c102-4a9f-aca8-93cb707d98ea.png>\n</p>\n\n*Differences in the location of the nodal points of two different cube grids with equally deformed boundaries at ν=0.4*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702774-757392b6-e1a5-45ec-b890-6f7eb2172c2b.png>\n</p>\n\n*Differences of coordinate lines of two different cube grids with equally deformed boundaries at ν=0.4*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702791-51b74daf-9cf6-4aea-b0e9-081b8ec96634.png>\n</p>\n\nDeformed mesh (transfinite interpolation) in (x,y,z)*\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702806-d09d181b-30e4-4806-bc98-1aa376be4fd0.png>\n</p>\n\nDeformed grid (mechanical analogy) in (x,y,z)\n\n<p align=\"center\">\n<img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702816-607775b3-6d52-434e-b454-40e509f43d69.png\">\n</p>\n\n####\n1. in both \".html\" files, it is possible to selectively display the elements under construction, such as control points, control lines, node points of the grid,\ngrid lines, surfaces, and the result of the work is their visual comparison.\n\n2. the rotation animation is made using quaternions, not css tools.\n\n###\n- the method of generating a grid on the surface of the kunsa is programmed (algebraic method of transfinite interpolation on a single square);\n- developed and programmed a method of generating a grid in a two-dimensional case (differential method based on a mechanical analogy on a single square);\nThe method of transfinite interpolation is extended to a three-dimensional case (single cube);\nThe method of mechanical analogy is extended to a three-dimensional case (single cube);\n- each case and method is visualized separately in one figure to compare the results of the grid construction;\n- the possibility of dynamic change of the poisson coefficient is added to compare the results of grid construction.\n",
    "readme_before": "## применение методов генерации трехерных регулярных сеток для учета криволинейной анизотропии материала\n#### **суть работы**\nвизуализация динамической деформации композитного материала с заданными прочностными свойствами  \n#### **цель работы**\nрасчет, построение и корректная визуализация ***поверхностей кунса*** (2d случай), а также расширение двумерного представления на трехмерный случай, т.е. сам композит.\n#### **аннотация и визуальные результаты**\n\nв файле `coonslinearsurface_2d.js` представлено построение поверхности кунса, 4 границы которой заданы естественными кубическими сплайнами, несколькими способами:\n- алгебраическим методом, заключающимся в трансфинитной интерполяции граничных кривых,\n  при этом параметрические координаты могут быть заданы тремя разными способами: uniform, хордовым и центростремительным;\n- дифференциальным методом, основывающимся на методе решения двумерной квазистатической задачи мдтт из курса мсс с помощью механической аналогии,\n  и решении полученных уравнений через конечно-разностные схемы.\n\n*недеформированная сетка в (x,y)*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194700379-810d2b72-3e9a-4aae-9c80-e3f25a790701.png\">\n</p>  \n\n*недеформированная сетка (поверхность кунса) в (x,y,z)*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194701517-a2321ac8-6d74-405a-9fd7-ac135517a549.png\">\n</p>  \n\n*наложение сеток на деформированной поверхности кунса в (x,y,z) при ν=0.4*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194701597-8f563900-53bc-49a7-a424-4379d6d8b0ae.png\">\n</p>  \n\n*деформированная сетка (поверхность кунса) в (x,y,z)*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194701705-1a14fa6b-1e70-4ae5-9d91-26ced445dea8.png\">\n</p> \n\nфайл `coonslinearsurface_3d.js` отражает результаты расширения указанных методов на трехмерный случай.\n \n*недеформированная сетка единичного куба в (x,y,z)*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702742-44377cc9-a7c4-4be6-be98-c47896d1e2b1.png\">\n</p> \n\n*деформированная сетка в (x,y,z) при ν=0.4*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702761-68b38f0a-c102-4a9f-aca8-93cb707d98ea.png\">\n</p> \n\n*различия в местоположении узловых точек двух различных сеток куба с одинаково деформированными границами при ν=0.4*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702774-757392b6-e1a5-45ec-b890-6f7eb2172c2b.png\">\n</p> \n\n*различия координатных линий двух различных сеток куба с одинаково деформированными границами при ν=0.4* \n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702791-51b74daf-9cf6-4aea-b0e9-081b8ec96634.png\">\n</p> \n\n*деформированная сетка (трансфинитная интерполяция) в (x,y,z)*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702806-d09d181b-30e4-4806-bc98-1aa376be4fd0.png\">\n</p> \n\n*деформированная сетка (механическая аналогия) в (x,y,z)*\n\n<p align=\"center\">\n  <img width=\"460\" height=\"350\" src=\"https://user-images.githubusercontent.com/108822342/194702816-607775b3-6d52-434e-b454-40e509f43d69.png\">\n</p> \n\n#### особенности\n1. в обоих `.html` файлах есть возможность выборочного отображения строящихся элементов, таких как контрольные точки, контрольные линии, узловые точки сетки, \nсеточные линии сетки, поверхности, причем итогом работы является их визуальное сравнение.\n\n2. анимация поворотов выполнена с применением кватернионов, а не инструментов css.\n\n### итог\n-\tзапрограммирован метод генерации сетки на поверхности кунса (алгебраический метод трансфинитной интерполяции на единичном квадрате);\n-\tразработан и запрограммирован метод генерации сетки в двумерном случае (дифференциальный метод на основе механической аналогии на единичном квадрате);\n-\tметод трансфинитной интерполяции расширен до трехмерного случая (единичный куб);\n-\tметод механической аналогии расширен до трехмерного случая (единичный куб);\n-\tкаждый случай и метод визуализирован отдельно на одной фигуре для возможности сравнения результатов построения сетки;\n-\tдобавлена возможность динамического изменения коэффициента пуассона для сравнения результатов построения сетки.\n"
  },
  {
    "readme": "#svdfaces\n# custom svd is in main.ipynb\n# presentation [here](https://github.com/zhekuson/svdfaces/blob/main/svd%) 20for%20face%20recognition.pptx\n",
    "readme_before": "# svdfaces\n# custom svd лежит в main.ipynb\n# презентация [здесь](https://github.com/zhekuson/svdfaces/blob/main/svd%20for%20face%20recognition.pptx)\n"
  },
  {
    "readme": "# metadata image files and steganography\n\nIntroduction\nThis project was carried out by damodarane jean-baptist and elumalai sriguru, students in computer 2 degree within group c. it is based on the concept of steganography, a technique aimed at concealing information, such as messages, within digital media, mainly image files.\n\n\n\n**java version**\n\nfor this project, we selected with the version `javase-11`\n\n## use and execution in click mode\n\nThis project can be run in click mode on the console using a jar file.\nOpen your linux console.\nthe file name is: `mycli.jar`\nIn click mode, the user can:\n\n1. explore a folder, whose name will be passed into argument or the user will have to put a '.'\ncommand to type:\n```\njava -jar mycli.jar -d .\n```\nou \n\n```\njava -jar mycli.jar -d images\n```\n\n2. afficher les métadonnées d'un fichier image dont le nom sera passé en argument\ncommande à taper : \n```\njava -jar mycli.jar nom_image.png\n```\n\n3. cacher un message/texte dans une image, le message et le nom de l'image seront passés en argument\ncommande à taper : \n```\njava -jar mycli.jar -f nom_image.png -s \"message_secret\"\n```\n\n4. extraire le message dissimulé dans l'image, le nom de l'image contenant le message caché sera passé en argument\ncommande à taper : \n```\njava -jar mycli.jar -f nom_image_encode.png -e\"\n```\n\n5. pour avoir des aides\ncommande à taper : \n```\njava -jar mycli.jar -h` ou `java -jar mycli.jar --help\n```\n\n\n## utilisation et exécutions en mode gui\n\nce projet peut être exécuté en mode gui à l'aide d'un fichier jar.\nle ficher se nomme : `mygui.jar`\n\npour lancer la fenêtre, veuillez taper la commande : \n```\njava -jar mygui.jar\n```\n\n1. pour explorer un dossier, l'utilisateur doit se placer dans l'onlget \"lister un repertoire\", puis cliquer sur le boutton \"choisissez un dossier' (pour choisir un dossier) et ensuite cliquer sur analyser\n![image](https://user-images.githubusercontent.com/91695685/147091029-71debde3-2ab0-41b1-8603-93771f3d145f.png)\n\n\n2. pour afficher les metadonnees d'une image, l'utilisateur doit se placer dans l'onglet \"metadonnees\", puis choisir un fichier image et ensuite examiner\n![image](https://user-images.githubusercontent.com/91695685/147091137-e863be34-0429-47b1-a493-a2a8c9c1ae1d.png)\n\n\n3. pour encoder une image, l'utilisateur doit se placer dans l'onglet correspondant, puis choisir une image et taper nom de la nouvelle image qui va contenir le message. ensuite taper le message secret et enfin appuyer sur le bouton cacher\n![image](https://user-images.githubusercontent.com/91695685/147091253-4dca57d7-ab67-419a-8505-cd80b53321b8.png)\n\n\n4. pour decoder l'image, l'utilisateur doit se placer dans l'onglet correspondant, choisir le fichier image qui contient le message secret et appuyer sur le bouton decoder\n![image](https://user-images.githubusercontent.com/91695685/147091328-41b617f3-78cd-4169-9708-a0314f231803.png)\n\n# contribution\npour toute contribution ou réutilisation de ce projet, veuillez mentionner les noms des développeurs de ce projet : [damodarane jean-baptiste](https://github.com/jeanbaptiste02) et [elumalai sriguru](https://github.com/sriguru95). pour collaborer, veuillez les contacter pour obtenir leur consentement formel.\n",
    "readme_before": "# metadonnees des fichiers images et steganographie\n\n## introduction\nce projet a été réalisé par damodarane jean-baptiste et elumalai sriguru, étudiants en licence 2 informatique au sein du groupe c. il s'articule autour du concept de stéganographie, une technique visant à dissimuler des informations, telles que des messages, au sein de supports numériques, principalement des fichiers image.\n\n\n\n**la version java**\n\npour ce projet, nous choisi avec la version `javase-11`\n\n## utilisation et exécutions en mode cli\n\nce projet peut être exécuté en mode cli sur la console à l'aide d'un fichier jar.\nouvrir votre console linux.\nle ficher se nomme : `mycli.jar`\nen mode cli, l'utilisateur peut :\n\n1. explorer un dossier, dont le nom sera passé en argument ou l'utilisateur devra mettre un '.'\ncommande à taper : \n```\njava -jar mycli.jar -d .\n```\nou \n\n```\njava -jar mycli.jar -d images\n```\n\n2. afficher les métadonnées d'un fichier image dont le nom sera passé en argument\ncommande à taper : \n```\njava -jar mycli.jar nom_image.png\n```\n\n3. cacher un message/texte dans une image, le message et le nom de l'image seront passés en argument\ncommande à taper : \n```\njava -jar mycli.jar -f nom_image.png -s \"message_secret\"\n```\n\n4. extraire le message dissimulé dans l'image, le nom de l'image contenant le message caché sera passé en argument\ncommande à taper : \n```\njava -jar mycli.jar -f nom_image_encode.png -e\"\n```\n\n5. pour avoir des aides\ncommande à taper : \n```\njava -jar mycli.jar -h` ou `java -jar mycli.jar --help\n```\n\n\n## utilisation et exécutions en mode gui\n\nce projet peut être exécuté en mode gui à l'aide d'un fichier jar.\nle ficher se nomme : `mygui.jar`\n\npour lancer la fenêtre, veuillez taper la commande : \n```\njava -jar mygui.jar\n```\n\n1. pour explorer un dossier, l'utilisateur doit se placer dans l'onlget \"lister un repertoire\", puis cliquer sur le boutton \"choisissez un dossier' (pour choisir un dossier) et ensuite cliquer sur analyser\n![image](https://user-images.githubusercontent.com/91695685/147091029-71debde3-2ab0-41b1-8603-93771f3d145f.png)\n\n\n2. pour afficher les metadonnees d'une image, l'utilisateur doit se placer dans l'onglet \"metadonnees\", puis choisir un fichier image et ensuite examiner\n![image](https://user-images.githubusercontent.com/91695685/147091137-e863be34-0429-47b1-a493-a2a8c9c1ae1d.png)\n\n\n3. pour encoder une image, l'utilisateur doit se placer dans l'onglet correspondant, puis choisir une image et taper nom de la nouvelle image qui va contenir le message. ensuite taper le message secret et enfin appuyer sur le bouton cacher\n![image](https://user-images.githubusercontent.com/91695685/147091253-4dca57d7-ab67-419a-8505-cd80b53321b8.png)\n\n\n4. pour decoder l'image, l'utilisateur doit se placer dans l'onglet correspondant, choisir le fichier image qui contient le message secret et appuyer sur le bouton decoder\n![image](https://user-images.githubusercontent.com/91695685/147091328-41b617f3-78cd-4169-9708-a0314f231803.png)\n\n# contribution\npour toute contribution ou réutilisation de ce projet, veuillez mentionner les noms des développeurs de ce projet : [damodarane jean-baptiste](https://github.com/jeanbaptiste02) et [elumalai sriguru](https://github.com/sriguru95). pour collaborer, veuillez les contacter pour obtenir leur consentement formel.\n"
  },
  {
    "readme": "# rhythm break\n\nrhythm break is a project carried out by damodarane jean-baptist and elumalai sriguru, second-year graduate students of computer science, at cy cergy paris university as part of the module of **web development 2021/2022**.\n\n[cy cergy paris universitaire](https://upload.wikimedia.org/wikipedia/en/thumb/6/69/logo_cy_cergy_paris_universit%c3%a9.svg/129px-logo_cy_cergy_paris_universit%c3%a9.svg.png)\n\n\n## project description\n\nOur project is about designing a website with dynamic pages in php. (the project is carried out in php, html5 & css3.)\n\nThis website is based on music and uses the apis of lastfm and deezer.\n\n## urls\n- http://rhythmbreak.alwaysdata.net/\n- https://damodaranejb.alwaysdata.net/\n- https://elumalai.alwaysdata.net/\n\n## online\n\nwe used a free platform for hosting our website: **[alwaysdata](https://alwaysdata.com)** .\n\n",
    "readme_before": "# rythm break\n\nrythm break est un projet réalisé par damodarane jean-baptiste et elumalai sriguru, étudiants en licence de deuxième année d'informatique, à cy cergy paris université dans le cadre du module de **développement web 2021/2022**.\n\n![cy cergy paris université](https://upload.wikimedia.org/wikipedia/fr/thumb/6/69/logo_cy_cergy_paris_universit%c3%a9.svg/129px-logo_cy_cergy_paris_universit%c3%a9.svg.png)\n\n\n## description du projet\n\nnotre projet porte sur la conception d'un site web avec des pages dynamiques en php. (le projet est réalisé en php, html5 & css3.)\n\nce site web se base sur la music et utilise les apis de lastfm et de deezer.\n\n### urls\n - http://rythmbreak.alwaysdata.net/\n - https://damodaranejb.alwaysdata.net/\n - https://elumalai.alwaysdata.net/\n\n## mise en ligne\n\nnous avons utilisé un plateforme gratuit pour l'hébergement de notre site web :  **[alwaysdata](https://alwaysdata.com)** .\n\n"
  },
  {
    "readme": "virtupad\n",
    "readme_before": "virtupad\n"
  },
  {
    "readme": "# trombinoscope - draft end of license\n\n## mit license\n[![license: mit](https://img.shields.io/badge/license-mit-yellow.svg)](https://opensource.org/licenses/mit)\n\n## project description\n\nas part of our third year of computer license at cy cergy paris university, our team has developed a trombinoscope using php in the integration project module. This platform allows users to visualize student faces and information intuitively. In addition, we have integrated a teaching evaluation feature by students to improve the quality of teaching.\n\n## main features\n\n- visualisation and complete management of students: consult the students' faces and detailed information in a user-friendly way.\n\n- evaluation of teaching: students can evaluate courses and provide feedback to teachers to improve the quality of teaching.\n\n## technologies used\n\n- php\n- psql\n\n## configuration and installation\n\n- clone the restitory: git clone https://github.com/jeanbaptist02/trombinoscope\n\n- Start the php server: ```php -s localhost:8000```\n\n## user guide\n\n- Access the application via your browser: http://localhost:8000.\n\n## project creators\n\n- [jean-baptist](https://github.com/jeanbaptist02)\n- [sriguru](https://github.com/sriguru95)\n- [nihar](#)\n- [victor](https://github.com/seed4616)\n\n© copyright\n\n### © project autheurs and cy cergy paris university\n\nThis project is an intellectual property protected by copyright laws. the source code, design and associated documents may not be reproduced, distributed or transmitted without the prior written permission of the development team.\n\nRestricted use\n\nThis source code is provided exclusively for educational and understanding purposes. No reproduction, commercial use, redistribution or modification is permitted without explicit permission from the development team.\n",
    "readme_before": "# trombinoscope - projet de fin de licence\n\n## mit license\n[![license: mit](https://img.shields.io/badge/license-mit-yellow.svg)](https://opensource.org/licenses/mit)  \n\n## description du projet\n\ndans le cadre de notre troisième année de licence informatique à cy cergy paris université, notre équipe a développé un trombinoscope en utilisant php dans le module projet d'intégration. cette plateforme permet aux utilisateurs de visualiser les visages et les informations des étudiants de manière intuitive. de plus, nous avons intégré une fonctionnalité d'évaluation des enseignements par les étudiants pour améliorer la qualité de l'enseignement.\n\n## fonctionnalités principales\n\n- visualisation et une gestion complète des étudiants : consultez les visages et les informations détaillées des étudiants de manière conviviale.\n\n- évaluation des enseignements : les étudiants peuvent évaluer les cours et fournir des feedbacks aux enseignants pour améliorer la qualité de l'enseignement.\n\n## technologies utilisées\n\n- php\n- psql\n\n## configuration et installation\n\n- clonez le repository : git clone https://github.com/jeanbaptiste02/trombinoscope\n\n- démarrez le serveur php : ```php -s localhost:8000```\n\n## guide d'utilisation\n\n- accédez à l'application via votre navigateur : http://localhost:8000.\n\n## créateurs du projet \n\n- [jean-baptiste](https://github.com/jeanbaptiste02)\n- [sriguru](https://github.com/sriguru95)\n- [nihar](#)\n- [victor](https://github.com/seed4616)\n\n## © copyright \n\n### © autheurs du projet et cy cergy paris université \n\nce projet est une propriété intellectuelle protégée par les lois sur les droits d'auteur. le code source, la conception et les documents associés ne peuvent être reproduits, distribués ou transmis sans l'autorisation écrite préalable de l'équipe de développement.\n\n### utilisation restreinte\n\nce code source est fourni exclusivement à des fins éducatives et de compréhension. aucune reproduction, utilisation commerciale, redistribution ou modification n'est autorisée sans une autorisation explicite de l'équipe de développement.\n"
  },
  {
    "readme": "# project dungeon descriiler\n\n# # description\n\nproject the end of class bachelor informatics of university amikom yogyakarta\nfor an algorithm & programming course. This project is a text-based game\nAim to defeat the monsters in the dungeon.\nThis game was created using c + + programming language.\n\n# # how to build\n\ndependents:\n- cmake\n- python3.10 (for conan)\n- c + + compiler (msvc for windows, gcc for linux)\n- conan\n- Shh.\n- nlohmann _ json\n\n# # # how to build dependents\n\nMake sure conan is installed on your computer. If not, please install conan first.\n\n\n1. Run detection conan profile\n```bash\nconan profile detect\n```\n\n2. install dependencies\n```bash\nconan install . --build=missing -c tools.system.package_manager:mode=install -c tools.system.package_manager:sudo=true\n```\n\n3. build project\n```bash\ncmake . -dcmake_build_type=debug -dcmake_project_top_level_includes=\"conan_provider.cmake\"\n```\n",
    "readme_before": "# project dungeon despoiler\n\n## description\n\nproject tugas akhir kelas bachelor informatics dari universitas amikom yogyakarta\nuntuk mata kuliah algorithm & programming. project ini merupakan game berbasis text yang \nbertujuan untuk mengalahkan monster-monster yang ada di dalam dungeon. \ngame ini dibuat menggunakan bahasa pemrograman c++.\n\n## how to build\n\ndependencies:\n- cmake\n- python3.10 (for conan)\n- c++ compiler (msvc for windows, gcc for linux)\n- conan\n- sdl\n- nlohmann_json\n\n### how to build dependencies\n\npastikan conan sudah terinstall di komputer anda. jika belum, silahkan install conan terlebih dahulu.\n\n\n1. jalankan deteksi profile conan\n```bash\nconan profile detect\n```\n\n2. install dependencies\n```bash\nconan install . --build=missing -c tools.system.package_manager:mode=install -c tools.system.package_manager:sudo=true\n```\n\n3. build project\n```bash\ncmake . -dcmake_build_type=debug -dcmake_project_top_level_includes=\"conan_provider.cmake\"\n```\n"
  },
  {
    "readme": "design_a_chip-snake_by_group_a4\n",
    "readme_before": "design_a_chip-snake_by_group_a4\n"
  },
  {
    "readme": "cascavell\n======\n\ncascavell is a c-based programming language concept that uses spaces to define code blocks. developed using yacc/bison and flex.\n\n<p allign=\"center\">\n<img alt=\"logo cascavell\" src=\"https://raw.githubusercontent. with/heckrodsav/cascavell/master/docs/cascavell_logo. png\" width=\"500px\">\n</p>\n\n---\n\n\nabout\n------\n\ncascavell is a programming language concept developed as the final project of the compiler discipline, in the bachelor's degree in computer science at the federal university of abc.\n\nthe purpose of the language is to use indentation as code blocks delimiters and omit '**;**', characteristic of c language. it is an implementation of c language with less resources, inspired by python language.\n\nthe extension of the language files is **.cll**.\n\nin this repository are the specifications of the lexical and syntactic analyzer for cascavell language.\n\n# Symbols and reserved words\n\nthe language has bit-a-bit operators, logical operators and arithmetic operators. operators have their precedence defined based on language c:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n==References====External links==\n\n\n\n\n\n\n\n\n\nwhere the level of precedence ranges from 1 to 14, 1 being the highest possible precedence.\n\nthe reserved words are used to define types of variables and functions and perform control of the program flow:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Syntax of language\n\nlanguage requires the use of parentheses if it requires nesting of ternary operators.\n\nfunctions must have a blank line between their settings.\n\n---\n\n\ninstallation and use\n------\n\n# Prerequisites #\n\nfor it is possible to compile the analyzers it is necessary to have flex and bison/yacc installed. to install:\n\n```console\n$ sudo apt-get update\n$ sudo apt-get install flex\n$ sudo apt-get install bison\n```\n\npara executar o compilador é necessário um compilador de c.\n\n### executando os analisadores\n\npara executar os analisadores, entre na pasta da versão desejada:\n\n```console\n$ cd c.version\n```\n\nou \n\n```console\n$ cd cpp.version\n```\n\ne digite:\n\n```console\n$ make full\n```\n\nesse comando utilizará o flex e o bison para gerar os analisadores, criará a versão executável e automaticamente irá acessar a pasta _exemplos_, gerando um arquivo log para cada um dos códigos de exemplo da linguagem.\n\n---",
    "readme_before": "cascavell\n======\n\ncascavell é um conceito de linguagem de programação baseada em c que usa espaços para definir blocos de código. desenvolvida utilizando o yacc/bison e o flex.\n\n<p align=\"center\">\n  <img alt=\"logo cascavell\" src=\"https://raw.githubusercontent.com/heckrodsav/cascavell/master/docs/cascavell_logo.png\" width=\"500px\">\n</p>\n\n---\n\n\nsobre\n------\n\ncascavell é um conceito de linguagem de programação desenvolvido como projeto final da disciplina de compiladores, no curso de bacharelado em ciência da computação na universidade federal do abc.\n\na proposta da linguagem é utilizar a indentação como delimitadores de blocos de código e omitir os '**;**', característicos da linguagem c. trata-se de uma implementação da linguagem c com menos recursos, inspirada pela linguagem python.\n\na extensão dos arquivos da linguagem é **.cll**.\n\nneste repositório se encontram as especificações do analisador léxico e sintático para a linguagem cascavell.\n\n### símbolos e palavras reservadas\n\na linguagem conta com operadores bit-a-bit, operadores lógicos e operadores aritméticos. os operadores tem sua precedência definida baseados na linguagem c:\n\n|símbolo|descrição|símbolo|descrição|\n|:-----:|:--------|:-----:|:--------|\n|==|comparação lógica de igualdade|%|resto da divisão de inteiros|\n|!=|comparação lógica de desigualdade|\\||ou lógico bit-a-bit|\n|<=|comparação lógica|&|e lógico bit-a-bit|\n|>=|comparação lógica|,|separador|\n|=|atribuição|:|separador de if-else do operador ternário|\n|<|comparação lógica|?|operador ternário|\n|>|comparação lógica|!|negação lógica|\n|+|soma (real ou inteiro)|(|abre parênteses|\n|-|subtração (real ou inteiro)|)|fecha parênteses|\n|*|multiplicação (real ou inteiro)|[|abre colchete|\n|/|divisão (real ou inteiro)|]|fecha colchete|\n|^|xor lógico bit-a-bit|{|abre chave|\n|~|negação lógica bit-a-bit|}|fecha chave|\n\n\n|nível de precedência|operador|grupo|descrição|\n|:------------------:|:------:|:---:|:--------|\n| 1  | ( )  | lógico | precedencia preferencial |\n| 2  | !    | lógico | negação lógica |\n| 2  | ~    | bit-a-bit | negação bit-a-bit |\n| 3  | *    | aritmético | multiplicação |\n| 3  | /    | aritmético | divisão |\n| 3  | %    | aritmético | resto da divisão |\n| 4  | +    | aritmético | soma |\n| 4  | -    | aritmético | subtração |\n| 5  | >=   | lógico | relação de ordem |\n| 5  | <=   | lógico | relação de ordem |\n| 5  | >    | lógico | relação de ordem |\n| 5  | <    | lógico | relação de ordem |\n| 6  | !=   | lógico | comparação de desigualdade |\n| 6  | ==   | lógico | comparação de igualdade |\n| 7  | &    | bit-a-bit | and bit-a-bit |\n| 8  | ^    | bit-a-bit | xor bit-a-bit |\n| 9  | \\|   | bit-a-bit | or bit-a-bit |\n| 10 | &&   | lógico | and lógico |\n| 11 | \\|\\| | lógico | or lógico |\n| 12 | ?:   | aritmético | operador de atribuição condicional (ternário) |\n| 13 | =    | aritmético | atribuição |\n| 14 | ,    | | |\n\nonde o nível de precedência vai de 1 a 14, 1 sendo a maior precedência possível.\n\nas palavras reservadas são utilizadas para definir tipos de variáveis e funções e realizar controle do fluxo do programa:\n\n|palavra reservada|descrição|\n|:---------------:|:--------|\n|void|tipo de variável/retorno nulo|\n|int|tipo de variável numérica inteira|\n|double|tipo de variável numérica real|\n|char|tipo de variável caractere|\n|bool|tipo de variável lógica booleana|\n|if|controle de fluxo condicional que executa o bloco indentado abaixo caso a condição seja verdadeira|\n|else|controle de fluxo condicional que executa o bloco indentado caso o if que o antecede tenha sido falso|\n|while|laço de repetição que executa o bloco indentado enquanto a condição for verdadeira|\n|return|instrução de retorno de valor para uma função|\n|end|delimitador de fim de bloco indentado|\n\n### sintáxe da linguagem\n\na linguagem requer o uso de parênteses caso precise de aninhamento de operadores ternários.\n\nfunções devem ter uma linha em branco entre suas definições.\n\n---\n\n  \ninstalação e uso\n------\n\n### pré-requisitos\n\npara que seja possível compilar os analisadores é preciso ter o flex e o bison/yacc instalados. para instalar:\n\n```console\n$ sudo apt-get update\n$ sudo apt-get install flex\n$ sudo apt-get install bison\n```\n\npara executar o compilador é necessário um compilador de c.\n\n### executando os analisadores\n\npara executar os analisadores, entre na pasta da versão desejada:\n\n```console\n$ cd c.version\n```\n\nou \n\n```console\n$ cd cpp.version\n```\n\ne digite:\n\n```console\n$ make full\n```\n\nesse comando utilizará o flex e o bison para gerar os analisadores, criará a versão executável e automaticamente irá acessar a pasta _exemplos_, gerando um arquivo log para cada um dos códigos de exemplo da linguagem.\n\n---"
  },
  {
    "readme": "# Resources\n## font\nexo 2 - https://fonts.google.com/download/next-steps?query=exo+2\n",
    "readme_before": "# zdroje\n## font\nexo 2 - https://fonts.google.com/download/next-steps?query=exo+2\n"
  },
  {
    "readme": "♪ museumomer\n###Management-type multiplatform application as an internship project.\n## object of study: (https://www.museomero.it/).\n\n## mobile (android + ios)\n\n<div align=\"left\">\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598086-c32e6fd2-d17f-4c78-85b3-f81d110d14fa.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598095-ed68a459-4551-45c7-a6a8-36ea656a7e4.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598101-01b8103d-4449-433b-ba65-fb8955868592.png\"/>\n\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598102-6814c097-9aad-4a1c-95cc-d0d0b5801c43.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598105-fd277962-842d-4776-b4a2-f99c16d442c2.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598106-19cfc37b-c63a-499f-8899-75ae9f18a993.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598108-f10e8cf0-3768-4a2c-b596-3d86f7e8b321.png\"/>\n\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598111-98b9e39d-1f34-44e0-8b9b-933e0487ebb8.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598113-3d6cb931-d1f7-4198-8c87-f8fc65f255d7.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598116-84007d85-2836-48a1-86ca-0e8da56a1a2a.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598120-2deb634d-a68d-4978-a063-19ce9e467852.png\"/>\n\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598122-c2819938-26af-4d50-abca-7c6707d7c3ea.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598125-274daef6-ced3-4063-a892-74bd41a87ffb.png\"/>\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598128-681ed68d-20d-4436-986c-c1532a91f777.png\"/>\n\n\n\n--\n\n♪ windows ♪\n\n![screenshot 2023-03-10 173528](https://user-images.githubusercontent.com/22773005/224372456-9e404ec3-d1a1-4138-8425-abf832f86341.png)\n![screenshot 2023-03-10 173451](https://user-images.githubusercontent.com/22773005/224372464-7dbbba82-050fb3-be92-d33b781954ec.png)\n![screenshot 2023-03-10 173813](https://user-images.githubusercontent.com/22773005/224372468-67c46bb5-4ebe-4aeb-a776-75406916703a.png)\n![screenshot 2023-03-10 173649](https://user-images.githubusercontent.com/22773005/224372471-dbef5f08-2022-42d3-bc4b-280a09da17a4.png)\n![screenshot 2023-03-10 173624](https://user-images.githubusercontent.com/22773005/224372476-a929ef32-33ff-40d2-b925-d74bf28dbff9.png)\n\n",
    "readme_before": "# museoomero\n### applicazione multipiattaforma di tipo gestionale realizzata come progetto di tirocinio.\n### oggetto di studio: [museo tattile statale omero](https://www.museoomero.it/).\n\n## mobile (android + ios)\n\n<div align=\"left\">\n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598086-c32e6fd2-d17f-4c78-85b3-f81d110d14fa.png\"/>    \n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598095-ed68a459-4551-45c7-a6a8-36ea656aa7e4.png\"/>    \n<img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598101-01b8103d-4449-433b-ba65-fb8955868592.png\"/>\n  \n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598102-6814c097-9aad-4a1c-95cc-d0d0b5801c43.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598105-fd277962-842d-4776-b4a2-f99c16d442c2.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598106-19cfc37b-c63a-499f-8899-75ae9f18a993.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598108-f10e8cf0-3768-4a2c-b596-3d86f7e8b321.png\"/>\n  \n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598111-98b9e39d-1f34-44e0-8b9b-933e0487ebb8.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598113-3d6cb931-d1f7-4198-8c87-f8fc65f255d7.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598116-84007d85-2836-48a1-86ca-0e8da56a1a2a.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598120-2deb634d-a68d-4978-a063-19ce9e467852.png\"/>\n  \n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598122-c2819938-26af-4d50-abca-7c6707d7c3ea.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598125-274daef6-ced3-4063-a892-74bd41a87ffb.png\"/>\n  <img alt=\"api\" height=\"480\" src=\"https://user-images.githubusercontent.com/22773005/225598128-681ed68d-20dd-4436-986c-c1532a91f777.png\"/>\n \n\n\n---\n\n## windows\n\n![screenshot 2023-03-10 173528](https://user-images.githubusercontent.com/22773005/224372456-9e404ec3-d1a1-4138-8425-abf832f86341.png)\n![screenshot 2023-03-10 173451](https://user-images.githubusercontent.com/22773005/224372464-7dbbba82-050f-4fb3-be92-d33b781954ec.png)\n![screenshot 2023-03-10 173813](https://user-images.githubusercontent.com/22773005/224372468-67c46bb5-4ebe-4aeb-a776-75406916703a.png)\n![screenshot 2023-03-10 173649](https://user-images.githubusercontent.com/22773005/224372471-dbef5f08-2022-42d3-bc4b-280a09da17a4.png)\n![screenshot 2023-03-10 173624](https://user-images.githubusercontent.com/22773005/224372476-a929ef32-33ff-40d2-b925-d74bf28dbff9.png)\n\n"
  },
  {
    "readme": "==References====External links== with/pryskas/brazilian_racial_segregation/blob/main/data/figures/gate%20-%20log%201%20vert.png\" alt=\"logo\" width=\"200\">\n<img allign=\"right\" src=\"https://github.com/pryskas/brazilian_racial_segregation/blob/main/data/figures/ufabc-logo.png\" alt=\"logo\" width=\"110\" height=\"110\">\n\n# Racial residential segregation: patterns of isolation and exposure\n\n\n<p allign=\"justify\">this repository refers to a research project that seeks to understand and characterize the isolation and explosion patterns of spatial segregation of racial groups separated by different income ranges in Brazilian metropolises. we analyzed the black and white groups of five income ranges classified between a and, in the metropolis of são paulo, rio de janeiro, belo horizonte, recife and porto alegre. </p>\n\n-------------------------------------\n\nProject structure\n\n\n md < - main project documentation with general information to manipulate the repository.\nDate\n\n\n\n\n\n\n\n\n\n\n txt <- package requests to use running scripts on the local host (python)\n\n-------------------------------------\n\nTeam:\n- author: [priscilla santos](https://www.linkedin.com/in/priscilla-santoss/)\n- advisor and co-author: [flavia f. fesa](https://flaviafeitosa.wordpress.com/)\n- co-advisor and co-author: [joana barros](https://www.bbk.ac.uk/our-staff/profile/8008655/joana-barros#overview)\n- co-author: [flavia lisboa](http://lattes.cnpq.br/3860822725559503)\n\n# References:\n- [gate](https://gateufabc.wixsite.com/gate/search)\n- [bacharelate in territorial planning](https://gradacao.ufabc.edu.br/bpt/)\n- [Federal university of abc](https://www.ufabc.edu.br/)\n",
    "readme_before": "<img align=\"right\" src=\"https://github.com/pryskas/brazilian_racial_segregation/blob/main/data/figures/gate%20-%20logo%201%20vert.png\" alt=\"logo\" width=\"200\">\n<img align=\"right\" src=\"https://github.com/pryskas/brazilian_racial_segregation/blob/main/data/figures/ufabc-logo.png\" alt=\"logo\" width=\"110\" height=\"110\">\n\n# segregação residencial racial: padrões de isolamento e exposição\n\n\n<p align=\"justify\">esse repositório refere-se a um projeto de pesquisa que busca entender e caracterizar os padrões de isolamento e explosição da segregação espacial de grupos raciais separado por diferentes faixas de renda em metrópoles brasileiras. foram analisados os grupos negros e brancos, de cinco faixas de renda classificadas entre a e e, na metrópoles de são paulo, rio de janeiro, belo horizonte, recife e porto alegre.</p> \n\n-------------------------------------\n\n### estrutura do projeto\n\n    ├── license                    \n    ├── readme.md                  <- principal documentação do projeto com informações gerais para manipular o repositório.\n    ├── data\n    │   ├── figures                <- visualizações (mapas, figuras, imagens)\n    │   ├── output                 <- dados processados e prontos\n    │   ├── treated                <- dados pré-processados, limpos, tratados e organizados\n    │   └── raw                    <- dados originais\n    ├── documents\n    │   ├── articles               <- dados processados e prontos\n    │   ├── references             <- dados pré-processados, limpos, tratados e organizados\n    │   └── reports                <- dados originais\n    ├── notebooks                  <- jupyter notebooks(.ipynb) (python)\n    ├── scripts                    <- arquivos python(.py), spss syntax (.sps, .sas), arquivos r (.r, .rproj)\n    ├── requirements.txt           <- requisições de pacotes para usar rodar os scripts na máquina local (python)\n\n-------------------------------------\n\n### equipe: \n- autora: [priscila santos](https://www.linkedin.com/in/priscila-santoss/) \n- orientadora e coautora: [flávia f. feitosa](https://flaviafeitosa.wordpress.com/)\n- coorientadora e coautora: [joana barros](https://www.bbk.ac.uk/our-staff/profile/8008655/joana-barros#overview)\n- coautora: [flávia lisboa](http://lattes.cnpq.br/3860822725559503)\n\n### referências: \n- [gate](https://gateufabc.wixsite.com/gate/pesquisas)\n- [bacharelado em planejamento territorial](https://graduacao.ufabc.edu.br/bpt/)\n- [universidade federal do abc](https://www.ufabc.edu.br/)\n"
  },
  {
    "readme": "![custom badge](https://img.shields.io/badge/required-docker-blue.svg) ![custom badge](https://img.shields.io/badge/required-npm%20v6.9.0-cc0000.svg)\n\n---\n\n## back-end\n![custom badge](https://img.shields.io/badge/node.js-v10.14.1-00aa00.svg) ![custom badge](https://img.shields.io/badge/ecmascript-5.1-orange.svg)\n\n## front-end\n![custom badge](https://img.shields.io/badge/javascript-2.0-orange.svg) ![custom badge](https://img.shields.io/badge/html-5-orange.svg) ![custom badge](https://img.shields.io/badge/css-3-ff0000.svg)\n\n-----\n\n# table of content\n\n> [1 project csrf](#1 project csrf)\n\n> > [1.1 scenario 1 - csrf exploit](#11 scenario 1--crf exploit)\n\n> > [1.2 scenario 2 - csrf mitigation](#12 scenario 2--csrf mitigation)\n\n> [2 project oauth-jwt](#2 project oauth-jwt)\n\n> > [2.1 scenario 3 - saving tokens in local storage](#21 scenario 3--token-save-in-local storage)\n\n-----\n\n![custom badge](https://img.shields.io/badge/trusted%20server%20web%20application-http%3a%2f%2flocalhost%3a8081-crimson.svg) ![custom badge](https://img.shields.io/badge/csrf%20exploit-http%3a%2f%2flocalhost%3a8082-crimson.svg)\n\n# 1 project csrf\n\n## 1.1 scenario 1 - csrf exploit\n\n### Step 1: Start docker containers\n\n```bash\n$ git checkout csrf-1/csrf-vulnerability-example\n$ cd csrf/docker\n```\n- **linux**: `path/to/docker $ ./up.sh`\n- **windows**: `path/to/docker> up.bat`\n\n### stap 2: de csrf-aanval\n\n1. surf naar [http://localhost:8081](http://localhost:8081)\n2. kies een gebruiker en meld je aan\n3. (optioneel) klik op de knop `wijzigen` en wijzig het e-mailadres\n4. surf naar [http://localhost:8082](http://localhost:8082)\n5. volg de instructies voor een csrf-aanval\n6. ververs de webapplicatie op de _trusted server_: het e-mailadres moet `forged@bybadguy.example.com` worden. **de csrf-aanval is gelukt!**\n\n### stap 3: docker-containers stoppen\n\n- **linux**: `path/to/docker $ ./down.sh`\n- **windows**: `path/to/docker> down.bat`\n\n## 1.2 scenario 2 - csrf-mitigatie\n\n![custom badge](https://img.shields.io/badge/security-csrf-purple.svg)\n\n```bash\n$ git checkout csrf-1/csrf-token-example\n$ cd csrf/docker\n```\ndezelfde stappen herhalen zoals bij [1.1 scenario 1 - csrf-exploit](#11-scenario-1---csrf-exploit).\nde csrf-aanval mislukt.\n\n# 2 project oauth-jwt\n\n![custom badge](https://img.shields.io/badge/web%20application-http%3a%2f%2flocalhost%3a8083-crimson.svg) ![custom badge](https://img.shields.io/badge/web%20api-http%3a%2f%2flocalhost%3a8083%2fapi-crimson.svg) ![custom badge](https://img.shields.io/badge/token%20endpoint-http%3a%2f%2flocalhost%3a8083%2fauth-crimson.svg)\n\n## 2.1 scenario 3 - tokens opslaan in localstorage\n\n![custom badge](https://img.shields.io/badge/security-oauth%202-purple.svg) ![custom badge](https://img.shields.io/badge/security-jws-purple.svg)\n\n### stap 1: node.js server starten \n\n```bash\n$ git checkout oauth-1/oauth-ropc-initial\n$ cd oauth/webapp\n$ node app\n```\n\n### stap 2: toegangstoken aanvragen\n\n1. surf naar [http://localhost:8083](http://localhost:8083), klik op `localstorage weergeven`: het zal leeg zijn.\n2. meldt u aan. u wordt omgeleid naar de homepagina.\n3. klik vervolgens opnieuw op `localstorage weergeven`: een toegangstoken (jwt) wordt weergegeven, uitgegeven door het token endpoint (**resource owner password credentials grant type**).\n4. wijzig het e-mailadres. het zal succesvol gewijzigd worden.\n",
    "readme_before": "![custom badge](https://img.shields.io/badge/required-docker-blue.svg) ![custom badge](https://img.shields.io/badge/required-npm%20v6.9.0-cc0000.svg)\n\n---\n\n### back-end\n![custom badge](https://img.shields.io/badge/node.js-v10.14.1-00aa00.svg)  ![custom badge](https://img.shields.io/badge/ecmascript-5.1-orange.svg)\n\n### front-end\n![custom badge](https://img.shields.io/badge/javascript-2.0-orange.svg) ![custom badge](https://img.shields.io/badge/html-5-orange.svg) ![custom badge](https://img.shields.io/badge/css-3-ff0000.svg)\n\n------\n\n# table of contents\n\n> [1 project csrf](#1-project-csrf)\n\n> > [1.1 scenario 1 - csrf exploit](#11-scenario-1---csrf-exploit)\n\n> > [1.2 scenario 2 - csrf mitigatie](#12-scenario-2---csrf-mitigatie)\n\n> [2 project oauth-jwt](#2-project-oauth-jwt)\n\n> > [2.1 scenario 3 - tokens opslaan in localstorage](#21-scenario-3---tokens-opslaan-in-localstorage)\n\n------\n\n![custom badge](https://img.shields.io/badge/trusted%20server%20web%20application-http%3a%2f%2flocalhost%3a8081-crimson.svg) ![custom badge](https://img.shields.io/badge/csrf%20exploit-http%3a%2f%2flocalhost%3a8082-crimson.svg)\n\n# 1 project csrf\n\n## 1.1 scenario 1 - csrf-exploit\n\n### stap 1: docker-containers starten \n\n```bash\n$ git checkout csrf-1/csrf-vulnerability-example\n$ cd csrf/docker\n```\n- **linux**: `path/to/docker $ ./up.sh`\n- **windows**: `path/to/docker> up.bat`\n\n### stap 2: de csrf-aanval\n\n1. surf naar [http://localhost:8081](http://localhost:8081)\n2. kies een gebruiker en meld je aan\n3. (optioneel) klik op de knop `wijzigen` en wijzig het e-mailadres\n4. surf naar [http://localhost:8082](http://localhost:8082)\n5. volg de instructies voor een csrf-aanval\n6. ververs de webapplicatie op de _trusted server_: het e-mailadres moet `forged@bybadguy.example.com` worden. **de csrf-aanval is gelukt!**\n\n### stap 3: docker-containers stoppen\n\n- **linux**: `path/to/docker $ ./down.sh`\n- **windows**: `path/to/docker> down.bat`\n\n## 1.2 scenario 2 - csrf-mitigatie\n\n![custom badge](https://img.shields.io/badge/security-csrf-purple.svg)\n\n```bash\n$ git checkout csrf-1/csrf-token-example\n$ cd csrf/docker\n```\ndezelfde stappen herhalen zoals bij [1.1 scenario 1 - csrf-exploit](#11-scenario-1---csrf-exploit).\nde csrf-aanval mislukt.\n\n# 2 project oauth-jwt\n\n![custom badge](https://img.shields.io/badge/web%20application-http%3a%2f%2flocalhost%3a8083-crimson.svg) ![custom badge](https://img.shields.io/badge/web%20api-http%3a%2f%2flocalhost%3a8083%2fapi-crimson.svg) ![custom badge](https://img.shields.io/badge/token%20endpoint-http%3a%2f%2flocalhost%3a8083%2fauth-crimson.svg)\n\n## 2.1 scenario 3 - tokens opslaan in localstorage\n\n![custom badge](https://img.shields.io/badge/security-oauth%202-purple.svg) ![custom badge](https://img.shields.io/badge/security-jws-purple.svg)\n\n### stap 1: node.js server starten \n\n```bash\n$ git checkout oauth-1/oauth-ropc-initial\n$ cd oauth/webapp\n$ node app\n```\n\n### stap 2: toegangstoken aanvragen\n\n1. surf naar [http://localhost:8083](http://localhost:8083), klik op `localstorage weergeven`: het zal leeg zijn.\n2. meldt u aan. u wordt omgeleid naar de homepagina.\n3. klik vervolgens opnieuw op `localstorage weergeven`: een toegangstoken (jwt) wordt weergegeven, uitgegeven door het token endpoint (**resource owner password credentials grant type**).\n4. wijzig het e-mailadres. het zal succesvol gewijzigd worden.\n"
  },
  {
    "readme": "# IT project l3 - reindeer 1 2017/2018\n\n## subject\nmakemyquiz, quiz creation software.\n\n#authors\n- maxime lambert - [profile](https://github.com/magikarplvl5)\n- josie signe - [profile](https://github.com/darlysia)\n- leo rouzic - [profile](https://github.com/morphaning)\n- Dovid fox--calzant - [profile](https://github.com/chacrex)\n- sahid christophus - [profile](https://github.com/markhum)\n\n### project goal\n\nmakemyquiz is a quiz design software mainly designed for entertainment purposes, especially during animations in bars, playrooms, etc... but also for the field of education.\nthe software is designed to be played with remote controls but any controllers compatible with your computer can substitute these remote controls.\n\nPrerequisite\n\n- unity community 2018.1.1f1 (https://unity3d.com/)\n- windows 7+: 64 or 32 bits\n\nFunctions\n\n- [x] up to 8 participating teams\n- [x] points calculation and bonus management\n- [x] Sleeve-subject-question organization\n- [x] different types of questions:\n- [x] multiple choices\n- [x] music recognition\n- [x] image recognition\n- [x] true - fake\n- internationalization\n- [x] speed mode\n- [x] equality management\n- [x] automatic backup/backup\n\n\n### user guide\n\nlink: [use guide](documents/use guide.pdf)\n(available in the documents folder)\ncontact us: makemyquiz.serviceapresfun@gmail.com\nnb: download the document to access hyperlinks and the plan.\n\nGallery\n![image1](https://i.imgur.com/vijdwow.jpg)",
    "readme_before": "\n# projet l3 informatique - rennes 1 2017/2018\n\n## sujet\nmakemyquiz, logiciel de création de quiz.\n\n## auteurs\n- maxime lambert - [profil](https://github.com/magikarplvl5)\n- josie signe - [profil](https://github.com/darlysia)\n- leo rouzic - [profil](https://github.com/morkaning)\n- david renard--calzant - [profil](https://github.com/chacrex)\n- christophe sahid - [profil](https://github.com/markhum)\n\n### but du projet\n\nmakemyquiz est un logiciel de conception de quiz principalement conçu à des fins de divertissement, notamment lors d'animations dans des bars, salles de jeu, etc... mais également pour le domaine de l'éducation.\nle logiciel est conçu pour être joué avec des télécommandes mais toutes manettes compatibles avec votre ordinateur peuvent substituer ces télécommandes.\n\n### prérequis \n\n- unity community 2018.1.1f1 (https://unity3d.com/)\n- windows 7+ : 64 ou 32 bits\n\n### fonctionalités\n\n- [x] jusqu'à 8 équipes participantes\n- [x] calcul de points et gestion de bonus\n- [x] organisation en manches-sujet-questions\n- [x] différents types de question : \n    - [x] choix multiples\n    - [x] reconnaissance de musiques\n    - [x] reconnaissance d'images\n    - [x] vrai - faux\n- [x] internationalisation\n- [x] mode rapidité\n- [x] gestion des égalités\n- [x] sauvegarde/backup automatique \n\n\n### guide d'utilisation\n\nlien : [guide d'utilisation](documents/guide_d'utilisation.pdf)\n(disponible dans le dossier documents)\nnous contacter : makemyquiz.serviceapresfun@gmail.com\nnb : telecharger le document pour avoir accès aux hyperliens et au plan. \n\n### galerie\n![image1](https://i.imgur.com/vijdwow.jpg)"
  },
  {
    "readme": "<! -- languages ------------------------------------------------------------------------------------------------------------------- >\n< div >\n< p align = \"left\" >\n< a href = \"/ readme-en.md\" > english < a > · < b > Spanish < / b >\n< / p >\n< / div >\n\n# self-monitoring\n# # # * reactive road planning by pure car-to-scale chase using ros and gazebo *\n\n< br >\n\n# # execution guide\n\n1. be located in the work folder:\n```\ncd catkin_racecar\n```\n\n2. generar el entorno de trabajo:\n```\nsource devel/setup.bash:\n```\n\n3. ejeuctar el control mediante mando:\n```\nroslaunch racecar_control gazebo_sim_joy.launch\n```\n\n4. ejecutar el algoritmo de seguimiento:\n```\nrosrun path_tracker follower.py\n```\n",
    "readme_before": "<!-- idiomas ------------------------------------------------------------------------------------------------------------------->\n<div>\n    <p align=\"left\">\n        <a href=\"/readme-en.md\">english<a> · <b>español</b>\n    </p>\n</div>\n            \n# seguimiento autónomo\n### *planificación reactiva de caminos mediante persecución pura en coche a escala utilizando ros y gazebo*\n  \n<br>\n\n## guía de ejecución\n\n1. ubicarse en la carpeta de trabajo:\n```\ncd catkin_racecar\n```\n\n2. generar el entorno de trabajo:\n```\nsource devel/setup.bash:\n```\n\n3. ejeuctar el control mediante mando:\n```\nroslaunch racecar_control gazebo_sim_joy.launch\n```\n\n4. ejecutar el algoritmo de seguimiento:\n```\nrosrun path_tracker follower.py\n```\n"
  }
]